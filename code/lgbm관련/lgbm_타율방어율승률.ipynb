{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : 해당하는 달까지에 대한 데이터를 넣어주면, 최종적으로 다음달을 예측함!!!\n",
    "\n",
    "- 현재 이 코드는 7월까지 있어서 8월(7월의 y_next)을 예측함 !!!!\n",
    "- 우리가 9월데이터까지를 추가하면 10월꺼를 예측하는 것임!!! \n",
    "\n",
    "(맞지??)\n",
    "\n",
    "\n",
    "타율, 방어율까지만 했고 창건오빠한테 승률 틀 받으면 그것도 만들어갈게유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimMinyoung\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 기본\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# 회귀분석\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:/Users/KimMinyoung/desktop/깃헙관련/빅콘git/data/total'\n",
    "data_list = os.listdir(data_dir)\n",
    "#print(len(data_list))\n",
    "#print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#년도별 저장\n",
    "data_list_2016 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2016') ]\n",
    "data_2016 = [pd.read_csv(os.path.join(data_dir,data_list_2016[x]),encoding='cp949') for x in range(len(data_list_2016))]\n",
    "data_list_2017 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2017') ]\n",
    "data_2017 = [pd.read_csv(os.path.join(data_dir,data_list_2017[x]),encoding='cp949') for x in range(len(data_list_2017))]\n",
    "data_list_2018 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2018') ]\n",
    "data_2018 = [pd.read_csv(os.path.join(data_dir,data_list_2018[x]),encoding='cp949') for x in range(len(data_list_2018))]\n",
    "data_list_2019 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2019') ]\n",
    "data_2019 = [pd.read_csv(os.path.join(data_dir,data_list_2019[x]),encoding='cp949') for x in range(len(data_list_2019))]\n",
    "data_list_2020 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2020') ]\n",
    "data_2020 = [pd.read_csv(os.path.join(data_dir,data_list_2020[x]),encoding='cp949') for x in range(len(data_list_2020))]\n",
    "#print('2020년 데이터: \\n', data_2020)\n",
    "\n",
    "#항목별 저장\n",
    "data_list_single_hitter = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('개인타자')]\n",
    "data_single_hitter = [pd.read_csv(os.path.join(data_dir, data_list_single_hitter[x]), encoding='cp949') for x in range(len(data_list_single_hitter))]\n",
    "data_list_single_pitcher = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('개인투수')]\n",
    "data_single_pitcher = [pd.read_csv(os.path.join(data_dir, data_list_single_pitcher[x]), encoding='cp949') for x in range(len(data_list_single_pitcher))]\n",
    "data_list_games = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('경기')]\n",
    "data_games = [pd.read_csv(os.path.join(data_dir, data_list_games[x]), encoding='cp949') for x in range(len(data_list_games))]\n",
    "data_list_player_enroll = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('등록선수')]\n",
    "data_player_enroll = [pd.read_csv(os.path.join(data_dir, data_list_player_enroll[x]), encoding='cp949') for x in range(len(data_list_player_enroll))]\n",
    "data_list_players = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('선수')]\n",
    "data_players = [pd.read_csv(os.path.join(data_dir, data_list_players[x]), encoding='cp949') for x in range(len(data_list_players))]\n",
    "data_list_teams = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀')]\n",
    "data_teams = [pd.read_csv(os.path.join(data_dir, data_list_teams[x]), encoding='cp949') for x in range(len(data_list_teams))]\n",
    "data_list_team_hitter = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀타자')]\n",
    "data_team_hitter = [pd.read_csv(os.path.join(data_dir, data_list_team_hitter[x]), encoding='cp949') for x in range(len(data_list_team_hitter))]\n",
    "data_list_team_pitcher = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀투수')]\n",
    "data_team_pitcher = [pd.read_csv(os.path.join(data_dir, data_list_team_pitcher[x]), encoding='cp949') for x in range(len(data_list_team_pitcher))]\n",
    "#print('팀투수 데이터:\\n', data_team_pitcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 투수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def team_pitcher_eda(year, team_name):\n",
    "    year_index = year - 2016 \n",
    "    \n",
    "    # team_pitcher data에 해당 경기의 해당 팀의 홈 어웨이 여부 column 추가\n",
    "    data_games_year = data_games[year_index]\n",
    "    data_games_year = data_games_year[['G_ID', 'VISIT_KEY', 'HOME_KEY']]\n",
    "    data_games_year = data_games_year.set_index('G_ID')\n",
    "    \n",
    "    data_team_pitcher_year = data_team_pitcher[year_index]\n",
    "    data_team_pitcher_year = pd.merge(data_team_pitcher_year, data_games_year, how='left', on=['G_ID'])\n",
    "\n",
    "    data_team_pitcher_year_team = data_team_pitcher_year[data_team_pitcher_year.T_ID == team_name]\n",
    "    df = data_team_pitcher_year_team\n",
    "    df['HOME_KEY'] = df['HOME_KEY'].map(lambda x: 1 if x == team_name else 0 )\n",
    "    df = df.drop(columns = ['VISIT_KEY', 'GDAY_DS'])\n",
    "    \n",
    "    # LabelEncoding\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    df['VS_T_ID'] = encoder.fit_transform(df['VS_T_ID']) #상대편\n",
    "    df['TB_SC'] = encoder.fit_transform(df['TB_SC']) #이닝 초/말\n",
    "    df['WLS'] = encoder.fit_transform(df['WLS']) #승패무 여부\n",
    "    \n",
    "    \n",
    "    ### 이부분은 모든 EDA에서 동일하게 작성\n",
    "    \n",
    "    df['H1']=df['HIT']-df['H2']-df['H3']-df['HR']\n",
    "\n",
    "    #df['G_ID'] = pd.Series(dt)\n",
    "    df['year']=df['G_ID'].str.slice(0,4).astype(int)\n",
    "    df['month']=df['G_ID'].str.slice(4,6).astype(int)\n",
    "    \n",
    "    df[\"FIP\"] = ((13*df.HR+3*(df.BB+df.HP-df.IB)-2*df.KK)/(df.INN2/3)) +3.2\n",
    "    df[\"BABIP\"] = (df.HIT-df.HR)/(df.AB-df.KK-df.HR+df.SF)\n",
    "    df['SLG']=(df['HIT']+df['HP']+df['BB'])/(df['AB']+df['BB']+df['HP']+df['SF'])\n",
    "    df['OBA']=(df['H1']+2*df['H2']+3*df['H3']+4*df['HR'])/df['AB']\n",
    "    df['W_OPS']=0.57* df['SLG']+0.43*df['OBA']\n",
    "\n",
    "    # 시계열 데이터(경기당 방어율 계산)이기 때문에 경기 코드를 index로\n",
    "    df = df.set_index('G_ID')\n",
    "\n",
    "    # 경기당 방어율 column 생성\n",
    "    df['ERA'] = df['ER'] * 27 / df['INN2']\n",
    "\n",
    "    df = df.drop(columns=['T_ID'])\n",
    "    df_year_team_name = df\n",
    "    \n",
    "    return df_year_team_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 타자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "def team_hitter_eda(year, team_name):\n",
    "    year_index = year - 2016 \n",
    "    \n",
    "    # team_hitter data에 해당 경기의 해당 팀의 홈 어웨이 여부 column 추가\n",
    "    data_games_year = data_games[year_index]\n",
    "    data_games_year = data_games_year[['G_ID', 'VISIT_KEY', 'HOME_KEY']]\n",
    "    data_games_year = data_games_year.set_index('G_ID')\n",
    "    \n",
    "    data_team_hitter_year = data_team_hitter[year_index]\n",
    "    data_team_hitter_year = pd.merge(data_team_hitter_year, data_games_year, how='left', on=['G_ID'])\n",
    "\n",
    "    data_team_hitter_year_team = data_team_hitter_year[data_team_hitter_year.T_ID == team_name]\n",
    "    df = data_team_hitter_year_team\n",
    "    df['HOME_KEY'] = df['HOME_KEY'].map(lambda x: 1 if x == team_name else 0 )\n",
    "    df = df.drop(columns = ['VISIT_KEY', 'G_ID'])\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True) #index 재정렬\n",
    "    \n",
    "    # LabelEncoding\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    df['VS_T_ID'] = encoder.fit_transform(df['VS_T_ID']) #상대편\n",
    "    df['TB_SC'] = encoder.fit_transform(df['TB_SC']) #이닝 초/말\n",
    "    \n",
    "    \n",
    "    ### 이부분은 모든 EDA에서 동일하게 작성\n",
    "    \n",
    "    # GDAY_DS => Datetime type\n",
    "    df['GDAY_DS'] = df['GDAY_DS'].astype(str) + (df['HEADER_NO']+1).astype(str)\n",
    "    df['year']=df['GDAY_DS'].str.slice(0,4).astype(int)\n",
    "    df['month']=df['GDAY_DS'].str.slice(4,6).astype(int)\n",
    "    df['H1']=df['HIT']-df['H2']-df['H3']-df['HR']\n",
    "    dt = []\n",
    "    for i in df['GDAY_DS']:\n",
    "        dt_ = datetime.strptime(i, '%Y%m%d%H')\n",
    "        dt.append(dt_)\n",
    "    df['GDAY_DS'] = pd.Series(dt)\n",
    "    df['month']=df['GDAY_DS'].apply(lambda x: x.month)\n",
    "    \n",
    "    #장타율\n",
    "    df['SLG']=(df['HIT']+df['HP']+df['BB'])/(df['AB']+df['BB']+df['HP']+df['SF'])\n",
    "    #출루율\n",
    "    df['OBA']=(df['H1']+2*df['H2']+3*df['H3']+4*df['HR'])/df['AB']\n",
    "    df['W_OPS']=0.57* df['SLG']+0.43*df['OBA']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = df.drop(columns=['T_ID'])\n",
    "    #lags\n",
    "    #lags=[1,4,6,12,30,60]\n",
    "    #for lag in lags:\n",
    "    #    df['AVG_lag_'+str(lag)]=df['AVG'].shift(lag).astype(np.float16)\n",
    "    #SK Expanding window 추가\n",
    "    #df['expanding_AVG_mean']=df['AVG'].transform(lambda x: x.expanding(2).mean().astype(np.float16))\n",
    "    #rolling window\n",
    "    #df['rolling_AVG_mean']=df['AVG'].transform(lambda x: x.rolling(window=7).mean().astype(np.float16))\n",
    "    #trend\n",
    "    \n",
    "    # 경기당 타율 column 생성\n",
    "    df['AVG'] = df['HIT'] / df['AB']\n",
    "    \n",
    "    df['avg_AVG'] = df['AVG'].mean()\n",
    "    df['AVG_trend'] = (df['AVG'] - df['avg_AVG']).astype(np.float16)\n",
    "    df.drop(['avg_AVG'],axis=1,inplace=True)\n",
    "    \n",
    "    # Drop Categorical feature for 시계열 => coint 과정에서 singular matrix 발생\n",
    "    df = df.drop(columns=[ 'HOME_KEY'])\n",
    "    \n",
    "\n",
    "#     df = df.drop(columns=['T_ID', 'HEADER_NO', 'CG_CK', 'BK'])\n",
    "#     df = df.drop(columns=['TB_SC', 'HR', 'SB', 'VS_T_ID', 'HOME_KEY', 'HOLD', 'INN2', 'BF', 'CS', 'SH', 'HP', 'GD', 'ERR' ,'ER'])\n",
    "    df_year_team_name = df\n",
    "    \n",
    "    return df_year_team_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 승률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_win_eda(year, team_name):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_year_team_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mae(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    abs_val = abs(difference)\n",
    "    \n",
    "    score = abs_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "def mse(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    sqr_val = difference ** 2\n",
    "    \n",
    "    score = sqr_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def plot_train_test_pred_graph(trainset, testset, pred):\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(trainset.ERA, label='train')\n",
    "    plt.plot(testset.ERA, label='test')\n",
    "    plt.plot(testset.index, pred, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얘는 쓰지 않음\n",
    "def predict_columns(data_frame, x_cols, y_col):\n",
    "    size = int(len(data_frame) * 0.7)\n",
    "    train = data_frame[:size]\n",
    "    test = data_frame[size:]\n",
    "    \n",
    "    reg_models = [LinearRegression(), Ridge(), Lasso(), ElasticNet(), GradientBoostingRegressor(), SVR(), XGBRegressor(), LGBMRegressor()]\n",
    "    reg_model_names = [\"LinearRegression\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"GradientBoositng\", \" SupportVector\", \"XGBoost\",\"lgbm\"]\n",
    "\n",
    "    for i in range(len(reg_models)):\n",
    "        reg = reg_models[i].fit(train[x_cols], train[y_col])\n",
    "        pred = reg_models[i].predict(test[x_cols])\n",
    "        print('{} : {}'.format(reg_model_names[i], mae(test[y_col], pred.astype(int))))\n",
    "        #print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 지정\n",
    "\n",
    "params_grid = {\n",
    "    'num_leaves': [5,10,20,30],\n",
    "    'reg_alpha': [0.1, 0.5],\n",
    "    'min_data_in_leaf': [10,30, 50, 100],\n",
    "    'lambda_l1': [0, 1, 1.5],\n",
    "    'lambda_l2': [0, 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 투수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_pitcher_modeling(score, t):\n",
    "    df_2016 = team_pitcher_eda(2016, t)\n",
    "    df_2017 = team_pitcher_eda(2017, t)\n",
    "    df_2018 = team_pitcher_eda(2018, t)\n",
    "    df_2019 = team_pitcher_eda(2019, t)\n",
    "    df_2020 = team_pitcher_eda(2020, t)\n",
    "    \n",
    "    df_all = pd.concat([df_2016,df_2017,df_2018,df_2019,df_2020])\n",
    "    df_all =df_all.reset_index()\n",
    "    \n",
    "    df_all['ym']=df_all['G_ID'].str.slice(0,6)\n",
    "\n",
    "    a=df_all['ym'].unique()\n",
    "    b=list(range(len(a)))\n",
    "    list_C = [ x for x in zip(a,b) ]\n",
    "    dict1=dict(list_C)\n",
    "\n",
    "    df_all['dummy']=df_all['ym'].map(dict1)\n",
    "    df_all['dummy+1']=df_all['dummy']+1\n",
    "\n",
    "    y_dict=df_all.groupby(['dummy'])['ERA'].mean().to_dict()\n",
    "\n",
    "    df_all['y_next']=df_all['dummy+1'].map(y_dict)\n",
    "    df_all.drop(['dummy','dummy+1','ym'],axis=1,inplace=True)\n",
    "    \n",
    "    # 테스트용 데이터 뽑기\n",
    "    final_test = df_all[df_all['y_next'].isnull()]; \n",
    "    \n",
    "    df_all.dropna(inplace=True)#일단 드랍하고 진행\n",
    "    \n",
    "    df_all=df_all.drop(['G_ID'],axis=1)\n",
    "\n",
    "    # 범주형 변수 지정\n",
    "    cat_features = ['VS_T_ID' ,'HEADER_NO', 'TB_SC' ]\n",
    "    df_all[cat_features] = df_all[cat_features].astype('category')\n",
    "\n",
    "    # X,y Train split\n",
    "    X = df_all.drop(columns = ['y_next'])\n",
    "    y = df_all['y_next']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, shuffle = True, random_state = 2020)\n",
    " \n",
    "    X_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\n",
    "    X_val.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_val.columns]\n",
    "\n",
    "    \n",
    "    # 이부분 수정 필요\n",
    "    lgb = LGBMRegressor(boosting_type='gbdt', num_boost_round=2000, learning_rate=0.01)\n",
    "    lgb_grid = GridSearchCV(estimator=lgb,\n",
    "                        param_grid=params_grid,\n",
    "                        n_jobs=10,\n",
    "                        verbose=3)\n",
    "    lgb_grid.fit(X_train,y_train) \n",
    "    \n",
    "    final_test = final_test.drop(['G_ID','y_next'],axis=1)\n",
    "    final_test[cat_features] = final_test[cat_features].astype('category')\n",
    "    \n",
    "    final_predict = lgb_grid.predict(final_test)\n",
    "\n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 타자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_hitter_modeling(score, t):\n",
    "    df_2016 = team_hitter_eda(2016, t)\n",
    "    df_2017 = team_hitter_eda(2017, t)\n",
    "    df_2018 = team_hitter_eda(2018, t)\n",
    "    df_2019 = team_hitter_eda(2019, t)\n",
    "    df_2020 = team_hitter_eda(2020, t)\n",
    "    \n",
    "    df_all = pd.concat([df_2016,df_2017,df_2018,df_2019,df_2020])\n",
    "    df_all =df_all.reset_index()\n",
    "    \n",
    "    df_all['ym']=df_all['GDAY_DS'].apply(lambda x: str(x.year)+str(x.month))\n",
    "\n",
    "    a=df_all['GDAY_DS'].apply(lambda x: str(x.year)+str(x.month)).unique()\n",
    "    b=list(range(len(a)))\n",
    "    list_C = [ x for x in zip(a,b) ]\n",
    "    dict1=dict(list_C)\n",
    "\n",
    "    df_all['dummy']=df_all['ym'].map(dict1)\n",
    "\n",
    "    df_all['dummy+1']=df_all['dummy']+1\n",
    "\n",
    "    y_dict=df_all.groupby(['dummy'])['AVG'].mean().to_dict()\n",
    "\n",
    "    df_all['y_next']=df_all['dummy+1'].map(y_dict)\n",
    "\n",
    "    df_all.drop(['dummy','dummy+1','ym'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    # 테스트용 데이터 뽑기\n",
    "    final_test = df_all[df_all['y_next'].isnull()]; \n",
    "    \n",
    "    df_all.dropna(inplace=True)#일단 드랍하고 진행\n",
    "    \n",
    "    df_all = df_all.drop(['GDAY_DS'],axis=1)\n",
    "\n",
    "    # 범주형 변수 지정\n",
    "    cat_features = ['VS_T_ID' ,'HEADER_NO', 'TB_SC' ]\n",
    "    df_all[cat_features] = df_all[cat_features].astype('category')\n",
    "\n",
    "    # X,y Train test val split\n",
    "    X = df_all.drop(columns = ['y_next'])\n",
    "    y = df_all['y_next']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, shuffle = True, random_state = 2020)\n",
    " \n",
    "    X_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\n",
    "    X_val.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_val.columns]\n",
    "\n",
    "    \n",
    "    # 이부분 수정 필요\n",
    "    lgb = LGBMRegressor(boosting_type='gbdt', num_boost_round=2000, learning_rate=0.01)\n",
    "    lgb_grid = GridSearchCV(estimator=lgb,\n",
    "                        param_grid=params_grid,\n",
    "                        n_jobs=10,\n",
    "                        verbose=3)\n",
    "    lgb_grid.fit(X_train,y_train) \n",
    "    \n",
    "    print(final_test.columns)\n",
    "    print(df_all.columns)\n",
    "    final_test = final_test.drop(['GDAY_DS','y_next'],axis=1)\n",
    "    final_test[cat_features] = final_test[cat_features].astype('category')\n",
    "    \n",
    "    final_predict = lgb_grid.predict(final_test)\n",
    "\n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_list = ['WO','OB','NC','SK','LG','KT','LT','HT','SS','HH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팀별 최종 예측 방어율 (주어진 데이터 다음달)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in team_list:\n",
    "    print(t)\n",
    "    print(team_pitcher_modeling(\"mae\",t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팀별 최종 예측 타율 (주어진 데이터 다음달)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in team_list:\n",
    "    print(t)\n",
    "    print(team_hitter_modeling(\"mae\",t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팀별 최종 예측 승률 (주어진 데이터 다음달)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
