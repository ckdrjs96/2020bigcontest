{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# 회귀분석\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:/Users/KimMinyoung/desktop/깃헙관련/빅콘git/data/total'\n",
    "data_list = os.listdir(data_dir)\n",
    "#print(len(data_list))\n",
    "#print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#년도별 저장\n",
    "data_list_2016 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2016') ]\n",
    "data_2016 = [pd.read_csv(os.path.join(data_dir,data_list_2016[x]),encoding='cp949') for x in range(len(data_list_2016))]\n",
    "data_list_2017 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2017') ]\n",
    "data_2017 = [pd.read_csv(os.path.join(data_dir,data_list_2017[x]),encoding='cp949') for x in range(len(data_list_2017))]\n",
    "data_list_2018 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2018') ]\n",
    "data_2018 = [pd.read_csv(os.path.join(data_dir,data_list_2018[x]),encoding='cp949') for x in range(len(data_list_2018))]\n",
    "data_list_2019 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2019') ]\n",
    "data_2019 = [pd.read_csv(os.path.join(data_dir,data_list_2019[x]),encoding='cp949') for x in range(len(data_list_2019))]\n",
    "data_list_2020 = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-1].startswith('2020') ]\n",
    "data_2020 = [pd.read_csv(os.path.join(data_dir,data_list_2020[x]),encoding='cp949') for x in range(len(data_list_2020))]\n",
    "#print('2020년 데이터: \\n', data_2020)\n",
    "\n",
    "#항목별 저장\n",
    "data_list_single_hitter = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('개인타자')]\n",
    "data_single_hitter = [pd.read_csv(os.path.join(data_dir, data_list_single_hitter[x]), encoding='cp949') for x in range(len(data_list_single_hitter))]\n",
    "data_list_single_pitcher = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('개인투수')]\n",
    "data_single_pitcher = [pd.read_csv(os.path.join(data_dir, data_list_single_pitcher[x]), encoding='cp949') for x in range(len(data_list_single_pitcher))]\n",
    "data_list_games = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('경기')]\n",
    "data_games = [pd.read_csv(os.path.join(data_dir, data_list_games[x]), encoding='cp949') for x in range(len(data_list_games))]\n",
    "data_list_player_enroll = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('등록선수')]\n",
    "data_player_enroll = [pd.read_csv(os.path.join(data_dir, data_list_player_enroll[x]), encoding='cp949') for x in range(len(data_list_player_enroll))]\n",
    "data_list_players = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('선수')]\n",
    "data_players = [pd.read_csv(os.path.join(data_dir, data_list_players[x]), encoding='cp949') for x in range(len(data_list_players))]\n",
    "data_list_teams = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀')]\n",
    "data_teams = [pd.read_csv(os.path.join(data_dir, data_list_teams[x]), encoding='cp949') for x in range(len(data_list_teams))]\n",
    "data_list_team_hitter = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀타자')]\n",
    "data_team_hitter = [pd.read_csv(os.path.join(data_dir, data_list_team_hitter[x]), encoding='cp949') for x in range(len(data_list_team_hitter))]\n",
    "data_list_team_pitcher = [data_list[x] for x in range(len(data_list)) if data_list[x].split('_')[-2].startswith('팀투수')]\n",
    "data_team_pitcher = [pd.read_csv(os.path.join(data_dir, data_list_team_pitcher[x]), encoding='cp949') for x in range(len(data_list_team_pitcher))]\n",
    "#print('팀투수 데이터:\\n', data_team_pitcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def team_pitcher_eda(year, team_name):\n",
    "    year_index = year - 2016 \n",
    "    \n",
    "    # team_pitcher data에 해당 경기의 해당 팀의 홈 어웨이 여부 column 추가\n",
    "    data_games_year = data_games[year_index]\n",
    "    data_games_year = data_games_year[['G_ID', 'VISIT_KEY', 'HOME_KEY']]\n",
    "    data_games_year = data_games_year.set_index('G_ID')\n",
    "    \n",
    "    data_team_pitcher_year = data_team_pitcher[year_index]\n",
    "    data_team_pitcher_year = pd.merge(data_team_pitcher_year, data_games_year, how='left', on=['G_ID'])\n",
    "\n",
    "    data_team_pitcher_year_team = data_team_pitcher_year[data_team_pitcher_year.T_ID == team_name]\n",
    "    df = data_team_pitcher_year_team\n",
    "    df['HOME_KEY'] = df['HOME_KEY'].map(lambda x: 1 if x == team_name else 0 )\n",
    "    df = df.drop(columns = ['VISIT_KEY', 'GDAY_DS'])\n",
    "    \n",
    "    # LabelEncoding\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    df['VS_T_ID'] = encoder.fit_transform(df['VS_T_ID']) #상대편\n",
    "    df['TB_SC'] = encoder.fit_transform(df['TB_SC']) #이닝 초/말\n",
    "    df['WLS'] = encoder.fit_transform(df['WLS']) #승패무 여부\n",
    "    \n",
    "    \n",
    "    ### 이부분은 모든 EDA에서 동일하게 작성\n",
    "    \n",
    "    df['H1']=df['HIT']-df['H2']-df['H3']-df['HR']\n",
    "\n",
    "    #df['G_ID'] = pd.Series(dt)\n",
    "    df['year']=df['G_ID'].str.slice(0,4).astype(int)\n",
    "    df['month']=df['G_ID'].str.slice(4,6).astype(int)\n",
    "    \n",
    "    df[\"FIP\"] = ((13*df.HR+3*(df.BB+df.HP-df.IB)-2*df.KK)/(df.INN2/3)) +3.2\n",
    "    df[\"BABIP\"] = (df.HIT-df.HR)/(df.AB-df.KK-df.HR+df.SF)\n",
    "    df['SLG']=(df['HIT']+df['HP']+df['BB'])/(df['AB']+df['BB']+df['HP']+df['SF'])\n",
    "    df['OBA']=(df['H1']+2*df['H2']+3*df['H3']+4*df['HR'])/df['AB']\n",
    "    df['W_OPS']=0.57* df['SLG']+0.43*df['OBA']\n",
    "\n",
    "    # 시계열 데이터(경기당 방어율 계산)이기 때문에 경기 코드를 index로\n",
    "    df = df.set_index('G_ID')\n",
    "\n",
    "    # 경기당 방어율 column 생성\n",
    "    df['ERA'] = df['ER'] * 27 / df['INN2']\n",
    "\n",
    "    df = df.drop(columns=['T_ID'])\n",
    "    df_year_team_name = df\n",
    "    \n",
    "    return df_year_team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_LG = team_pitcher_eda(2016,'LG')\n",
    "df_2017_LG = team_pitcher_eda(2017,'LG')\n",
    "df_2018_LG = team_pitcher_eda(2018,'LG')\n",
    "df_2019_LG = team_pitcher_eda(2019,'LG')\n",
    "df_2020_LG = team_pitcher_eda(2020,'LG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_LG = pd.concat([df_2016_LG,df_2017_LG,df_2018_LG,df_2019_LG,df_2020_LG])\n",
    "df_all_LG =df_all_LG.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor에는 datatime을 사용할 수 없으므로 year, month를 생성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year = df_all_LG['G_ID'].str.slice(0,4).astype(int)\n",
    "#month = df_all_LG['G_ID'].str.slice(4,6).astype(int)\n",
    "#df_all_LG['year']=year\n",
    "#df_all_LG['month']=month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_ID</th>\n",
       "      <th>VS_T_ID</th>\n",
       "      <th>HEADER_NO</th>\n",
       "      <th>TB_SC</th>\n",
       "      <th>CG_CK</th>\n",
       "      <th>WLS</th>\n",
       "      <th>HOLD</th>\n",
       "      <th>INN2</th>\n",
       "      <th>BF</th>\n",
       "      <th>PA</th>\n",
       "      <th>...</th>\n",
       "      <th>HOME_KEY</th>\n",
       "      <th>H1</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>FIP</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OBA</th>\n",
       "      <th>W_OPS</th>\n",
       "      <th>ERA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160401HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>184</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.283333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.326340</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160402HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>176</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.654545</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.383750</td>\n",
       "      <td>5.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160405LGHT0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.319055</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160407LGHT0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>137</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.361924</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160408LGSK0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3.613793</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.262385</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>20200715LGLT0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>139</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6.644444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>20200716LGLT0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>142</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.488714</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>20200717HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>145</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.166185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>20200718HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>149</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>4.422222</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.321208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>20200719HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.280525</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              G_ID  VS_T_ID  HEADER_NO  TB_SC  CG_CK  WLS  HOLD  INN2   BF  \\\n",
       "0    20160401HHLG0        0          0      0      0    2     0    36  184   \n",
       "1    20160402HHLG0        0          0      0      0    2     2    33  176   \n",
       "2    20160405LGHT0        1          0      1      0    1     0    24  123   \n",
       "3    20160407LGHT0        1          0      1      0    2     2    27  137   \n",
       "4    20160408LGSK0        6          0      1      0    1     0    29  142   \n",
       "..             ...      ...        ...    ...    ...  ...   ...   ...  ...   \n",
       "635  20200715LGLT0        3          0      1      0    2     0    27  139   \n",
       "636  20200716LGLT0        3          0      1      0    1     0    24  142   \n",
       "637  20200717HHLG0        0          0      0      0    2     0    27  145   \n",
       "638  20200718HHLG0        0          0      0      0    2     1    27  149   \n",
       "639  20200719HHLG0        0          0      0      0    2     0    27  129   \n",
       "\n",
       "     PA  ...  HOME_KEY  H1  year  month       FIP     BABIP       SLG  \\\n",
       "0    52  ...         1  11  2016      4  2.283333  0.361111  0.326531   \n",
       "1    50  ...         1   9  2016      4  2.654545  0.382353  0.375000   \n",
       "2    31  ...         0   4  2016      4  3.450000  0.294118  0.290323   \n",
       "3    37  ...         0   4  2016      4  2.866667  0.321429  0.324324   \n",
       "4    41  ...         0   8  2016      4  3.613793  0.242424  0.292683   \n",
       "..   ..  ...       ...  ..   ...    ...       ...       ...       ...   \n",
       "635  39  ...         0   9  2020      7  6.644444  0.333333  0.358974   \n",
       "636  42  ...         0  10  2020      7  5.450000  0.419355  0.404762   \n",
       "637  32  ...         1   2  2020      7  2.200000  0.150000  0.187500   \n",
       "638  37  ...         1   7  2020      7  4.422222  0.266667  0.351351   \n",
       "639  37  ...         1   6  2020      7  0.422222  0.380952  0.270270   \n",
       "\n",
       "          OBA     W_OPS       ERA  \n",
       "0    0.326087  0.326340  3.000000  \n",
       "1    0.395349  0.383750  5.727273  \n",
       "2    0.357143  0.319055  2.250000  \n",
       "3    0.411765  0.361924  4.000000  \n",
       "4    0.222222  0.262385  0.931034  \n",
       "..        ...       ...       ...  \n",
       "635  0.567568  0.448669  3.000000  \n",
       "636  0.600000  0.488714  9.000000  \n",
       "637  0.137931  0.166185  0.000000  \n",
       "638  0.281250  0.321208  1.000000  \n",
       "639  0.294118  0.280525  2.000000  \n",
       "\n",
       "[640 rows x 42 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_ID</th>\n",
       "      <th>VS_T_ID</th>\n",
       "      <th>HEADER_NO</th>\n",
       "      <th>TB_SC</th>\n",
       "      <th>CG_CK</th>\n",
       "      <th>WLS</th>\n",
       "      <th>HOLD</th>\n",
       "      <th>INN2</th>\n",
       "      <th>BF</th>\n",
       "      <th>PA</th>\n",
       "      <th>...</th>\n",
       "      <th>H1</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>FIP</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OBA</th>\n",
       "      <th>W_OPS</th>\n",
       "      <th>ERA</th>\n",
       "      <th>y_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160401HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>184</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.283333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.326340</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.506522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160402HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>176</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.654545</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.383750</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>5.506522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160405LGHT0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.319055</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>5.506522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160407LGHT0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>137</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.361924</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.506522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160408LGSK0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3.613793</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.262385</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>5.506522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>20200715LGLT0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>139</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6.644444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>20200716LGLT0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>142</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.488714</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>20200717HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>145</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.166185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>20200718HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>149</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>4.422222</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.321208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>20200719HHLG0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.280525</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              G_ID  VS_T_ID  HEADER_NO  TB_SC  CG_CK  WLS  HOLD  INN2   BF  \\\n",
       "0    20160401HHLG0        0          0      0      0    2     0    36  184   \n",
       "1    20160402HHLG0        0          0      0      0    2     2    33  176   \n",
       "2    20160405LGHT0        1          0      1      0    1     0    24  123   \n",
       "3    20160407LGHT0        1          0      1      0    2     2    27  137   \n",
       "4    20160408LGSK0        6          0      1      0    1     0    29  142   \n",
       "..             ...      ...        ...    ...    ...  ...   ...   ...  ...   \n",
       "635  20200715LGLT0        3          0      1      0    2     0    27  139   \n",
       "636  20200716LGLT0        3          0      1      0    1     0    24  142   \n",
       "637  20200717HHLG0        0          0      0      0    2     0    27  145   \n",
       "638  20200718HHLG0        0          0      0      0    2     1    27  149   \n",
       "639  20200719HHLG0        0          0      0      0    2     0    27  129   \n",
       "\n",
       "     PA  ...  H1  year  month       FIP     BABIP       SLG       OBA  \\\n",
       "0    52  ...  11  2016      4  2.283333  0.361111  0.326531  0.326087   \n",
       "1    50  ...   9  2016      4  2.654545  0.382353  0.375000  0.395349   \n",
       "2    31  ...   4  2016      4  3.450000  0.294118  0.290323  0.357143   \n",
       "3    37  ...   4  2016      4  2.866667  0.321429  0.324324  0.411765   \n",
       "4    41  ...   8  2016      4  3.613793  0.242424  0.292683  0.222222   \n",
       "..   ..  ...  ..   ...    ...       ...       ...       ...       ...   \n",
       "635  39  ...   9  2020      7  6.644444  0.333333  0.358974  0.567568   \n",
       "636  42  ...  10  2020      7  5.450000  0.419355  0.404762  0.600000   \n",
       "637  32  ...   2  2020      7  2.200000  0.150000  0.187500  0.137931   \n",
       "638  37  ...   7  2020      7  4.422222  0.266667  0.351351  0.281250   \n",
       "639  37  ...   6  2020      7  0.422222  0.380952  0.270270  0.294118   \n",
       "\n",
       "        W_OPS       ERA    y_next  \n",
       "0    0.326340  3.000000  5.506522  \n",
       "1    0.383750  5.727273  5.506522  \n",
       "2    0.319055  2.250000  5.506522  \n",
       "3    0.361924  4.000000  5.506522  \n",
       "4    0.262385  0.931034  5.506522  \n",
       "..        ...       ...       ...  \n",
       "635  0.448669  3.000000       NaN  \n",
       "636  0.488714  9.000000       NaN  \n",
       "637  0.166185  0.000000       NaN  \n",
       "638  0.321208  1.000000       NaN  \n",
       "639  0.280525  2.000000       NaN  \n",
       "\n",
       "[640 rows x 43 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_LG['ym']=df_all_LG['G_ID'].str.slice(0,6)\n",
    "\n",
    "a=df_all_LG['ym'].unique()\n",
    "b=list(range(len(a)))\n",
    "list_C = [ x for x in zip(a,b) ]\n",
    "dict1=dict(list_C)\n",
    "dict1\n",
    "\n",
    "df_all_LG['dummy']=df_all_LG['ym'].map(dict1)\n",
    "df_all_LG['dummy+1']=df_all_LG['dummy']+1\n",
    "\n",
    "y_dict=df_all_LG.groupby(['dummy'])['ERA'].mean().to_dict()\n",
    "y_dict\n",
    "\n",
    "df_all_LG['y_next']=df_all_LG['dummy+1'].map(y_dict)\n",
    "df_all_LG.drop(['dummy','dummy+1','ym'],axis=1,inplace=True)\n",
    "\n",
    "df_all_LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_LG.dropna(inplace=True)#일단 드랍하고 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mae(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    abs_val = abs(difference)\n",
    "    \n",
    "    score = abs_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "mae_scorer = make_scorer(mae)\n",
    "mae_scorer\n",
    "def mse(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    sqr_val = difference ** 2\n",
    "    \n",
    "    score = sqr_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "mse_scorer = make_scorer(mse)\n",
    "mse_scorer\n",
    "\n",
    "def plot_train_test_pred_graph(trainset, testset, pred):\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(trainset.ERA, label='train')\n",
    "    plt.plot(testset.ERA, label='test')\n",
    "    plt.plot(testset.index, pred, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_LG=df_all_LG.drop(['G_ID','ERA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_all_LG.iloc[:200]\n",
    "valid=df_all_LG.iloc[200:300]\n",
    "test=df_all_LG.iloc[300:]\n",
    "\n",
    "X_train,y_train=train.drop(['y_next'],axis=1),train['y_next']\n",
    "X_valid,y_valid=valid.drop(['y_next'],axis=1),valid['y_next']\n",
    "X_test,y_test=test.drop(['y_next'],axis=1),test['y_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 0.9046\ttraining's l2: 0.818302\tvalid_1's rmse: 0.823249\tvalid_1's l2: 0.677739\n",
      "[2]\ttraining's rmse: 0.84874\ttraining's l2: 0.72036\tvalid_1's rmse: 0.853647\tvalid_1's l2: 0.728713\n",
      "[3]\ttraining's rmse: 0.800177\ttraining's l2: 0.640283\tvalid_1's rmse: 0.880044\tvalid_1's l2: 0.774478\n",
      "[4]\ttraining's rmse: 0.758565\ttraining's l2: 0.575421\tvalid_1's rmse: 0.90658\tvalid_1's l2: 0.821888\n",
      "[5]\ttraining's rmse: 0.7227\ttraining's l2: 0.522295\tvalid_1's rmse: 0.935937\tvalid_1's l2: 0.875978\n",
      "[6]\ttraining's rmse: 0.692234\ttraining's l2: 0.479187\tvalid_1's rmse: 0.951626\tvalid_1's l2: 0.905592\n",
      "[7]\ttraining's rmse: 0.666217\ttraining's l2: 0.443845\tvalid_1's rmse: 0.974787\tvalid_1's l2: 0.950209\n",
      "[8]\ttraining's rmse: 0.644064\ttraining's l2: 0.414819\tvalid_1's rmse: 0.99959\tvalid_1's l2: 0.99918\n",
      "[9]\ttraining's rmse: 0.625212\ttraining's l2: 0.39089\tvalid_1's rmse: 1.02195\tvalid_1's l2: 1.04438\n",
      "[10]\ttraining's rmse: 0.609097\ttraining's l2: 0.371\tvalid_1's rmse: 1.03609\tvalid_1's l2: 1.07348\n",
      "[11]\ttraining's rmse: 0.595563\ttraining's l2: 0.354695\tvalid_1's rmse: 1.05576\tvalid_1's l2: 1.11464\n",
      "[12]\ttraining's rmse: 0.583964\ttraining's l2: 0.341014\tvalid_1's rmse: 1.07323\tvalid_1's l2: 1.15182\n",
      "[13]\ttraining's rmse: 0.574004\ttraining's l2: 0.32948\tvalid_1's rmse: 1.08299\tvalid_1's l2: 1.17286\n",
      "[14]\ttraining's rmse: 0.565478\ttraining's l2: 0.319765\tvalid_1's rmse: 1.08833\tvalid_1's l2: 1.18446\n",
      "[15]\ttraining's rmse: 0.558238\ttraining's l2: 0.31163\tvalid_1's rmse: 1.10192\tvalid_1's l2: 1.21423\n",
      "[16]\ttraining's rmse: 0.551953\ttraining's l2: 0.304652\tvalid_1's rmse: 1.11211\tvalid_1's l2: 1.23678\n",
      "[17]\ttraining's rmse: 0.546539\ttraining's l2: 0.298704\tvalid_1's rmse: 1.11759\tvalid_1's l2: 1.249\n",
      "[18]\ttraining's rmse: 0.539127\ttraining's l2: 0.290658\tvalid_1's rmse: 1.12696\tvalid_1's l2: 1.27005\n",
      "[19]\ttraining's rmse: 0.533204\ttraining's l2: 0.284306\tvalid_1's rmse: 1.13389\tvalid_1's l2: 1.28571\n",
      "[20]\ttraining's rmse: 0.526324\ttraining's l2: 0.277017\tvalid_1's rmse: 1.13776\tvalid_1's l2: 1.29449\n",
      "[21]\ttraining's rmse: 0.521797\ttraining's l2: 0.272272\tvalid_1's rmse: 1.14848\tvalid_1's l2: 1.31902\n",
      "[22]\ttraining's rmse: 0.517906\ttraining's l2: 0.268227\tvalid_1's rmse: 1.15776\tvalid_1's l2: 1.3404\n",
      "[23]\ttraining's rmse: 0.511267\ttraining's l2: 0.261394\tvalid_1's rmse: 1.17051\tvalid_1's l2: 1.37009\n",
      "[24]\ttraining's rmse: 0.505824\ttraining's l2: 0.255857\tvalid_1's rmse: 1.18228\tvalid_1's l2: 1.39778\n",
      "[25]\ttraining's rmse: 0.501061\ttraining's l2: 0.251062\tvalid_1's rmse: 1.19096\tvalid_1's l2: 1.41839\n",
      "[26]\ttraining's rmse: 0.49558\ttraining's l2: 0.245599\tvalid_1's rmse: 1.19069\tvalid_1's l2: 1.41773\n",
      "[27]\ttraining's rmse: 0.490205\ttraining's l2: 0.240301\tvalid_1's rmse: 1.18808\tvalid_1's l2: 1.41153\n",
      "[28]\ttraining's rmse: 0.486053\ttraining's l2: 0.236247\tvalid_1's rmse: 1.18067\tvalid_1's l2: 1.39398\n",
      "[29]\ttraining's rmse: 0.48188\ttraining's l2: 0.232208\tvalid_1's rmse: 1.18058\tvalid_1's l2: 1.39376\n",
      "[30]\ttraining's rmse: 0.479332\ttraining's l2: 0.22976\tvalid_1's rmse: 1.18186\tvalid_1's l2: 1.39679\n",
      "[31]\ttraining's rmse: 0.475211\ttraining's l2: 0.225826\tvalid_1's rmse: 1.1788\tvalid_1's l2: 1.38956\n",
      "[32]\ttraining's rmse: 0.470919\ttraining's l2: 0.221764\tvalid_1's rmse: 1.17731\tvalid_1's l2: 1.38605\n",
      "[33]\ttraining's rmse: 0.468632\ttraining's l2: 0.219615\tvalid_1's rmse: 1.18225\tvalid_1's l2: 1.39771\n",
      "[34]\ttraining's rmse: 0.465664\ttraining's l2: 0.216843\tvalid_1's rmse: 1.1761\tvalid_1's l2: 1.38322\n",
      "[35]\ttraining's rmse: 0.461041\ttraining's l2: 0.212559\tvalid_1's rmse: 1.17547\tvalid_1's l2: 1.38174\n",
      "[36]\ttraining's rmse: 0.456505\ttraining's l2: 0.208397\tvalid_1's rmse: 1.17748\tvalid_1's l2: 1.38646\n",
      "[37]\ttraining's rmse: 0.451018\ttraining's l2: 0.203418\tvalid_1's rmse: 1.17641\tvalid_1's l2: 1.38394\n",
      "[38]\ttraining's rmse: 0.449107\ttraining's l2: 0.201697\tvalid_1's rmse: 1.17752\tvalid_1's l2: 1.38656\n",
      "[39]\ttraining's rmse: 0.444826\ttraining's l2: 0.19787\tvalid_1's rmse: 1.1869\tvalid_1's l2: 1.40874\n",
      "[40]\ttraining's rmse: 0.441347\ttraining's l2: 0.194787\tvalid_1's rmse: 1.1844\tvalid_1's l2: 1.40279\n",
      "[41]\ttraining's rmse: 0.438359\ttraining's l2: 0.192159\tvalid_1's rmse: 1.18797\tvalid_1's l2: 1.41126\n",
      "[42]\ttraining's rmse: 0.43573\ttraining's l2: 0.189861\tvalid_1's rmse: 1.18411\tvalid_1's l2: 1.40212\n",
      "[43]\ttraining's rmse: 0.433551\ttraining's l2: 0.187967\tvalid_1's rmse: 1.17874\tvalid_1's l2: 1.38943\n",
      "[44]\ttraining's rmse: 0.429198\ttraining's l2: 0.184211\tvalid_1's rmse: 1.17387\tvalid_1's l2: 1.37797\n",
      "[45]\ttraining's rmse: 0.427339\ttraining's l2: 0.182618\tvalid_1's rmse: 1.17901\tvalid_1's l2: 1.39007\n",
      "[46]\ttraining's rmse: 0.423685\ttraining's l2: 0.179509\tvalid_1's rmse: 1.18748\tvalid_1's l2: 1.41011\n",
      "[47]\ttraining's rmse: 0.42184\ttraining's l2: 0.177949\tvalid_1's rmse: 1.18242\tvalid_1's l2: 1.39812\n",
      "[48]\ttraining's rmse: 0.419129\ttraining's l2: 0.175669\tvalid_1's rmse: 1.17767\tvalid_1's l2: 1.38691\n",
      "[49]\ttraining's rmse: 0.415438\ttraining's l2: 0.172589\tvalid_1's rmse: 1.17473\tvalid_1's l2: 1.38\n",
      "[50]\ttraining's rmse: 0.413032\ttraining's l2: 0.170596\tvalid_1's rmse: 1.17133\tvalid_1's l2: 1.37201\n",
      "[51]\ttraining's rmse: 0.411271\ttraining's l2: 0.169144\tvalid_1's rmse: 1.17688\tvalid_1's l2: 1.38505\n",
      "[52]\ttraining's rmse: 0.409849\ttraining's l2: 0.167977\tvalid_1's rmse: 1.17318\tvalid_1's l2: 1.37636\n",
      "[53]\ttraining's rmse: 0.406847\ttraining's l2: 0.165525\tvalid_1's rmse: 1.18135\tvalid_1's l2: 1.3956\n",
      "[54]\ttraining's rmse: 0.404492\ttraining's l2: 0.163614\tvalid_1's rmse: 1.17889\tvalid_1's l2: 1.38979\n",
      "[55]\ttraining's rmse: 0.401033\ttraining's l2: 0.160827\tvalid_1's rmse: 1.18101\tvalid_1's l2: 1.39479\n",
      "[56]\ttraining's rmse: 0.399883\ttraining's l2: 0.159906\tvalid_1's rmse: 1.17755\tvalid_1's l2: 1.38662\n",
      "[57]\ttraining's rmse: 0.396234\ttraining's l2: 0.157001\tvalid_1's rmse: 1.17525\tvalid_1's l2: 1.38122\n",
      "[58]\ttraining's rmse: 0.393076\ttraining's l2: 0.154509\tvalid_1's rmse: 1.174\tvalid_1's l2: 1.37827\n",
      "[59]\ttraining's rmse: 0.390069\ttraining's l2: 0.152154\tvalid_1's rmse: 1.17967\tvalid_1's l2: 1.39162\n",
      "[60]\ttraining's rmse: 0.386739\ttraining's l2: 0.149567\tvalid_1's rmse: 1.18005\tvalid_1's l2: 1.39251\n",
      "[61]\ttraining's rmse: 0.384238\ttraining's l2: 0.147639\tvalid_1's rmse: 1.18217\tvalid_1's l2: 1.39752\n",
      "[62]\ttraining's rmse: 0.381617\ttraining's l2: 0.145632\tvalid_1's rmse: 1.18646\tvalid_1's l2: 1.40769\n",
      "[63]\ttraining's rmse: 0.378257\ttraining's l2: 0.143079\tvalid_1's rmse: 1.18598\tvalid_1's l2: 1.40655\n",
      "[64]\ttraining's rmse: 0.376796\ttraining's l2: 0.141975\tvalid_1's rmse: 1.18341\tvalid_1's l2: 1.40045\n",
      "[65]\ttraining's rmse: 0.373145\ttraining's l2: 0.139237\tvalid_1's rmse: 1.18105\tvalid_1's l2: 1.39487\n",
      "[66]\ttraining's rmse: 0.370751\ttraining's l2: 0.137456\tvalid_1's rmse: 1.18562\tvalid_1's l2: 1.4057\n",
      "[67]\ttraining's rmse: 0.368281\ttraining's l2: 0.135631\tvalid_1's rmse: 1.18613\tvalid_1's l2: 1.40692\n",
      "[68]\ttraining's rmse: 0.364561\ttraining's l2: 0.132905\tvalid_1's rmse: 1.18408\tvalid_1's l2: 1.40205\n",
      "[69]\ttraining's rmse: 0.361769\ttraining's l2: 0.130877\tvalid_1's rmse: 1.18543\tvalid_1's l2: 1.40524\n",
      "[70]\ttraining's rmse: 0.359452\ttraining's l2: 0.129205\tvalid_1's rmse: 1.19241\tvalid_1's l2: 1.42183\n",
      "[71]\ttraining's rmse: 0.358213\ttraining's l2: 0.128317\tvalid_1's rmse: 1.19003\tvalid_1's l2: 1.41617\n",
      "[72]\ttraining's rmse: 0.355677\ttraining's l2: 0.126506\tvalid_1's rmse: 1.18772\tvalid_1's l2: 1.41068\n",
      "[73]\ttraining's rmse: 0.353144\ttraining's l2: 0.12471\tvalid_1's rmse: 1.18605\tvalid_1's l2: 1.40671\n",
      "[74]\ttraining's rmse: 0.351837\ttraining's l2: 0.12379\tvalid_1's rmse: 1.18957\tvalid_1's l2: 1.41508\n",
      "[75]\ttraining's rmse: 0.349073\ttraining's l2: 0.121852\tvalid_1's rmse: 1.1887\tvalid_1's l2: 1.41302\n",
      "[76]\ttraining's rmse: 0.347102\ttraining's l2: 0.12048\tvalid_1's rmse: 1.19074\tvalid_1's l2: 1.41787\n",
      "[77]\ttraining's rmse: 0.34325\ttraining's l2: 0.117821\tvalid_1's rmse: 1.18724\tvalid_1's l2: 1.40954\n",
      "[78]\ttraining's rmse: 0.341968\ttraining's l2: 0.116942\tvalid_1's rmse: 1.18785\tvalid_1's l2: 1.41098\n",
      "[79]\ttraining's rmse: 0.339111\ttraining's l2: 0.114996\tvalid_1's rmse: 1.18614\tvalid_1's l2: 1.40693\n",
      "[80]\ttraining's rmse: 0.337893\ttraining's l2: 0.114171\tvalid_1's rmse: 1.19035\tvalid_1's l2: 1.41694\n",
      "[81]\ttraining's rmse: 0.335881\ttraining's l2: 0.112816\tvalid_1's rmse: 1.19667\tvalid_1's l2: 1.43202\n",
      "[82]\ttraining's rmse: 0.333703\ttraining's l2: 0.111358\tvalid_1's rmse: 1.19642\tvalid_1's l2: 1.43141\n",
      "[83]\ttraining's rmse: 0.331709\ttraining's l2: 0.110031\tvalid_1's rmse: 1.19544\tvalid_1's l2: 1.42908\n",
      "[84]\ttraining's rmse: 0.329844\ttraining's l2: 0.108797\tvalid_1's rmse: 1.19927\tvalid_1's l2: 1.43824\n",
      "[85]\ttraining's rmse: 0.32875\ttraining's l2: 0.108076\tvalid_1's rmse: 1.19714\tvalid_1's l2: 1.43314\n",
      "[86]\ttraining's rmse: 0.326149\ttraining's l2: 0.106373\tvalid_1's rmse: 1.1977\tvalid_1's l2: 1.43448\n",
      "[87]\ttraining's rmse: 0.323647\ttraining's l2: 0.104747\tvalid_1's rmse: 1.20088\tvalid_1's l2: 1.4421\n",
      "[88]\ttraining's rmse: 0.322606\ttraining's l2: 0.104074\tvalid_1's rmse: 1.19761\tvalid_1's l2: 1.43428\n",
      "[89]\ttraining's rmse: 0.320391\ttraining's l2: 0.102651\tvalid_1's rmse: 1.19685\tvalid_1's l2: 1.43245\n",
      "[90]\ttraining's rmse: 0.318326\ttraining's l2: 0.101331\tvalid_1's rmse: 1.1929\tvalid_1's l2: 1.42302\n",
      "[91]\ttraining's rmse: 0.317258\ttraining's l2: 0.100653\tvalid_1's rmse: 1.19679\tvalid_1's l2: 1.4323\n",
      "[92]\ttraining's rmse: 0.316166\ttraining's l2: 0.0999609\tvalid_1's rmse: 1.19727\tvalid_1's l2: 1.43345\n",
      "[93]\ttraining's rmse: 0.312992\ttraining's l2: 0.0979641\tvalid_1's rmse: 1.19462\tvalid_1's l2: 1.42712\n",
      "[94]\ttraining's rmse: 0.310168\ttraining's l2: 0.0962043\tvalid_1's rmse: 1.19321\tvalid_1's l2: 1.42375\n",
      "[95]\ttraining's rmse: 0.309156\ttraining's l2: 0.0955777\tvalid_1's rmse: 1.19677\tvalid_1's l2: 1.43225\n",
      "[96]\ttraining's rmse: 0.306979\ttraining's l2: 0.0942364\tvalid_1's rmse: 1.19605\tvalid_1's l2: 1.43053\n",
      "[97]\ttraining's rmse: 0.305161\ttraining's l2: 0.0931235\tvalid_1's rmse: 1.20002\tvalid_1's l2: 1.44004\n",
      "[98]\ttraining's rmse: 0.301969\ttraining's l2: 0.0911853\tvalid_1's rmse: 1.20078\tvalid_1's l2: 1.44187\n",
      "[99]\ttraining's rmse: 0.299917\ttraining's l2: 0.0899502\tvalid_1's rmse: 1.20003\tvalid_1's l2: 1.44007\n",
      "[100]\ttraining's rmse: 0.297298\ttraining's l2: 0.0883864\tvalid_1's rmse: 1.20239\tvalid_1's l2: 1.44575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "             eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l1: 0.674399\ttraining's l2: 0.818302\tvalid_1's l1: 0.631935\tvalid_1's l2: 0.677739\n",
      "[2]\ttraining's l1: 0.62572\ttraining's l2: 0.72036\tvalid_1's l1: 0.626784\tvalid_1's l2: 0.728713\n",
      "[3]\ttraining's l1: 0.582423\ttraining's l2: 0.640283\tvalid_1's l1: 0.633453\tvalid_1's l2: 0.774478\n",
      "[4]\ttraining's l1: 0.543455\ttraining's l2: 0.575421\tvalid_1's l1: 0.651719\tvalid_1's l2: 0.821888\n",
      "[5]\ttraining's l1: 0.507618\ttraining's l2: 0.522295\tvalid_1's l1: 0.675571\tvalid_1's l2: 0.875978\n",
      "[6]\ttraining's l1: 0.472153\ttraining's l2: 0.479187\tvalid_1's l1: 0.692762\tvalid_1's l2: 0.905592\n",
      "[7]\ttraining's l1: 0.443524\ttraining's l2: 0.443845\tvalid_1's l1: 0.713122\tvalid_1's l2: 0.950209\n",
      "[8]\ttraining's l1: 0.417103\ttraining's l2: 0.414819\tvalid_1's l1: 0.733268\tvalid_1's l2: 0.99918\n",
      "[9]\ttraining's l1: 0.394817\ttraining's l2: 0.39089\tvalid_1's l1: 0.750555\tvalid_1's l2: 1.04438\n",
      "[10]\ttraining's l1: 0.374377\ttraining's l2: 0.371\tvalid_1's l1: 0.760208\tvalid_1's l2: 1.07348\n",
      "[11]\ttraining's l1: 0.354753\ttraining's l2: 0.354695\tvalid_1's l1: 0.775129\tvalid_1's l2: 1.11464\n",
      "[12]\ttraining's l1: 0.338477\ttraining's l2: 0.341014\tvalid_1's l1: 0.787776\tvalid_1's l2: 1.15182\n",
      "[13]\ttraining's l1: 0.323464\ttraining's l2: 0.32948\tvalid_1's l1: 0.79354\tvalid_1's l2: 1.17286\n",
      "[14]\ttraining's l1: 0.306296\ttraining's l2: 0.319765\tvalid_1's l1: 0.802986\tvalid_1's l2: 1.18446\n",
      "[15]\ttraining's l1: 0.294794\ttraining's l2: 0.31163\tvalid_1's l1: 0.812249\tvalid_1's l2: 1.21423\n",
      "[16]\ttraining's l1: 0.28344\ttraining's l2: 0.304652\tvalid_1's l1: 0.820198\tvalid_1's l2: 1.23678\n",
      "[17]\ttraining's l1: 0.273781\ttraining's l2: 0.298704\tvalid_1's l1: 0.822526\tvalid_1's l2: 1.249\n",
      "[18]\ttraining's l1: 0.26738\ttraining's l2: 0.290658\tvalid_1's l1: 0.830795\tvalid_1's l2: 1.27005\n",
      "[19]\ttraining's l1: 0.263133\ttraining's l2: 0.284306\tvalid_1's l1: 0.837808\tvalid_1's l2: 1.28571\n",
      "[20]\ttraining's l1: 0.260308\ttraining's l2: 0.277017\tvalid_1's l1: 0.841345\tvalid_1's l2: 1.29449\n",
      "[21]\ttraining's l1: 0.251117\ttraining's l2: 0.272272\tvalid_1's l1: 0.8486\tvalid_1's l2: 1.31902\n",
      "[22]\ttraining's l1: 0.244178\ttraining's l2: 0.268227\tvalid_1's l1: 0.854411\tvalid_1's l2: 1.3404\n",
      "[23]\ttraining's l1: 0.236007\ttraining's l2: 0.261394\tvalid_1's l1: 0.86265\tvalid_1's l2: 1.37009\n",
      "[24]\ttraining's l1: 0.228863\ttraining's l2: 0.255857\tvalid_1's l1: 0.870065\tvalid_1's l2: 1.39778\n",
      "[25]\ttraining's l1: 0.222198\ttraining's l2: 0.251062\tvalid_1's l1: 0.87629\tvalid_1's l2: 1.41839\n",
      "[26]\ttraining's l1: 0.219705\ttraining's l2: 0.245599\tvalid_1's l1: 0.875845\tvalid_1's l2: 1.41773\n",
      "[27]\ttraining's l1: 0.218027\ttraining's l2: 0.240301\tvalid_1's l1: 0.872211\tvalid_1's l2: 1.41153\n",
      "[28]\ttraining's l1: 0.210819\ttraining's l2: 0.236247\tvalid_1's l1: 0.871539\tvalid_1's l2: 1.39398\n",
      "[29]\ttraining's l1: 0.211688\ttraining's l2: 0.232208\tvalid_1's l1: 0.871168\tvalid_1's l2: 1.39376\n",
      "[30]\ttraining's l1: 0.208952\ttraining's l2: 0.22976\tvalid_1's l1: 0.870334\tvalid_1's l2: 1.39679\n",
      "[31]\ttraining's l1: 0.208885\ttraining's l2: 0.225826\tvalid_1's l1: 0.866259\tvalid_1's l2: 1.38956\n",
      "[32]\ttraining's l1: 0.209222\ttraining's l2: 0.221764\tvalid_1's l1: 0.864131\tvalid_1's l2: 1.38605\n",
      "[33]\ttraining's l1: 0.206103\ttraining's l2: 0.219615\tvalid_1's l1: 0.868252\tvalid_1's l2: 1.39771\n",
      "[34]\ttraining's l1: 0.201236\ttraining's l2: 0.216843\tvalid_1's l1: 0.86873\tvalid_1's l2: 1.38322\n",
      "[35]\ttraining's l1: 0.19952\ttraining's l2: 0.212559\tvalid_1's l1: 0.868665\tvalid_1's l2: 1.38174\n",
      "[36]\ttraining's l1: 0.197389\ttraining's l2: 0.208397\tvalid_1's l1: 0.869358\tvalid_1's l2: 1.38646\n",
      "[37]\ttraining's l1: 0.195604\ttraining's l2: 0.203418\tvalid_1's l1: 0.867329\tvalid_1's l2: 1.38394\n",
      "[38]\ttraining's l1: 0.194616\ttraining's l2: 0.201697\tvalid_1's l1: 0.867498\tvalid_1's l2: 1.38656\n",
      "[39]\ttraining's l1: 0.191665\ttraining's l2: 0.19787\tvalid_1's l1: 0.874641\tvalid_1's l2: 1.40874\n",
      "[40]\ttraining's l1: 0.191592\ttraining's l2: 0.194787\tvalid_1's l1: 0.870472\tvalid_1's l2: 1.40279\n",
      "[41]\ttraining's l1: 0.191082\ttraining's l2: 0.192159\tvalid_1's l1: 0.87196\tvalid_1's l2: 1.41126\n",
      "[42]\ttraining's l1: 0.189877\ttraining's l2: 0.189861\tvalid_1's l1: 0.869719\tvalid_1's l2: 1.40212\n",
      "[43]\ttraining's l1: 0.186875\ttraining's l2: 0.187967\tvalid_1's l1: 0.869703\tvalid_1's l2: 1.38943\n",
      "[44]\ttraining's l1: 0.186922\ttraining's l2: 0.184211\tvalid_1's l1: 0.865376\tvalid_1's l2: 1.37797\n",
      "[45]\ttraining's l1: 0.18562\ttraining's l2: 0.182618\tvalid_1's l1: 0.869095\tvalid_1's l2: 1.39007\n",
      "[46]\ttraining's l1: 0.183197\ttraining's l2: 0.179509\tvalid_1's l1: 0.875201\tvalid_1's l2: 1.41011\n",
      "[47]\ttraining's l1: 0.180427\ttraining's l2: 0.177949\tvalid_1's l1: 0.874683\tvalid_1's l2: 1.39812\n",
      "[48]\ttraining's l1: 0.179417\ttraining's l2: 0.175669\tvalid_1's l1: 0.871681\tvalid_1's l2: 1.38691\n",
      "[49]\ttraining's l1: 0.179447\ttraining's l2: 0.172589\tvalid_1's l1: 0.868658\tvalid_1's l2: 1.38\n",
      "[50]\ttraining's l1: 0.179462\ttraining's l2: 0.170596\tvalid_1's l1: 0.86545\tvalid_1's l2: 1.37201\n",
      "[51]\ttraining's l1: 0.177256\ttraining's l2: 0.169144\tvalid_1's l1: 0.869482\tvalid_1's l2: 1.38505\n",
      "[52]\ttraining's l1: 0.17512\ttraining's l2: 0.167977\tvalid_1's l1: 0.869603\tvalid_1's l2: 1.37636\n",
      "[53]\ttraining's l1: 0.173517\ttraining's l2: 0.165525\tvalid_1's l1: 0.875384\tvalid_1's l2: 1.3956\n",
      "[54]\ttraining's l1: 0.173862\ttraining's l2: 0.163614\tvalid_1's l1: 0.873349\tvalid_1's l2: 1.38979\n",
      "[55]\ttraining's l1: 0.172228\ttraining's l2: 0.160827\tvalid_1's l1: 0.875368\tvalid_1's l2: 1.39479\n",
      "[56]\ttraining's l1: 0.170502\ttraining's l2: 0.159906\tvalid_1's l1: 0.875245\tvalid_1's l2: 1.38662\n",
      "[57]\ttraining's l1: 0.169499\ttraining's l2: 0.157001\tvalid_1's l1: 0.872544\tvalid_1's l2: 1.38122\n",
      "[58]\ttraining's l1: 0.169932\ttraining's l2: 0.154509\tvalid_1's l1: 0.869112\tvalid_1's l2: 1.37827\n",
      "[59]\ttraining's l1: 0.168196\ttraining's l2: 0.152154\tvalid_1's l1: 0.872499\tvalid_1's l2: 1.39162\n",
      "[60]\ttraining's l1: 0.166909\ttraining's l2: 0.149567\tvalid_1's l1: 0.872939\tvalid_1's l2: 1.39251\n",
      "[61]\ttraining's l1: 0.165599\ttraining's l2: 0.147639\tvalid_1's l1: 0.873858\tvalid_1's l2: 1.39752\n",
      "[62]\ttraining's l1: 0.164971\ttraining's l2: 0.145632\tvalid_1's l1: 0.876999\tvalid_1's l2: 1.40769\n",
      "[63]\ttraining's l1: 0.163789\ttraining's l2: 0.143079\tvalid_1's l1: 0.876118\tvalid_1's l2: 1.40655\n",
      "[64]\ttraining's l1: 0.163439\ttraining's l2: 0.141975\tvalid_1's l1: 0.874067\tvalid_1's l2: 1.40045\n",
      "[65]\ttraining's l1: 0.16298\ttraining's l2: 0.139237\tvalid_1's l1: 0.871641\tvalid_1's l2: 1.39487\n",
      "[66]\ttraining's l1: 0.162177\ttraining's l2: 0.137456\tvalid_1's l1: 0.875048\tvalid_1's l2: 1.4057\n",
      "[67]\ttraining's l1: 0.162144\ttraining's l2: 0.135631\tvalid_1's l1: 0.875076\tvalid_1's l2: 1.40692\n",
      "[68]\ttraining's l1: 0.160453\ttraining's l2: 0.132905\tvalid_1's l1: 0.872444\tvalid_1's l2: 1.40205\n",
      "[69]\ttraining's l1: 0.159628\ttraining's l2: 0.130877\tvalid_1's l1: 0.87373\tvalid_1's l2: 1.40524\n",
      "[70]\ttraining's l1: 0.158166\ttraining's l2: 0.129205\tvalid_1's l1: 0.877652\tvalid_1's l2: 1.42183\n",
      "[71]\ttraining's l1: 0.158302\ttraining's l2: 0.128317\tvalid_1's l1: 0.875912\tvalid_1's l2: 1.41617\n",
      "[72]\ttraining's l1: 0.157629\ttraining's l2: 0.126506\tvalid_1's l1: 0.874305\tvalid_1's l2: 1.41068\n",
      "[73]\ttraining's l1: 0.1575\ttraining's l2: 0.12471\tvalid_1's l1: 0.873042\tvalid_1's l2: 1.40671\n",
      "[74]\ttraining's l1: 0.156611\ttraining's l2: 0.12379\tvalid_1's l1: 0.875094\tvalid_1's l2: 1.41508\n",
      "[75]\ttraining's l1: 0.156649\ttraining's l2: 0.121852\tvalid_1's l1: 0.874044\tvalid_1's l2: 1.41302\n",
      "[76]\ttraining's l1: 0.15564\ttraining's l2: 0.12048\tvalid_1's l1: 0.875196\tvalid_1's l2: 1.41787\n",
      "[77]\ttraining's l1: 0.154161\ttraining's l2: 0.117821\tvalid_1's l1: 0.873207\tvalid_1's l2: 1.40954\n",
      "[78]\ttraining's l1: 0.15355\ttraining's l2: 0.116942\tvalid_1's l1: 0.872497\tvalid_1's l2: 1.41098\n",
      "[79]\ttraining's l1: 0.153171\ttraining's l2: 0.114996\tvalid_1's l1: 0.871011\tvalid_1's l2: 1.40693\n",
      "[80]\ttraining's l1: 0.152052\ttraining's l2: 0.114171\tvalid_1's l1: 0.873933\tvalid_1's l2: 1.41694\n",
      "[81]\ttraining's l1: 0.150629\ttraining's l2: 0.112816\tvalid_1's l1: 0.877989\tvalid_1's l2: 1.43202\n",
      "[82]\ttraining's l1: 0.150582\ttraining's l2: 0.111358\tvalid_1's l1: 0.877329\tvalid_1's l2: 1.43141\n",
      "[83]\ttraining's l1: 0.150444\ttraining's l2: 0.110031\tvalid_1's l1: 0.87584\tvalid_1's l2: 1.42908\n",
      "[84]\ttraining's l1: 0.149663\ttraining's l2: 0.108797\tvalid_1's l1: 0.879037\tvalid_1's l2: 1.43824\n",
      "[85]\ttraining's l1: 0.149433\ttraining's l2: 0.108076\tvalid_1's l1: 0.877307\tvalid_1's l2: 1.43314\n",
      "[86]\ttraining's l1: 0.148065\ttraining's l2: 0.106373\tvalid_1's l1: 0.877159\tvalid_1's l2: 1.43448\n",
      "[87]\ttraining's l1: 0.147937\ttraining's l2: 0.104747\tvalid_1's l1: 0.879223\tvalid_1's l2: 1.4421\n",
      "[88]\ttraining's l1: 0.147493\ttraining's l2: 0.104074\tvalid_1's l1: 0.876995\tvalid_1's l2: 1.43428\n",
      "[89]\ttraining's l1: 0.146774\ttraining's l2: 0.102651\tvalid_1's l1: 0.875626\tvalid_1's l2: 1.43245\n",
      "[90]\ttraining's l1: 0.146473\ttraining's l2: 0.101331\tvalid_1's l1: 0.872833\tvalid_1's l2: 1.42302\n",
      "[91]\ttraining's l1: 0.145579\ttraining's l2: 0.100653\tvalid_1's l1: 0.875237\tvalid_1's l2: 1.4323\n",
      "[92]\ttraining's l1: 0.14483\ttraining's l2: 0.0999609\tvalid_1's l1: 0.874507\tvalid_1's l2: 1.43345\n",
      "[93]\ttraining's l1: 0.143063\ttraining's l2: 0.0979641\tvalid_1's l1: 0.873914\tvalid_1's l2: 1.42712\n",
      "[94]\ttraining's l1: 0.143023\ttraining's l2: 0.0962043\tvalid_1's l1: 0.872326\tvalid_1's l2: 1.42375\n",
      "[95]\ttraining's l1: 0.142156\ttraining's l2: 0.0955777\tvalid_1's l1: 0.87426\tvalid_1's l2: 1.43225\n",
      "[96]\ttraining's l1: 0.141356\ttraining's l2: 0.0942364\tvalid_1's l1: 0.873274\tvalid_1's l2: 1.43053\n",
      "[97]\ttraining's l1: 0.14059\ttraining's l2: 0.0931235\tvalid_1's l1: 0.875506\tvalid_1's l2: 1.44004\n",
      "[98]\ttraining's l1: 0.138989\ttraining's l2: 0.0911853\tvalid_1's l1: 0.876971\tvalid_1's l2: 1.44187\n",
      "[99]\ttraining's l1: 0.138679\ttraining's l2: 0.0899502\tvalid_1's l1: 0.876269\tvalid_1's l2: 1.44007\n",
      "[100]\ttraining's l1: 0.137899\ttraining's l2: 0.0883864\tvalid_1's l1: 0.878714\tvalid_1's l2: 1.44575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "             eval_metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_columns(data_frame, x_cols, y_col):\n",
    "    size = int(len(data_frame) * 0.7)\n",
    "    train = data_frame[:size]\n",
    "    test = data_frame[size:]\n",
    "    \n",
    "    reg_models = [LinearRegression(), Ridge(), Lasso(), ElasticNet(), GradientBoostingRegressor(), SVR(), XGBRegressor(), LGBMRegressor()]\n",
    "    reg_model_names = [\"LinearRegression\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"GradientBoositng\", \" SupportVector\", \"XGBoost\",\"lgbm\"]\n",
    "\n",
    "    for i in range(len(reg_models)):\n",
    "        reg = reg_models[i].fit(train[x_cols], train[y_col])\n",
    "        pred = reg_models[i].predict(test[x_cols])\n",
    "        print('{} : {}'.format(reg_model_names[i], mae(test[y_col], pred.astype(int))))\n",
    "        #print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression : 0.6741098096678316\n",
      "Ridge : 0.6741098096678316\n",
      "Lasso : 0.6741098096678316\n",
      "ElasticNet : 0.6741098096678316\n",
      "GradientBoositng : 0.9882488984089616\n",
      " SupportVector : 0.6741098096678316\n",
      "XGBoost : 1.1330934155939039\n",
      "lgbm : 1.1426377880493015\n"
     ]
    }
   ],
   "source": [
    "predict_columns(df_all_LG, ['year', 'month'], 'y_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_x = df_all_LG.drop(['y_next'], axis=1)\n",
    "reg_y = df_all_LG['y_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression :0.8154000947654048\n",
      "Ridge :0.8154136306634004\n",
      "Lasso :0.8410076805106096\n",
      "ElasticNet :0.8410076805106096\n",
      "GradientBoositng :0.216829657623768\n",
      " SupportVector :0.8427029113780667\n",
      "XGBoost :0.000773530890605643\n",
      "lgbm :0.15053343925391333\n"
     ]
    }
   ],
   "source": [
    "size = int(len(df_all_LG) * 0.7)\n",
    "train = df_all_LG[:size]\n",
    "test = df_all_LG[size:]\n",
    "\n",
    "reg_models = [LinearRegression(), Ridge(), Lasso(), ElasticNet(), GradientBoostingRegressor(), SVR(), XGBRegressor(),LGBMRegressor()]\n",
    "reg_model_names = [\"LinearRegression\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"GradientBoositng\", \" SupportVector\", \"XGBoost\",\"lgbm\"]\n",
    "for i in range(len(reg_models)):\n",
    "    full_cols = -cross_val_score(reg_models[i], reg_x, reg_y, scoring=\"neg_mean_absolute_error\", cv=cv)\n",
    "    certain_cols = -cross_val_score(reg_models[i], reg_x[['year', 'month']], reg_y, scoring=\"neg_mean_absolute_error\", cv=cv)\n",
    "    \n",
    "    print(\"{} :{}\".format(reg_model_names[i], certain_cols.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 작아 오버피팅 가능성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 변경하면서 튜닝중.. + 피처 IMPORTANCE 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['VS_T_ID' ,'HEADER_NO', 'TB_SC' ]\n",
    "df_all_LG[cat_features] = df_all_LG[cat_features].astype('category')\n",
    "\n",
    "X = df_all_LG.drop(columns = ['y_next'])\n",
    "y = df_all_LG['y_next']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, shuffle = True, random_state = 2020)\n",
    "\n",
    "X_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\n",
    "X_val.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_val.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=10)]: Done 492 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='split',\n",
       "                                     learning_rate=0.01, max_depth=-1,\n",
       "                                     min_child_samples=20,\n",
       "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
       "                                     n_estimators=100, n_jobs=-1,\n",
       "                                     num_boost_round=2000, num_leaves=31,\n",
       "                                     objective=None, random_state=None,\n",
       "                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                     subsample=1.0, subsample_for_bin=200000,\n",
       "                                     subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=10,\n",
       "             param_grid={'lambda_l1': [0, 1, 1.5], 'lambda_l2': [0, 1],\n",
       "                         'min_data_in_leaf': [10, 30, 50, 100],\n",
       "                         'num_leaves': [5, 10, 20, 30],\n",
       "                         'reg_alpha': [0.1, 0.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid = {\n",
    "    'num_leaves': [5,10,20,30],\n",
    "    'reg_alpha': [0.1, 0.5],\n",
    "    'min_data_in_leaf': [10,30, 50, 100],\n",
    "    'lambda_l1': [0, 1, 1.5],\n",
    "    'lambda_l2': [0, 1]\n",
    "    }\n",
    "lgb = LGBMRegressor(boosting_type='gbdt', num_boost_round=2000, learning_rate=0.01)\n",
    "lgb_grid = GridSearchCV(estimator=lgb,\n",
    "                        param_grid=params_grid,\n",
    "                        n_jobs=10,\n",
    "                        verbose=3)\n",
    "lgb_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 1.5,\n",
       " 'lambda_l2': 1,\n",
       " 'min_data_in_leaf': 30,\n",
       " 'num_leaves': 5,\n",
       " 'reg_alpha': 0.1}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6184586578118412"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = lgb_grid.predict(X_val)\n",
    "\n",
    "lgbm_rmse = sqrt(mean_squared_error(y_val, y_pred1))\n",
    "lgbm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3824911114224241"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_mse = mean_squared_error(y_val, y_pred1)\n",
    "lgbm_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month         2899\n",
       "year          2337\n",
       "BF            1810\n",
       "P2_WHIP_RT    1605\n",
       "P_WHIP_RT     1512\n",
       "BABIP         1423\n",
       "FIP           1362\n",
       "W_OPS         1146\n",
       "SLG           1075\n",
       "OBA           1029\n",
       "VS_T_ID        788\n",
       "CB_WHIP_RT     750\n",
       "AB             733\n",
       "KK             713\n",
       "PA             570\n",
       "R              415\n",
       "BB             386\n",
       "H1             375\n",
       "HP             363\n",
       "WP             343\n",
       "TB_SC          288\n",
       "SH             265\n",
       "GD             247\n",
       "ER             204\n",
       "HIT            182\n",
       "H2             157\n",
       "SB             144\n",
       "IB             124\n",
       "HOLD           117\n",
       "SF              99\n",
       "WLS             70\n",
       "H3              36\n",
       "INN2            28\n",
       "HR              17\n",
       "ERR             17\n",
       "CS               0\n",
       "HOME_KEY         0\n",
       "BK               0\n",
       "CG_CK            0\n",
       "HEADER_NO        0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_feature_importance = lgb_grid.best_estimator_.feature_importances_\n",
    "lgb_feature_imp=pd.Series(lgb_feature_importance,index=X_train.columns).sort_values(ascending=False)\n",
    "lgb_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2154dbccc08>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Light GBM feature Importance For Pitchers\")\n",
    "sns.barplot(x=lgb_feature_imp[0:30], y=lgb_feature_imp.index[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_all_LG.iloc[:200]\n",
    "valid=df_all_LG.iloc[200:300]\n",
    "test=df_all_LG.iloc[300:]\n",
    "\n",
    "X_train,y_train=train.drop(['y_next'],axis=1),train['y_next']\n",
    "X_valid,y_valid=valid.drop(['y_next'],axis=1),valid['y_next']\n",
    "X_test,y_test=test.drop(['y_next'],axis=1),test['y_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l1: 0.674399\ttraining's l2: 0.818302\tvalid_1's l1: 0.631935\tvalid_1's l2: 0.677739\n",
      "[2]\ttraining's l1: 0.62572\ttraining's l2: 0.72036\tvalid_1's l1: 0.626784\tvalid_1's l2: 0.728713\n",
      "[3]\ttraining's l1: 0.58191\ttraining's l2: 0.641027\tvalid_1's l1: 0.641264\tvalid_1's l2: 0.782607\n",
      "[4]\ttraining's l1: 0.539227\ttraining's l2: 0.576734\tvalid_1's l1: 0.651126\tvalid_1's l2: 0.813859\n",
      "[5]\ttraining's l1: 0.503587\ttraining's l2: 0.524236\tvalid_1's l1: 0.671665\tvalid_1's l2: 0.868239\n",
      "[6]\ttraining's l1: 0.472681\ttraining's l2: 0.481286\tvalid_1's l1: 0.688641\tvalid_1's l2: 0.90804\n",
      "[7]\ttraining's l1: 0.445198\ttraining's l2: 0.446166\tvalid_1's l1: 0.709534\tvalid_1's l2: 0.957981\n",
      "[8]\ttraining's l1: 0.418841\ttraining's l2: 0.417323\tvalid_1's l1: 0.729639\tvalid_1's l2: 1.00677\n",
      "[9]\ttraining's l1: 0.396195\ttraining's l2: 0.393474\tvalid_1's l1: 0.741117\tvalid_1's l2: 1.03894\n",
      "[10]\ttraining's l1: 0.371703\ttraining's l2: 0.373837\tvalid_1's l1: 0.755842\tvalid_1's l2: 1.06043\n",
      "[11]\ttraining's l1: 0.353631\ttraining's l2: 0.35745\tvalid_1's l1: 0.769874\tvalid_1's l2: 1.10021\n",
      "[12]\ttraining's l1: 0.337018\ttraining's l2: 0.343895\tvalid_1's l1: 0.777047\tvalid_1's l2: 1.12412\n",
      "[13]\ttraining's l1: 0.320871\ttraining's l2: 0.332591\tvalid_1's l1: 0.789296\tvalid_1's l2: 1.15985\n",
      "[14]\ttraining's l1: 0.308075\ttraining's l2: 0.322997\tvalid_1's l1: 0.799569\tvalid_1's l2: 1.19203\n",
      "[15]\ttraining's l1: 0.296252\ttraining's l2: 0.314964\tvalid_1's l1: 0.803611\tvalid_1's l2: 1.20868\n",
      "[16]\ttraining's l1: 0.281856\ttraining's l2: 0.308143\tvalid_1's l1: 0.811189\tvalid_1's l2: 1.21669\n",
      "[17]\ttraining's l1: 0.272522\ttraining's l2: 0.302254\tvalid_1's l1: 0.818719\tvalid_1's l2: 1.24231\n",
      "[18]\ttraining's l1: 0.266162\ttraining's l2: 0.294398\tvalid_1's l1: 0.826912\tvalid_1's l2: 1.26361\n",
      "[19]\ttraining's l1: 0.256625\ttraining's l2: 0.289701\tvalid_1's l1: 0.83419\tvalid_1's l2: 1.28756\n",
      "[20]\ttraining's l1: 0.251609\ttraining's l2: 0.283811\tvalid_1's l1: 0.840324\tvalid_1's l2: 1.30369\n",
      "[21]\ttraining's l1: 0.246375\ttraining's l2: 0.275834\tvalid_1's l1: 0.84692\tvalid_1's l2: 1.32755\n",
      "[22]\ttraining's l1: 0.243701\ttraining's l2: 0.270414\tvalid_1's l1: 0.847651\tvalid_1's l2: 1.33055\n",
      "[23]\ttraining's l1: 0.23685\ttraining's l2: 0.266737\tvalid_1's l1: 0.848378\tvalid_1's l2: 1.33792\n",
      "[24]\ttraining's l1: 0.230026\ttraining's l2: 0.260768\tvalid_1's l1: 0.855964\tvalid_1's l2: 1.36588\n",
      "[25]\ttraining's l1: 0.222225\ttraining's l2: 0.256555\tvalid_1's l1: 0.855776\tvalid_1's l2: 1.34969\n",
      "[26]\ttraining's l1: 0.216692\ttraining's l2: 0.251914\tvalid_1's l1: 0.862372\tvalid_1's l2: 1.3748\n",
      "[27]\ttraining's l1: 0.210333\ttraining's l2: 0.248652\tvalid_1's l1: 0.861708\tvalid_1's l2: 1.35923\n",
      "[28]\ttraining's l1: 0.208155\ttraining's l2: 0.244062\tvalid_1's l1: 0.862569\tvalid_1's l2: 1.36154\n",
      "[29]\ttraining's l1: 0.203277\ttraining's l2: 0.241457\tvalid_1's l1: 0.862017\tvalid_1's l2: 1.348\n",
      "[30]\ttraining's l1: 0.204683\ttraining's l2: 0.237946\tvalid_1's l1: 0.859469\tvalid_1's l2: 1.3425\n",
      "[31]\ttraining's l1: 0.202216\ttraining's l2: 0.235797\tvalid_1's l1: 0.858746\tvalid_1's l2: 1.34513\n",
      "[32]\ttraining's l1: 0.199016\ttraining's l2: 0.231406\tvalid_1's l1: 0.866675\tvalid_1's l2: 1.36847\n",
      "[33]\ttraining's l1: 0.195877\ttraining's l2: 0.229427\tvalid_1's l1: 0.866605\tvalid_1's l2: 1.35536\n",
      "[34]\ttraining's l1: 0.194276\ttraining's l2: 0.225112\tvalid_1's l1: 0.864651\tvalid_1's l2: 1.35101\n",
      "[35]\ttraining's l1: 0.19393\ttraining's l2: 0.221058\tvalid_1's l1: 0.862183\tvalid_1's l2: 1.34953\n",
      "[36]\ttraining's l1: 0.1915\ttraining's l2: 0.215495\tvalid_1's l1: 0.86011\tvalid_1's l2: 1.3467\n",
      "[37]\ttraining's l1: 0.189037\ttraining's l2: 0.212079\tvalid_1's l1: 0.867053\tvalid_1's l2: 1.36826\n",
      "[38]\ttraining's l1: 0.186634\ttraining's l2: 0.210629\tvalid_1's l1: 0.866642\tvalid_1's l2: 1.35725\n",
      "[39]\ttraining's l1: 0.184571\ttraining's l2: 0.205881\tvalid_1's l1: 0.86168\tvalid_1's l2: 1.34773\n",
      "[40]\ttraining's l1: 0.184027\ttraining's l2: 0.203024\tvalid_1's l1: 0.858713\tvalid_1's l2: 1.33436\n",
      "[41]\ttraining's l1: 0.182998\ttraining's l2: 0.201416\tvalid_1's l1: 0.862432\tvalid_1's l2: 1.3473\n",
      "[42]\ttraining's l1: 0.184075\ttraining's l2: 0.19768\tvalid_1's l1: 0.856706\tvalid_1's l2: 1.32991\n",
      "[43]\ttraining's l1: 0.181733\ttraining's l2: 0.196042\tvalid_1's l1: 0.861128\tvalid_1's l2: 1.34382\n",
      "[44]\ttraining's l1: 0.181757\ttraining's l2: 0.193465\tvalid_1's l1: 0.858791\tvalid_1's l2: 1.34243\n",
      "[45]\ttraining's l1: 0.180535\ttraining's l2: 0.191943\tvalid_1's l1: 0.858674\tvalid_1's l2: 1.34458\n",
      "[46]\ttraining's l1: 0.177355\ttraining's l2: 0.186915\tvalid_1's l1: 0.85958\tvalid_1's l2: 1.3533\n",
      "[47]\ttraining's l1: 0.175639\ttraining's l2: 0.184324\tvalid_1's l1: 0.865382\tvalid_1's l2: 1.37268\n",
      "[48]\ttraining's l1: 0.176123\ttraining's l2: 0.180983\tvalid_1's l1: 0.861488\tvalid_1's l2: 1.36969\n",
      "[49]\ttraining's l1: 0.175818\ttraining's l2: 0.178279\tvalid_1's l1: 0.861753\tvalid_1's l2: 1.3694\n",
      "[50]\ttraining's l1: 0.175313\ttraining's l2: 0.174157\tvalid_1's l1: 0.860208\tvalid_1's l2: 1.36729\n",
      "[51]\ttraining's l1: 0.174421\ttraining's l2: 0.170789\tvalid_1's l1: 0.858495\tvalid_1's l2: 1.36492\n",
      "[52]\ttraining's l1: 0.172735\ttraining's l2: 0.168295\tvalid_1's l1: 0.862364\tvalid_1's l2: 1.37754\n",
      "[53]\ttraining's l1: 0.173215\ttraining's l2: 0.165581\tvalid_1's l1: 0.86181\tvalid_1's l2: 1.37912\n",
      "[54]\ttraining's l1: 0.173181\ttraining's l2: 0.163345\tvalid_1's l1: 0.860628\tvalid_1's l2: 1.37648\n",
      "[55]\ttraining's l1: 0.171832\ttraining's l2: 0.161304\tvalid_1's l1: 0.859006\tvalid_1's l2: 1.37362\n",
      "[56]\ttraining's l1: 0.170356\ttraining's l2: 0.160018\tvalid_1's l1: 0.861312\tvalid_1's l2: 1.38389\n",
      "[57]\ttraining's l1: 0.170457\ttraining's l2: 0.156996\tvalid_1's l1: 0.858287\tvalid_1's l2: 1.37885\n",
      "[58]\ttraining's l1: 0.169001\ttraining's l2: 0.155866\tvalid_1's l1: 0.861299\tvalid_1's l2: 1.39016\n",
      "[59]\ttraining's l1: 0.16846\ttraining's l2: 0.153824\tvalid_1's l1: 0.858039\tvalid_1's l2: 1.38262\n",
      "[60]\ttraining's l1: 0.168623\ttraining's l2: 0.151683\tvalid_1's l1: 0.854358\tvalid_1's l2: 1.37827\n",
      "[61]\ttraining's l1: 0.16793\ttraining's l2: 0.150627\tvalid_1's l1: 0.857123\tvalid_1's l2: 1.38849\n",
      "[62]\ttraining's l1: 0.167916\ttraining's l2: 0.148517\tvalid_1's l1: 0.854805\tvalid_1's l2: 1.38492\n",
      "[63]\ttraining's l1: 0.166772\ttraining's l2: 0.146402\tvalid_1's l1: 0.859132\tvalid_1's l2: 1.39677\n",
      "[64]\ttraining's l1: 0.166186\ttraining's l2: 0.144394\tvalid_1's l1: 0.857959\tvalid_1's l2: 1.39878\n",
      "[65]\ttraining's l1: 0.165993\ttraining's l2: 0.141741\tvalid_1's l1: 0.859553\tvalid_1's l2: 1.40371\n",
      "[66]\ttraining's l1: 0.164922\ttraining's l2: 0.139914\tvalid_1's l1: 0.8636\tvalid_1's l2: 1.41522\n",
      "[67]\ttraining's l1: 0.163787\ttraining's l2: 0.137929\tvalid_1's l1: 0.863761\tvalid_1's l2: 1.41547\n",
      "[68]\ttraining's l1: 0.163471\ttraining's l2: 0.136474\tvalid_1's l1: 0.86269\tvalid_1's l2: 1.40899\n",
      "[69]\ttraining's l1: 0.164267\ttraining's l2: 0.134359\tvalid_1's l1: 0.861944\tvalid_1's l2: 1.40567\n",
      "[70]\ttraining's l1: 0.162592\ttraining's l2: 0.133403\tvalid_1's l1: 0.864798\tvalid_1's l2: 1.41603\n",
      "[71]\ttraining's l1: 0.161784\ttraining's l2: 0.131431\tvalid_1's l1: 0.864206\tvalid_1's l2: 1.41607\n",
      "[72]\ttraining's l1: 0.16101\ttraining's l2: 0.130242\tvalid_1's l1: 0.864894\tvalid_1's l2: 1.41491\n",
      "[73]\ttraining's l1: 0.161137\ttraining's l2: 0.128203\tvalid_1's l1: 0.862647\tvalid_1's l2: 1.41176\n",
      "[74]\ttraining's l1: 0.159604\ttraining's l2: 0.126389\tvalid_1's l1: 0.866096\tvalid_1's l2: 1.42392\n",
      "[75]\ttraining's l1: 0.157446\ttraining's l2: 0.124051\tvalid_1's l1: 0.865661\tvalid_1's l2: 1.42301\n",
      "[76]\ttraining's l1: 0.156561\ttraining's l2: 0.122452\tvalid_1's l1: 0.861527\tvalid_1's l2: 1.40613\n",
      "[77]\ttraining's l1: 0.155779\ttraining's l2: 0.121649\tvalid_1's l1: 0.861148\tvalid_1's l2: 1.40783\n",
      "[78]\ttraining's l1: 0.154544\ttraining's l2: 0.120027\tvalid_1's l1: 0.865085\tvalid_1's l2: 1.4235\n",
      "[79]\ttraining's l1: 0.154256\ttraining's l2: 0.119267\tvalid_1's l1: 0.863125\tvalid_1's l2: 1.41784\n",
      "[80]\ttraining's l1: 0.153125\ttraining's l2: 0.117474\tvalid_1's l1: 0.8671\tvalid_1's l2: 1.43054\n",
      "[81]\ttraining's l1: 0.152456\ttraining's l2: 0.115623\tvalid_1's l1: 0.866107\tvalid_1's l2: 1.42964\n",
      "[82]\ttraining's l1: 0.152543\ttraining's l2: 0.114586\tvalid_1's l1: 0.86425\tvalid_1's l2: 1.42196\n",
      "[83]\ttraining's l1: 0.151741\ttraining's l2: 0.113038\tvalid_1's l1: 0.86418\tvalid_1's l2: 1.42337\n",
      "[84]\ttraining's l1: 0.151292\ttraining's l2: 0.111376\tvalid_1's l1: 0.86802\tvalid_1's l2: 1.43499\n",
      "[85]\ttraining's l1: 0.150276\ttraining's l2: 0.109569\tvalid_1's l1: 0.867042\tvalid_1's l2: 1.43239\n",
      "[86]\ttraining's l1: 0.149741\ttraining's l2: 0.108341\tvalid_1's l1: 0.868152\tvalid_1's l2: 1.43546\n",
      "[87]\ttraining's l1: 0.149179\ttraining's l2: 0.107675\tvalid_1's l1: 0.867706\tvalid_1's l2: 1.43699\n",
      "[88]\ttraining's l1: 0.148268\ttraining's l2: 0.10638\tvalid_1's l1: 0.871248\tvalid_1's l2: 1.4512\n",
      "[89]\ttraining's l1: 0.147754\ttraining's l2: 0.10574\tvalid_1's l1: 0.869917\tvalid_1's l2: 1.44398\n",
      "[90]\ttraining's l1: 0.147469\ttraining's l2: 0.104224\tvalid_1's l1: 0.868757\tvalid_1's l2: 1.44443\n",
      "[91]\ttraining's l1: 0.147138\ttraining's l2: 0.102258\tvalid_1's l1: 0.867677\tvalid_1's l2: 1.44328\n",
      "[92]\ttraining's l1: 0.146277\ttraining's l2: 0.101639\tvalid_1's l1: 0.869482\tvalid_1's l2: 1.45133\n",
      "[93]\ttraining's l1: 0.146218\ttraining's l2: 0.10046\tvalid_1's l1: 0.871349\tvalid_1's l2: 1.45834\n",
      "[94]\ttraining's l1: 0.145919\ttraining's l2: 0.0995705\tvalid_1's l1: 0.870287\tvalid_1's l2: 1.45299\n",
      "[95]\ttraining's l1: 0.145603\ttraining's l2: 0.0989966\tvalid_1's l1: 0.869484\tvalid_1's l2: 1.45416\n",
      "[96]\ttraining's l1: 0.144921\ttraining's l2: 0.0978746\tvalid_1's l1: 0.872873\tvalid_1's l2: 1.46769\n",
      "[97]\ttraining's l1: 0.143789\ttraining's l2: 0.0973178\tvalid_1's l1: 0.870576\tvalid_1's l2: 1.45939\n",
      "[98]\ttraining's l1: 0.143401\ttraining's l2: 0.0967593\tvalid_1's l1: 0.868887\tvalid_1's l2: 1.45447\n",
      "[99]\ttraining's l1: 0.142864\ttraining's l2: 0.0954834\tvalid_1's l1: 0.869872\tvalid_1's l2: 1.45655\n",
      "[100]\ttraining's l1: 0.142812\ttraining's l2: 0.0941027\tvalid_1's l1: 0.868227\tvalid_1's l2: 1.45501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "             eval_metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l1: 0.723077\ttraining's l2: 0.926553\tvalid_1's l1: 0.637085\tvalid_1's l2: 0.636143\n",
      "[2]\ttraining's l1: 0.717722\ttraining's l2: 0.914141\tvalid_1's l1: 0.636519\tvalid_1's l2: 0.64026\n",
      "[3]\ttraining's l1: 0.712421\ttraining's l2: 0.901976\tvalid_1's l1: 0.635958\tvalid_1's l2: 0.644447\n",
      "[4]\ttraining's l1: 0.707173\ttraining's l2: 0.890053\tvalid_1's l1: 0.635402\tvalid_1's l2: 0.648702\n",
      "[5]\ttraining's l1: 0.701978\ttraining's l2: 0.878367\tvalid_1's l1: 0.634853\tvalid_1's l2: 0.653021\n",
      "[6]\ttraining's l1: 0.696834\ttraining's l2: 0.866913\tvalid_1's l1: 0.634308\tvalid_1's l2: 0.657403\n",
      "[7]\ttraining's l1: 0.691742\ttraining's l2: 0.855688\tvalid_1's l1: 0.63377\tvalid_1's l2: 0.661844\n",
      "[8]\ttraining's l1: 0.686701\ttraining's l2: 0.844686\tvalid_1's l1: 0.633236\tvalid_1's l2: 0.666341\n",
      "[9]\ttraining's l1: 0.68171\ttraining's l2: 0.833902\tvalid_1's l1: 0.632708\tvalid_1's l2: 0.670893\n",
      "[10]\ttraining's l1: 0.676769\ttraining's l2: 0.823334\tvalid_1's l1: 0.632185\tvalid_1's l2: 0.675497\n",
      "[11]\ttraining's l1: 0.671877\ttraining's l2: 0.812976\tvalid_1's l1: 0.631668\tvalid_1's l2: 0.680149\n",
      "[12]\ttraining's l1: 0.667035\ttraining's l2: 0.802824\tvalid_1's l1: 0.631156\tvalid_1's l2: 0.684848\n",
      "[13]\ttraining's l1: 0.66224\ttraining's l2: 0.792873\tvalid_1's l1: 0.630648\tvalid_1's l2: 0.689592\n",
      "[14]\ttraining's l1: 0.657494\ttraining's l2: 0.783121\tvalid_1's l1: 0.630146\tvalid_1's l2: 0.694378\n",
      "[15]\ttraining's l1: 0.652795\ttraining's l2: 0.773563\tvalid_1's l1: 0.629649\tvalid_1's l2: 0.699204\n",
      "[16]\ttraining's l1: 0.648144\ttraining's l2: 0.764195\tvalid_1's l1: 0.629157\tvalid_1's l2: 0.704067\n",
      "[17]\ttraining's l1: 0.643538\ttraining's l2: 0.755014\tvalid_1's l1: 0.628669\tvalid_1's l2: 0.708967\n",
      "[18]\ttraining's l1: 0.638979\ttraining's l2: 0.746015\tvalid_1's l1: 0.628187\tvalid_1's l2: 0.7139\n",
      "[19]\ttraining's l1: 0.634466\ttraining's l2: 0.737196\tvalid_1's l1: 0.62771\tvalid_1's l2: 0.718864\n",
      "[20]\ttraining's l1: 0.629997\ttraining's l2: 0.728552\tvalid_1's l1: 0.627237\tvalid_1's l2: 0.723859\n",
      "[21]\ttraining's l1: 0.625573\ttraining's l2: 0.72008\tvalid_1's l1: 0.626769\tvalid_1's l2: 0.728881\n",
      "[22]\ttraining's l1: 0.621194\ttraining's l2: 0.711776\tvalid_1's l1: 0.626305\tvalid_1's l2: 0.73393\n",
      "[23]\ttraining's l1: 0.616858\ttraining's l2: 0.703638\tvalid_1's l1: 0.625847\tvalid_1's l2: 0.739002\n",
      "[24]\ttraining's l1: 0.612565\ttraining's l2: 0.695662\tvalid_1's l1: 0.625392\tvalid_1's l2: 0.744098\n",
      "[25]\ttraining's l1: 0.608316\ttraining's l2: 0.687844\tvalid_1's l1: 0.626632\tvalid_1's l2: 0.749214\n",
      "[26]\ttraining's l1: 0.604109\ttraining's l2: 0.680182\tvalid_1's l1: 0.628963\tvalid_1's l2: 0.754349\n",
      "[27]\ttraining's l1: 0.599944\ttraining's l2: 0.672672\tvalid_1's l1: 0.631271\tvalid_1's l2: 0.759502\n",
      "[28]\ttraining's l1: 0.595821\ttraining's l2: 0.665312\tvalid_1's l1: 0.633556\tvalid_1's l2: 0.764671\n",
      "[29]\ttraining's l1: 0.591739\ttraining's l2: 0.658099\tvalid_1's l1: 0.635818\tvalid_1's l2: 0.769855\n",
      "[30]\ttraining's l1: 0.587698\ttraining's l2: 0.651029\tvalid_1's l1: 0.638057\tvalid_1's l2: 0.775052\n",
      "[31]\ttraining's l1: 0.583697\ttraining's l2: 0.644099\tvalid_1's l1: 0.640274\tvalid_1's l2: 0.780261\n",
      "[32]\ttraining's l1: 0.579411\ttraining's l2: 0.637306\tvalid_1's l1: 0.641266\tvalid_1's l2: 0.783127\n",
      "[33]\ttraining's l1: 0.575488\ttraining's l2: 0.630645\tvalid_1's l1: 0.643445\tvalid_1's l2: 0.788349\n",
      "[34]\ttraining's l1: 0.571284\ttraining's l2: 0.624115\tvalid_1's l1: 0.644413\tvalid_1's l2: 0.791251\n",
      "[35]\ttraining's l1: 0.567437\ttraining's l2: 0.617711\tvalid_1's l1: 0.646554\tvalid_1's l2: 0.796482\n",
      "[36]\ttraining's l1: 0.563312\ttraining's l2: 0.611434\tvalid_1's l1: 0.647499\tvalid_1's l2: 0.799414\n",
      "[37]\ttraining's l1: 0.559541\ttraining's l2: 0.605278\tvalid_1's l1: 0.649603\tvalid_1's l2: 0.804651\n",
      "[38]\ttraining's l1: 0.555494\ttraining's l2: 0.599243\tvalid_1's l1: 0.650525\tvalid_1's l2: 0.807608\n",
      "[39]\ttraining's l1: 0.551797\ttraining's l2: 0.593325\tvalid_1's l1: 0.652592\tvalid_1's l2: 0.812846\n",
      "[40]\ttraining's l1: 0.547826\ttraining's l2: 0.587523\tvalid_1's l1: 0.653492\tvalid_1's l2: 0.815824\n",
      "[41]\ttraining's l1: 0.544201\ttraining's l2: 0.581833\tvalid_1's l1: 0.655523\tvalid_1's l2: 0.821059\n",
      "[42]\ttraining's l1: 0.540741\ttraining's l2: 0.576254\tvalid_1's l1: 0.656611\tvalid_1's l2: 0.825102\n",
      "[43]\ttraining's l1: 0.53688\ttraining's l2: 0.570782\tvalid_1's l1: 0.657476\tvalid_1's l2: 0.828084\n",
      "[44]\ttraining's l1: 0.533358\ttraining's l2: 0.565415\tvalid_1's l1: 0.659459\tvalid_1's l2: 0.833302\n",
      "[45]\ttraining's l1: 0.530001\ttraining's l2: 0.56015\tvalid_1's l1: 0.660509\tvalid_1's l2: 0.837311\n",
      "[46]\ttraining's l1: 0.526547\ttraining's l2: 0.554988\tvalid_1's l1: 0.66246\tvalid_1's l2: 0.842513\n",
      "[47]\ttraining's l1: 0.522825\ttraining's l2: 0.549924\tvalid_1's l1: 0.663278\tvalid_1's l2: 0.845487\n",
      "[48]\ttraining's l1: 0.519566\ttraining's l2: 0.544956\tvalid_1's l1: 0.664291\tvalid_1's l2: 0.849457\n",
      "[49]\ttraining's l1: 0.516212\ttraining's l2: 0.540086\tvalid_1's l1: 0.666197\tvalid_1's l2: 0.85463\n",
      "[50]\ttraining's l1: 0.513017\ttraining's l2: 0.535308\tvalid_1's l1: 0.667187\tvalid_1's l2: 0.858575\n",
      "[51]\ttraining's l1: 0.509428\ttraining's l2: 0.53062\tvalid_1's l1: 0.668143\tvalid_1's l2: 0.861517\n",
      "[52]\ttraining's l1: 0.506296\ttraining's l2: 0.526025\tvalid_1's l1: 0.669412\tvalid_1's l2: 0.865433\n",
      "[53]\ttraining's l1: 0.503069\ttraining's l2: 0.521515\tvalid_1's l1: 0.671374\tvalid_1's l2: 0.870555\n",
      "[54]\ttraining's l1: 0.499578\ttraining's l2: 0.517093\tvalid_1's l1: 0.672407\tvalid_1's l2: 0.873479\n",
      "[55]\ttraining's l1: 0.496538\ttraining's l2: 0.512755\tvalid_1's l1: 0.674\tvalid_1's l2: 0.877344\n",
      "[56]\ttraining's l1: 0.493403\ttraining's l2: 0.508499\tvalid_1's l1: 0.676342\tvalid_1's l2: 0.882426\n",
      "[57]\ttraining's l1: 0.490459\ttraining's l2: 0.504324\tvalid_1's l1: 0.678474\tvalid_1's l2: 0.887402\n",
      "[58]\ttraining's l1: 0.487508\ttraining's l2: 0.500227\tvalid_1's l1: 0.680101\tvalid_1's l2: 0.891212\n",
      "[59]\ttraining's l1: 0.48417\ttraining's l2: 0.496208\tvalid_1's l1: 0.682198\tvalid_1's l2: 0.89407\n",
      "[60]\ttraining's l1: 0.481312\ttraining's l2: 0.492264\tvalid_1's l1: 0.684265\tvalid_1's l2: 0.898996\n",
      "[61]\ttraining's l1: 0.478324\ttraining's l2: 0.488395\tvalid_1's l1: 0.686499\tvalid_1's l2: 0.904001\n",
      "[62]\ttraining's l1: 0.475487\ttraining's l2: 0.484597\tvalid_1's l1: 0.688044\tvalid_1's l2: 0.907728\n",
      "[63]\ttraining's l1: 0.472715\ttraining's l2: 0.480872\tvalid_1's l1: 0.69005\tvalid_1's l2: 0.912602\n",
      "[64]\ttraining's l1: 0.469934\ttraining's l2: 0.477217\tvalid_1's l1: 0.691557\tvalid_1's l2: 0.916289\n",
      "[65]\ttraining's l1: 0.467057\ttraining's l2: 0.47363\tvalid_1's l1: 0.693708\tvalid_1's l2: 0.921221\n",
      "[66]\ttraining's l1: 0.464367\ttraining's l2: 0.47011\tvalid_1's l1: 0.695766\tvalid_1's l2: 0.926039\n",
      "[67]\ttraining's l1: 0.461255\ttraining's l2: 0.466655\tvalid_1's l1: 0.697745\tvalid_1's l2: 0.928765\n",
      "[68]\ttraining's l1: 0.458582\ttraining's l2: 0.463265\tvalid_1's l1: 0.699221\tvalid_1's l2: 0.932361\n",
      "[69]\ttraining's l1: 0.455971\ttraining's l2: 0.45994\tvalid_1's l1: 0.701244\tvalid_1's l2: 0.93712\n",
      "[70]\ttraining's l1: 0.453228\ttraining's l2: 0.456675\tvalid_1's l1: 0.703338\tvalid_1's l2: 0.941958\n",
      "[71]\ttraining's l1: 0.450634\ttraining's l2: 0.453472\tvalid_1's l1: 0.704757\tvalid_1's l2: 0.945486\n",
      "[72]\ttraining's l1: 0.447657\ttraining's l2: 0.450328\tvalid_1's l1: 0.706636\tvalid_1's l2: 0.948122\n",
      "[73]\ttraining's l1: 0.445148\ttraining's l2: 0.447242\tvalid_1's l1: 0.70858\tvalid_1's l2: 0.952799\n",
      "[74]\ttraining's l1: 0.44263\ttraining's l2: 0.444214\tvalid_1's l1: 0.709943\tvalid_1's l2: 0.956256\n",
      "[75]\ttraining's l1: 0.440014\ttraining's l2: 0.441242\tvalid_1's l1: 0.711939\tvalid_1's l2: 0.960989\n",
      "[76]\ttraining's l1: 0.43758\ttraining's l2: 0.438324\tvalid_1's l1: 0.713826\tvalid_1's l2: 0.965602\n",
      "[77]\ttraining's l1: 0.435135\ttraining's l2: 0.435462\tvalid_1's l1: 0.715135\tvalid_1's l2: 0.968987\n",
      "[78]\ttraining's l1: 0.432309\ttraining's l2: 0.432652\tvalid_1's l1: 0.716901\tvalid_1's l2: 0.971504\n",
      "[79]\ttraining's l1: 0.429947\ttraining's l2: 0.429894\tvalid_1's l1: 0.718732\tvalid_1's l2: 0.97605\n",
      "[80]\ttraining's l1: 0.427452\ttraining's l2: 0.427186\tvalid_1's l1: 0.720635\tvalid_1's l2: 0.980676\n",
      "[81]\ttraining's l1: 0.425102\ttraining's l2: 0.424528\tvalid_1's l1: 0.721873\tvalid_1's l2: 0.983961\n",
      "[82]\ttraining's l1: 0.422809\ttraining's l2: 0.421919\tvalid_1's l1: 0.723651\tvalid_1's l2: 0.988439\n",
      "[83]\ttraining's l1: 0.420385\ttraining's l2: 0.419359\tvalid_1's l1: 0.725499\tvalid_1's l2: 0.992998\n",
      "[84]\ttraining's l1: 0.418103\ttraining's l2: 0.416845\tvalid_1's l1: 0.726688\tvalid_1's l2: 0.99621\n",
      "[85]\ttraining's l1: 0.415879\ttraining's l2: 0.414377\tvalid_1's l1: 0.728413\tvalid_1's l2: 1.00062\n",
      "[86]\ttraining's l1: 0.413241\ttraining's l2: 0.411954\tvalid_1's l1: 0.730038\tvalid_1's l2: 1.00297\n",
      "[87]\ttraining's l1: 0.411026\ttraining's l2: 0.409576\tvalid_1's l1: 0.731178\tvalid_1's l2: 1.0061\n",
      "[88]\ttraining's l1: 0.408867\ttraining's l2: 0.407241\tvalid_1's l1: 0.732852\tvalid_1's l2: 1.01044\n",
      "[89]\ttraining's l1: 0.406576\ttraining's l2: 0.404948\tvalid_1's l1: 0.734598\tvalid_1's l2: 1.01486\n",
      "[90]\ttraining's l1: 0.404425\ttraining's l2: 0.402697\tvalid_1's l1: 0.735691\tvalid_1's l2: 1.01792\n",
      "[91]\ttraining's l1: 0.40233\ttraining's l2: 0.400487\tvalid_1's l1: 0.737316\tvalid_1's l2: 1.02219\n",
      "[92]\ttraining's l1: 0.399824\ttraining's l2: 0.398317\tvalid_1's l1: 0.738843\tvalid_1's l2: 1.0244\n",
      "[93]\ttraining's l1: 0.397619\ttraining's l2: 0.396187\tvalid_1's l1: 0.740523\tvalid_1's l2: 1.02873\n",
      "[94]\ttraining's l1: 0.395551\ttraining's l2: 0.394095\tvalid_1's l1: 0.741555\tvalid_1's l2: 1.03168\n",
      "[95]\ttraining's l1: 0.393538\ttraining's l2: 0.392039\tvalid_1's l1: 0.743116\tvalid_1's l2: 1.03586\n",
      "[96]\ttraining's l1: 0.391511\ttraining's l2: 0.390023\tvalid_1's l1: 0.74412\tvalid_1's l2: 1.03877\n",
      "[97]\ttraining's l1: 0.389538\ttraining's l2: 0.388042\tvalid_1's l1: 0.745651\tvalid_1's l2: 1.04289\n",
      "[98]\ttraining's l1: 0.387433\ttraining's l2: 0.386096\tvalid_1's l1: 0.747253\tvalid_1's l2: 1.04709\n",
      "[99]\ttraining's l1: 0.385072\ttraining's l2: 0.384185\tvalid_1's l1: 0.748673\tvalid_1's l2: 1.04916\n",
      "[100]\ttraining's l1: 0.383124\ttraining's l2: 0.382309\tvalid_1's l1: 0.749618\tvalid_1's l2: 1.05196\n",
      "[101]\ttraining's l1: 0.381228\ttraining's l2: 0.380465\tvalid_1's l1: 0.75109\tvalid_1's l2: 1.05599\n",
      "[102]\ttraining's l1: 0.3792\ttraining's l2: 0.378656\tvalid_1's l1: 0.752632\tvalid_1's l2: 1.0601\n",
      "[103]\ttraining's l1: 0.377309\ttraining's l2: 0.376879\tvalid_1's l1: 0.753537\tvalid_1's l2: 1.06283\n",
      "[104]\ttraining's l1: 0.375469\ttraining's l2: 0.375132\tvalid_1's l1: 0.754965\tvalid_1's l2: 1.06678\n",
      "[105]\ttraining's l1: 0.373224\ttraining's l2: 0.373416\tvalid_1's l1: 0.756298\tvalid_1's l2: 1.06871\n",
      "[106]\ttraining's l1: 0.371388\ttraining's l2: 0.371732\tvalid_1's l1: 0.757163\tvalid_1's l2: 1.07136\n",
      "[107]\ttraining's l1: 0.369602\ttraining's l2: 0.370077\tvalid_1's l1: 0.758549\tvalid_1's l2: 1.07524\n",
      "[108]\ttraining's l1: 0.367685\ttraining's l2: 0.36845\tvalid_1's l1: 0.760007\tvalid_1's l2: 1.07921\n",
      "[109]\ttraining's l1: 0.365902\ttraining's l2: 0.366854\tvalid_1's l1: 0.760833\tvalid_1's l2: 1.08179\n",
      "[110]\ttraining's l1: 0.364169\ttraining's l2: 0.365285\tvalid_1's l1: 0.762179\tvalid_1's l2: 1.0856\n",
      "[111]\ttraining's l1: 0.362034\ttraining's l2: 0.363743\tvalid_1's l1: 0.763431\tvalid_1's l2: 1.08739\n",
      "[112]\ttraining's l1: 0.360188\ttraining's l2: 0.362229\tvalid_1's l1: 0.764834\tvalid_1's l2: 1.09126\n",
      "[113]\ttraining's l1: 0.358473\ttraining's l2: 0.360741\tvalid_1's l1: 0.76561\tvalid_1's l2: 1.09373\n",
      "[114]\ttraining's l1: 0.356808\ttraining's l2: 0.359277\tvalid_1's l1: 0.766903\tvalid_1's l2: 1.09745\n",
      "[115]\ttraining's l1: 0.354745\ttraining's l2: 0.357842\tvalid_1's l1: 0.768104\tvalid_1's l2: 1.09916\n",
      "[116]\ttraining's l1: 0.35308\ttraining's l2: 0.356431\tvalid_1's l1: 0.768844\tvalid_1's l2: 1.10156\n",
      "[117]\ttraining's l1: 0.351464\ttraining's l2: 0.355043\tvalid_1's l1: 0.770099\tvalid_1's l2: 1.10521\n",
      "[118]\ttraining's l1: 0.349717\ttraining's l2: 0.353679\tvalid_1's l1: 0.771426\tvalid_1's l2: 1.10893\n",
      "[119]\ttraining's l1: 0.348101\ttraining's l2: 0.35234\tvalid_1's l1: 0.772132\tvalid_1's l2: 1.11126\n",
      "[120]\ttraining's l1: 0.346533\ttraining's l2: 0.351022\tvalid_1's l1: 0.77335\tvalid_1's l2: 1.11483\n",
      "[121]\ttraining's l1: 0.344834\ttraining's l2: 0.349728\tvalid_1's l1: 0.77464\tvalid_1's l2: 1.11849\n",
      "[122]\ttraining's l1: 0.343265\ttraining's l2: 0.348457\tvalid_1's l1: 0.775312\tvalid_1's l2: 1.12074\n",
      "[123]\ttraining's l1: 0.341743\ttraining's l2: 0.347206\tvalid_1's l1: 0.776494\tvalid_1's l2: 1.12424\n",
      "[124]\ttraining's l1: 0.339825\ttraining's l2: 0.345977\tvalid_1's l1: 0.777587\tvalid_1's l2: 1.12576\n",
      "[125]\ttraining's l1: 0.338301\ttraining's l2: 0.34477\tvalid_1's l1: 0.778227\tvalid_1's l2: 1.12794\n",
      "[126]\ttraining's l1: 0.336824\ttraining's l2: 0.343582\tvalid_1's l1: 0.779374\tvalid_1's l2: 1.13137\n",
      "[127]\ttraining's l1: 0.335217\ttraining's l2: 0.342414\tvalid_1's l1: 0.780594\tvalid_1's l2: 1.13489\n",
      "[128]\ttraining's l1: 0.333737\ttraining's l2: 0.341268\tvalid_1's l1: 0.781202\tvalid_1's l2: 1.137\n",
      "[129]\ttraining's l1: 0.332304\ttraining's l2: 0.340139\tvalid_1's l1: 0.782316\tvalid_1's l2: 1.14036\n",
      "[130]\ttraining's l1: 0.330477\ttraining's l2: 0.339029\tvalid_1's l1: 0.783342\tvalid_1's l2: 1.14175\n",
      "[131]\ttraining's l1: 0.328928\ttraining's l2: 0.337939\tvalid_1's l1: 0.784517\tvalid_1's l2: 1.14517\n",
      "[132]\ttraining's l1: 0.327537\ttraining's l2: 0.336867\tvalid_1's l1: 0.785598\tvalid_1's l2: 1.14846\n",
      "[133]\ttraining's l1: 0.326128\ttraining's l2: 0.33581\tvalid_1's l1: 0.786152\tvalid_1's l2: 1.15046\n",
      "[134]\ttraining's l1: 0.324621\ttraining's l2: 0.334775\tvalid_1's l1: 0.787294\tvalid_1's l2: 1.15381\n",
      "[135]\ttraining's l1: 0.323271\ttraining's l2: 0.333755\tvalid_1's l1: 0.788344\tvalid_1's l2: 1.15704\n",
      "[136]\ttraining's l1: 0.321903\ttraining's l2: 0.332751\tvalid_1's l1: 0.788869\tvalid_1's l2: 1.15896\n",
      "[137]\ttraining's l1: 0.320179\ttraining's l2: 0.331764\tvalid_1's l1: 0.789822\tvalid_1's l2: 1.16021\n",
      "[138]\ttraining's l1: 0.318912\ttraining's l2: 0.330795\tvalid_1's l1: 0.790841\tvalid_1's l2: 1.16336\n",
      "[139]\ttraining's l1: 0.317626\ttraining's l2: 0.329839\tvalid_1's l1: 0.791338\tvalid_1's l2: 1.16523\n",
      "[140]\ttraining's l1: 0.316242\ttraining's l2: 0.328901\tvalid_1's l1: 0.792419\tvalid_1's l2: 1.16845\n",
      "[141]\ttraining's l1: 0.315012\ttraining's l2: 0.327978\tvalid_1's l1: 0.793408\tvalid_1's l2: 1.17154\n",
      "[142]\ttraining's l1: 0.313763\ttraining's l2: 0.327069\tvalid_1's l1: 0.793878\tvalid_1's l2: 1.17334\n",
      "[143]\ttraining's l1: 0.312158\ttraining's l2: 0.326175\tvalid_1's l1: 0.794772\tvalid_1's l2: 1.17446\n",
      "[144]\ttraining's l1: 0.310965\ttraining's l2: 0.325297\tvalid_1's l1: 0.795732\tvalid_1's l2: 1.17748\n",
      "[145]\ttraining's l1: 0.309752\ttraining's l2: 0.324431\tvalid_1's l1: 0.796177\tvalid_1's l2: 1.17922\n",
      "[146]\ttraining's l1: 0.308441\ttraining's l2: 0.323579\tvalid_1's l1: 0.797199\tvalid_1's l2: 1.18231\n",
      "[147]\ttraining's l1: 0.307282\ttraining's l2: 0.322742\tvalid_1's l1: 0.798132\tvalid_1's l2: 1.18527\n",
      "[148]\ttraining's l1: 0.306104\ttraining's l2: 0.321918\tvalid_1's l1: 0.798551\tvalid_1's l2: 1.18694\n",
      "[149]\ttraining's l1: 0.304573\ttraining's l2: 0.321106\tvalid_1's l1: 0.799389\tvalid_1's l2: 1.18795\n",
      "[150]\ttraining's l1: 0.303309\ttraining's l2: 0.320308\tvalid_1's l1: 0.800374\tvalid_1's l2: 1.19096\n",
      "[151]\ttraining's l1: 0.302196\ttraining's l2: 0.319523\tvalid_1's l1: 0.80127\tvalid_1's l2: 1.19384\n",
      "[152]\ttraining's l1: 0.301063\ttraining's l2: 0.318748\tvalid_1's l1: 0.801656\tvalid_1's l2: 1.19542\n",
      "[153]\ttraining's l1: 0.299833\ttraining's l2: 0.317988\tvalid_1's l1: 0.802614\tvalid_1's l2: 1.19837\n",
      "[154]\ttraining's l1: 0.298753\ttraining's l2: 0.317239\tvalid_1's l1: 0.803484\tvalid_1's l2: 1.20118\n",
      "[155]\ttraining's l1: 0.297652\ttraining's l2: 0.3165\tvalid_1's l1: 0.803846\tvalid_1's l2: 1.20271\n",
      "[156]\ttraining's l1: 0.296202\ttraining's l2: 0.315774\tvalid_1's l1: 0.804624\tvalid_1's l2: 1.20359\n",
      "[157]\ttraining's l1: 0.295153\ttraining's l2: 0.315059\tvalid_1's l1: 0.805469\tvalid_1's l2: 1.20635\n",
      "[158]\ttraining's l1: 0.294084\ttraining's l2: 0.314355\tvalid_1's l1: 0.805808\tvalid_1's l2: 1.20781\n",
      "[159]\ttraining's l1: 0.292918\ttraining's l2: 0.313662\tvalid_1's l1: 0.806715\tvalid_1's l2: 1.21064\n",
      "[160]\ttraining's l1: 0.291901\ttraining's l2: 0.312979\tvalid_1's l1: 0.807535\tvalid_1's l2: 1.21334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttraining's l1: 0.290862\ttraining's l2: 0.312307\tvalid_1's l1: 0.807852\tvalid_1's l2: 1.21475\n",
      "[162]\ttraining's l1: 0.289477\ttraining's l2: 0.311645\tvalid_1's l1: 0.808582\tvalid_1's l2: 1.21552\n",
      "[163]\ttraining's l1: 0.288489\ttraining's l2: 0.310993\tvalid_1's l1: 0.809378\tvalid_1's l2: 1.21816\n",
      "[164]\ttraining's l1: 0.287374\ttraining's l2: 0.310351\tvalid_1's l1: 0.810245\tvalid_1's l2: 1.22089\n",
      "[165]\ttraining's l1: 0.286375\ttraining's l2: 0.309718\tvalid_1's l1: 0.810533\tvalid_1's l2: 1.22222\n",
      "[166]\ttraining's l1: 0.285417\ttraining's l2: 0.309095\tvalid_1's l1: 0.811306\tvalid_1's l2: 1.2248\n",
      "[167]\ttraining's l1: 0.284437\ttraining's l2: 0.308482\tvalid_1's l1: 0.811581\tvalid_1's l2: 1.2261\n",
      "[168]\ttraining's l1: 0.283361\ttraining's l2: 0.307877\tvalid_1's l1: 0.812417\tvalid_1's l2: 1.22875\n",
      "[169]\ttraining's l1: 0.282047\ttraining's l2: 0.307281\tvalid_1's l1: 0.813094\tvalid_1's l2: 1.22941\n",
      "[170]\ttraining's l1: 0.281126\ttraining's l2: 0.306694\tvalid_1's l1: 0.813837\tvalid_1's l2: 1.23192\n",
      "[171]\ttraining's l1: 0.280183\ttraining's l2: 0.306115\tvalid_1's l1: 0.814085\tvalid_1's l2: 1.23314\n",
      "[172]\ttraining's l1: 0.27928\ttraining's l2: 0.305545\tvalid_1's l1: 0.814814\tvalid_1's l2: 1.23561\n",
      "[173]\ttraining's l1: 0.278604\ttraining's l2: 0.304696\tvalid_1's l1: 0.815653\tvalid_1's l2: 1.23772\n",
      "[174]\ttraining's l1: 0.277577\ttraining's l2: 0.304138\tvalid_1's l1: 0.816449\tvalid_1's l2: 1.24027\n",
      "[175]\ttraining's l1: 0.276908\ttraining's l2: 0.30331\tvalid_1's l1: 0.817278\tvalid_1's l2: 1.24237\n",
      "[176]\ttraining's l1: 0.276247\ttraining's l2: 0.302498\tvalid_1's l1: 0.818099\tvalid_1's l2: 1.24445\n",
      "[177]\ttraining's l1: 0.27537\ttraining's l2: 0.301955\tvalid_1's l1: 0.818804\tvalid_1's l2: 1.24687\n",
      "[178]\ttraining's l1: 0.274749\ttraining's l2: 0.301162\tvalid_1's l1: 0.819613\tvalid_1's l2: 1.24895\n",
      "[179]\ttraining's l1: 0.273748\ttraining's l2: 0.300632\tvalid_1's l1: 0.820385\tvalid_1's l2: 1.25144\n",
      "[180]\ttraining's l1: 0.273137\ttraining's l2: 0.299858\tvalid_1's l1: 0.821184\tvalid_1's l2: 1.2535\n",
      "[181]\ttraining's l1: 0.272531\ttraining's l2: 0.2991\tvalid_1's l1: 0.82194\tvalid_1's l2: 1.25546\n",
      "[182]\ttraining's l1: 0.271677\ttraining's l2: 0.298582\tvalid_1's l1: 0.822622\tvalid_1's l2: 1.25782\n",
      "[183]\ttraining's l1: 0.271079\ttraining's l2: 0.29784\tvalid_1's l1: 0.823403\tvalid_1's l2: 1.25986\n",
      "[184]\ttraining's l1: 0.270207\ttraining's l2: 0.297335\tvalid_1's l1: 0.823597\tvalid_1's l2: 1.26093\n",
      "[185]\ttraining's l1: 0.269614\ttraining's l2: 0.296611\tvalid_1's l1: 0.824333\tvalid_1's l2: 1.26287\n",
      "[186]\ttraining's l1: 0.269029\ttraining's l2: 0.295902\tvalid_1's l1: 0.825095\tvalid_1's l2: 1.26488\n",
      "[187]\ttraining's l1: 0.2682\ttraining's l2: 0.295407\tvalid_1's l1: 0.825755\tvalid_1's l2: 1.26719\n",
      "[188]\ttraining's l1: 0.267738\ttraining's l2: 0.294749\tvalid_1's l1: 0.826413\tvalid_1's l2: 1.2687\n",
      "[189]\ttraining's l1: 0.26692\ttraining's l2: 0.294265\tvalid_1's l1: 0.827064\tvalid_1's l2: 1.27099\n",
      "[190]\ttraining's l1: 0.266463\ttraining's l2: 0.29362\tvalid_1's l1: 0.827711\tvalid_1's l2: 1.27248\n",
      "[191]\ttraining's l1: 0.265521\ttraining's l2: 0.293144\tvalid_1's l1: 0.82843\tvalid_1's l2: 1.27483\n",
      "[192]\ttraining's l1: 0.265071\ttraining's l2: 0.292514\tvalid_1's l1: 0.829102\tvalid_1's l2: 1.27641\n",
      "[193]\ttraining's l1: 0.264516\ttraining's l2: 0.291862\tvalid_1's l1: 0.829655\tvalid_1's l2: 1.27821\n",
      "[194]\ttraining's l1: 0.263719\ttraining's l2: 0.291397\tvalid_1's l1: 0.830288\tvalid_1's l2: 1.28045\n",
      "[195]\ttraining's l1: 0.263277\ttraining's l2: 0.290791\tvalid_1's l1: 0.830942\tvalid_1's l2: 1.28201\n",
      "[196]\ttraining's l1: 0.262358\ttraining's l2: 0.290336\tvalid_1's l1: 0.831642\tvalid_1's l2: 1.28431\n",
      "[197]\ttraining's l1: 0.261798\ttraining's l2: 0.289742\tvalid_1's l1: 0.831669\tvalid_1's l2: 1.28462\n",
      "[198]\ttraining's l1: 0.261021\ttraining's l2: 0.289295\tvalid_1's l1: 0.832288\tvalid_1's l2: 1.28683\n",
      "[199]\ttraining's l1: 0.260223\ttraining's l2: 0.288852\tvalid_1's l1: 0.832431\tvalid_1's l2: 1.28776\n",
      "[200]\ttraining's l1: 0.259741\ttraining's l2: 0.288269\tvalid_1's l1: 0.832478\tvalid_1's l2: 1.28802\n",
      "[201]\ttraining's l1: 0.258852\ttraining's l2: 0.287835\tvalid_1's l1: 0.833162\tvalid_1's l2: 1.29027\n",
      "[202]\ttraining's l1: 0.2581\ttraining's l2: 0.287406\tvalid_1's l1: 0.833764\tvalid_1's l2: 1.29244\n",
      "[203]\ttraining's l1: 0.257149\ttraining's l2: 0.286601\tvalid_1's l1: 0.834651\tvalid_1's l2: 1.29551\n",
      "[204]\ttraining's l1: 0.256784\ttraining's l2: 0.286004\tvalid_1's l1: 0.835356\tvalid_1's l2: 1.29682\n",
      "[205]\ttraining's l1: 0.255843\ttraining's l2: 0.285217\tvalid_1's l1: 0.836233\tvalid_1's l2: 1.29987\n",
      "[206]\ttraining's l1: 0.255334\ttraining's l2: 0.284663\tvalid_1's l1: 0.836243\tvalid_1's l2: 1.30017\n",
      "[207]\ttraining's l1: 0.254405\ttraining's l2: 0.283894\tvalid_1's l1: 0.837111\tvalid_1's l2: 1.3032\n",
      "[208]\ttraining's l1: 0.253485\ttraining's l2: 0.283141\tvalid_1's l1: 0.837969\tvalid_1's l2: 1.30622\n",
      "[209]\ttraining's l1: 0.252574\ttraining's l2: 0.282403\tvalid_1's l1: 0.83882\tvalid_1's l2: 1.30921\n",
      "[210]\ttraining's l1: 0.252208\ttraining's l2: 0.28186\tvalid_1's l1: 0.838866\tvalid_1's l2: 1.30941\n",
      "[211]\ttraining's l1: 0.251308\ttraining's l2: 0.281138\tvalid_1's l1: 0.839708\tvalid_1's l2: 1.31239\n",
      "[212]\ttraining's l1: 0.250985\ttraining's l2: 0.280579\tvalid_1's l1: 0.839811\tvalid_1's l2: 1.31241\n",
      "[213]\ttraining's l1: 0.250094\ttraining's l2: 0.279873\tvalid_1's l1: 0.840646\tvalid_1's l2: 1.31538\n",
      "[214]\ttraining's l1: 0.249221\ttraining's l2: 0.27918\tvalid_1's l1: 0.841471\tvalid_1's l2: 1.31832\n",
      "[215]\ttraining's l1: 0.248853\ttraining's l2: 0.278614\tvalid_1's l1: 0.842099\tvalid_1's l2: 1.31979\n",
      "[216]\ttraining's l1: 0.248006\ttraining's l2: 0.277938\tvalid_1's l1: 0.842915\tvalid_1's l2: 1.32271\n",
      "[217]\ttraining's l1: 0.247172\ttraining's l2: 0.277275\tvalid_1's l1: 0.843723\tvalid_1's l2: 1.32561\n",
      "[218]\ttraining's l1: 0.246953\ttraining's l2: 0.276722\tvalid_1's l1: 0.843798\tvalid_1's l2: 1.32588\n",
      "[219]\ttraining's l1: 0.24614\ttraining's l2: 0.276074\tvalid_1's l1: 0.844597\tvalid_1's l2: 1.32876\n",
      "[220]\ttraining's l1: 0.245337\ttraining's l2: 0.275438\tvalid_1's l1: 0.845388\tvalid_1's l2: 1.33163\n",
      "[221]\ttraining's l1: 0.245108\ttraining's l2: 0.274914\tvalid_1's l1: 0.845473\tvalid_1's l2: 1.33162\n",
      "[222]\ttraining's l1: 0.244315\ttraining's l2: 0.274292\tvalid_1's l1: 0.846258\tvalid_1's l2: 1.33447\n",
      "[223]\ttraining's l1: 0.243531\ttraining's l2: 0.273683\tvalid_1's l1: 0.847035\tvalid_1's l2: 1.3373\n",
      "[224]\ttraining's l1: 0.243304\ttraining's l2: 0.273207\tvalid_1's l1: 0.847016\tvalid_1's l2: 1.33758\n",
      "[225]\ttraining's l1: 0.242534\ttraining's l2: 0.272612\tvalid_1's l1: 0.847784\tvalid_1's l2: 1.34039\n",
      "[226]\ttraining's l1: 0.241776\ttraining's l2: 0.272028\tvalid_1's l1: 0.848544\tvalid_1's l2: 1.34319\n",
      "[227]\ttraining's l1: 0.241572\ttraining's l2: 0.27151\tvalid_1's l1: 0.849122\tvalid_1's l2: 1.34456\n",
      "[228]\ttraining's l1: 0.240886\ttraining's l2: 0.27094\tvalid_1's l1: 0.849873\tvalid_1's l2: 1.34733\n",
      "[229]\ttraining's l1: 0.240724\ttraining's l2: 0.270445\tvalid_1's l1: 0.849942\tvalid_1's l2: 1.3473\n",
      "[230]\ttraining's l1: 0.240082\ttraining's l2: 0.269888\tvalid_1's l1: 0.850687\tvalid_1's l2: 1.35005\n",
      "[231]\ttraining's l1: 0.239445\ttraining's l2: 0.269341\tvalid_1's l1: 0.851424\tvalid_1's l2: 1.35279\n",
      "[232]\ttraining's l1: 0.239203\ttraining's l2: 0.268832\tvalid_1's l1: 0.851386\tvalid_1's l2: 1.35304\n",
      "[233]\ttraining's l1: 0.238582\ttraining's l2: 0.268298\tvalid_1's l1: 0.852115\tvalid_1's l2: 1.35576\n",
      "[234]\ttraining's l1: 0.237905\ttraining's l2: 0.267773\tvalid_1's l1: 0.852881\tvalid_1's l2: 1.35878\n",
      "[235]\ttraining's l1: 0.237727\ttraining's l2: 0.267295\tvalid_1's l1: 0.852939\tvalid_1's l2: 1.35874\n",
      "[236]\ttraining's l1: 0.23712\ttraining's l2: 0.26678\tvalid_1's l1: 0.853655\tvalid_1's l2: 1.36142\n",
      "[237]\ttraining's l1: 0.236253\ttraining's l2: 0.266285\tvalid_1's l1: 0.853646\tvalid_1's l2: 1.35969\n",
      "[238]\ttraining's l1: 0.235403\ttraining's l2: 0.2658\tvalid_1's l1: 0.853637\tvalid_1's l2: 1.35799\n",
      "[239]\ttraining's l1: 0.235192\ttraining's l2: 0.265317\tvalid_1's l1: 0.854034\tvalid_1's l2: 1.35907\n",
      "[240]\ttraining's l1: 0.234345\ttraining's l2: 0.264842\tvalid_1's l1: 0.854026\tvalid_1's l2: 1.3574\n",
      "[241]\ttraining's l1: 0.233683\ttraining's l2: 0.264344\tvalid_1's l1: 0.854768\tvalid_1's l2: 1.36034\n",
      "[242]\ttraining's l1: 0.232862\ttraining's l2: 0.263882\tvalid_1's l1: 0.854755\tvalid_1's l2: 1.35867\n",
      "[243]\ttraining's l1: 0.23282\ttraining's l2: 0.263409\tvalid_1's l1: 0.854767\tvalid_1's l2: 1.35886\n",
      "[244]\ttraining's l1: 0.231996\ttraining's l2: 0.262958\tvalid_1's l1: 0.854757\tvalid_1's l2: 1.35723\n",
      "[245]\ttraining's l1: 0.231411\ttraining's l2: 0.262473\tvalid_1's l1: 0.855445\tvalid_1's l2: 1.35982\n",
      "[246]\ttraining's l1: 0.230609\ttraining's l2: 0.262032\tvalid_1's l1: 0.855431\tvalid_1's l2: 1.3582\n",
      "[247]\ttraining's l1: 0.229822\ttraining's l2: 0.261601\tvalid_1's l1: 0.855416\tvalid_1's l2: 1.35659\n",
      "[248]\ttraining's l1: 0.229663\ttraining's l2: 0.261138\tvalid_1's l1: 0.855319\tvalid_1's l2: 1.3566\n",
      "[249]\ttraining's l1: 0.228889\ttraining's l2: 0.260716\tvalid_1's l1: 0.855306\tvalid_1's l2: 1.35502\n",
      "[250]\ttraining's l1: 0.22832\ttraining's l2: 0.260248\tvalid_1's l1: 0.855981\tvalid_1's l2: 1.35757\n",
      "[251]\ttraining's l1: 0.227559\ttraining's l2: 0.259837\tvalid_1's l1: 0.855963\tvalid_1's l2: 1.356\n",
      "[252]\ttraining's l1: 0.227413\ttraining's l2: 0.259386\tvalid_1's l1: 0.855864\tvalid_1's l2: 1.356\n",
      "[253]\ttraining's l1: 0.22666\ttraining's l2: 0.258984\tvalid_1's l1: 0.855849\tvalid_1's l2: 1.35445\n",
      "[254]\ttraining's l1: 0.226049\ttraining's l2: 0.258527\tvalid_1's l1: 0.856555\tvalid_1's l2: 1.35727\n",
      "[255]\ttraining's l1: 0.225309\ttraining's l2: 0.258136\tvalid_1's l1: 0.856535\tvalid_1's l2: 1.35573\n",
      "[256]\ttraining's l1: 0.225062\ttraining's l2: 0.25761\tvalid_1's l1: 0.856553\tvalid_1's l2: 1.35582\n",
      "[257]\ttraining's l1: 0.22434\ttraining's l2: 0.257227\tvalid_1's l1: 0.856534\tvalid_1's l2: 1.3543\n",
      "[258]\ttraining's l1: 0.224089\ttraining's l2: 0.256713\tvalid_1's l1: 0.856553\tvalid_1's l2: 1.3544\n",
      "[259]\ttraining's l1: 0.223382\ttraining's l2: 0.256338\tvalid_1's l1: 0.856534\tvalid_1's l2: 1.35291\n",
      "[260]\ttraining's l1: 0.223109\ttraining's l2: 0.255836\tvalid_1's l1: 0.856549\tvalid_1's l2: 1.35299\n",
      "[261]\ttraining's l1: 0.222581\ttraining's l2: 0.255396\tvalid_1's l1: 0.857195\tvalid_1's l2: 1.35545\n",
      "[262]\ttraining's l1: 0.221887\ttraining's l2: 0.255033\tvalid_1's l1: 0.857172\tvalid_1's l2: 1.35396\n",
      "[263]\ttraining's l1: 0.221641\ttraining's l2: 0.254538\tvalid_1's l1: 0.857191\tvalid_1's l2: 1.35407\n",
      "[264]\ttraining's l1: 0.220956\ttraining's l2: 0.254183\tvalid_1's l1: 0.857169\tvalid_1's l2: 1.35261\n",
      "[265]\ttraining's l1: 0.220715\ttraining's l2: 0.253701\tvalid_1's l1: 0.857179\tvalid_1's l2: 1.35268\n",
      "[266]\ttraining's l1: 0.220212\ttraining's l2: 0.253275\tvalid_1's l1: 0.857811\tvalid_1's l2: 1.3551\n",
      "[267]\ttraining's l1: 0.219552\ttraining's l2: 0.25293\tvalid_1's l1: 0.857786\tvalid_1's l2: 1.35365\n",
      "[268]\ttraining's l1: 0.219316\ttraining's l2: 0.252472\tvalid_1's l1: 0.857871\tvalid_1's l2: 1.35386\n",
      "[269]\ttraining's l1: 0.218669\ttraining's l2: 0.252134\tvalid_1's l1: 0.857846\tvalid_1's l2: 1.35243\n",
      "[270]\ttraining's l1: 0.218445\ttraining's l2: 0.251671\tvalid_1's l1: 0.857852\tvalid_1's l2: 1.3525\n",
      "[271]\ttraining's l1: 0.217899\ttraining's l2: 0.251258\tvalid_1's l1: 0.858512\tvalid_1's l2: 1.35517\n",
      "[272]\ttraining's l1: 0.217265\ttraining's l2: 0.25093\tvalid_1's l1: 0.858484\tvalid_1's l2: 1.35375\n",
      "[273]\ttraining's l1: 0.217049\ttraining's l2: 0.250488\tvalid_1's l1: 0.858568\tvalid_1's l2: 1.35397\n",
      "[274]\ttraining's l1: 0.216422\ttraining's l2: 0.250168\tvalid_1's l1: 0.858541\tvalid_1's l2: 1.35257\n",
      "[275]\ttraining's l1: 0.216208\ttraining's l2: 0.249723\tvalid_1's l1: 0.858538\tvalid_1's l2: 1.35262\n",
      "[276]\ttraining's l1: 0.215589\ttraining's l2: 0.249411\tvalid_1's l1: 0.858512\tvalid_1's l2: 1.35125\n",
      "[277]\ttraining's l1: 0.215441\ttraining's l2: 0.248984\tvalid_1's l1: 0.858595\tvalid_1's l2: 1.35147\n",
      "[278]\ttraining's l1: 0.214989\ttraining's l2: 0.248583\tvalid_1's l1: 0.859198\tvalid_1's l2: 1.3538\n",
      "[279]\ttraining's l1: 0.214394\ttraining's l2: 0.248279\tvalid_1's l1: 0.859168\tvalid_1's l2: 1.35243\n",
      "[280]\ttraining's l1: 0.213801\ttraining's l2: 0.247979\tvalid_1's l1: 0.859139\tvalid_1's l2: 1.35107\n",
      "[281]\ttraining's l1: 0.213709\ttraining's l2: 0.247554\tvalid_1's l1: 0.859131\tvalid_1's l2: 1.35113\n",
      "[282]\ttraining's l1: 0.21365\ttraining's l2: 0.247141\tvalid_1's l1: 0.859212\tvalid_1's l2: 1.35135\n",
      "[283]\ttraining's l1: 0.213093\ttraining's l2: 0.24685\tvalid_1's l1: 0.859185\tvalid_1's l2: 1.35002\n",
      "[284]\ttraining's l1: 0.212677\ttraining's l2: 0.246583\tvalid_1's l1: 0.859094\tvalid_1's l2: 1.35024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285]\ttraining's l1: 0.212277\ttraining's l2: 0.246197\tvalid_1's l1: 0.859679\tvalid_1's l2: 1.35251\n",
      "[286]\ttraining's l1: 0.211747\ttraining's l2: 0.245915\tvalid_1's l1: 0.859645\tvalid_1's l2: 1.35118\n",
      "[287]\ttraining's l1: 0.211808\ttraining's l2: 0.245506\tvalid_1's l1: 0.859465\tvalid_1's l2: 1.35096\n",
      "[288]\ttraining's l1: 0.211301\ttraining's l2: 0.245005\tvalid_1's l1: 0.860312\tvalid_1's l2: 1.35338\n",
      "[289]\ttraining's l1: 0.210763\ttraining's l2: 0.244729\tvalid_1's l1: 0.860275\tvalid_1's l2: 1.35206\n",
      "[290]\ttraining's l1: 0.210634\ttraining's l2: 0.244325\tvalid_1's l1: 0.860398\tvalid_1's l2: 1.35234\n",
      "[291]\ttraining's l1: 0.210103\ttraining's l2: 0.244055\tvalid_1's l1: 0.860361\tvalid_1's l2: 1.35103\n",
      "[292]\ttraining's l1: 0.209605\ttraining's l2: 0.243567\tvalid_1's l1: 0.861193\tvalid_1's l2: 1.35343\n",
      "[293]\ttraining's l1: 0.209671\ttraining's l2: 0.243216\tvalid_1's l1: 0.860966\tvalid_1's l2: 1.3529\n",
      "[294]\ttraining's l1: 0.209171\ttraining's l2: 0.242953\tvalid_1's l1: 0.860928\tvalid_1's l2: 1.35161\n",
      "[295]\ttraining's l1: 0.208686\ttraining's l2: 0.242475\tvalid_1's l1: 0.861752\tvalid_1's l2: 1.35399\n",
      "[296]\ttraining's l1: 0.208761\ttraining's l2: 0.242084\tvalid_1's l1: 0.861575\tvalid_1's l2: 1.35379\n",
      "[297]\ttraining's l1: 0.208632\ttraining's l2: 0.241662\tvalid_1's l1: 0.861373\tvalid_1's l2: 1.35317\n",
      "[298]\ttraining's l1: 0.208155\ttraining's l2: 0.241192\tvalid_1's l1: 0.862193\tvalid_1's l2: 1.35555\n",
      "[299]\ttraining's l1: 0.208234\ttraining's l2: 0.240854\tvalid_1's l1: 0.861965\tvalid_1's l2: 1.35503\n",
      "[300]\ttraining's l1: 0.207759\ttraining's l2: 0.2406\tvalid_1's l1: 0.861924\tvalid_1's l2: 1.35376\n",
      "[301]\ttraining's l1: 0.207291\ttraining's l2: 0.240139\tvalid_1's l1: 0.862736\tvalid_1's l2: 1.35613\n",
      "[302]\ttraining's l1: 0.207185\ttraining's l2: 0.239726\tvalid_1's l1: 0.862531\tvalid_1's l2: 1.35551\n",
      "[303]\ttraining's l1: 0.20676\ttraining's l2: 0.239274\tvalid_1's l1: 0.863338\tvalid_1's l2: 1.35787\n",
      "[304]\ttraining's l1: 0.206796\ttraining's l2: 0.23892\tvalid_1's l1: 0.863164\tvalid_1's l2: 1.35765\n",
      "[305]\ttraining's l1: 0.20635\ttraining's l2: 0.238674\tvalid_1's l1: 0.863116\tvalid_1's l2: 1.35639\n",
      "[306]\ttraining's l1: 0.205931\ttraining's l2: 0.238232\tvalid_1's l1: 0.863913\tvalid_1's l2: 1.35873\n",
      "[307]\ttraining's l1: 0.205827\ttraining's l2: 0.237812\tvalid_1's l1: 0.863643\tvalid_1's l2: 1.35815\n",
      "[308]\ttraining's l1: 0.205412\ttraining's l2: 0.237377\tvalid_1's l1: 0.864433\tvalid_1's l2: 1.36049\n",
      "[309]\ttraining's l1: 0.205548\ttraining's l2: 0.237049\tvalid_1's l1: 0.864139\tvalid_1's l2: 1.35991\n",
      "[310]\ttraining's l1: 0.205419\ttraining's l2: 0.236596\tvalid_1's l1: 0.863744\tvalid_1's l2: 1.35885\n",
      "[311]\ttraining's l1: 0.205001\ttraining's l2: 0.236357\tvalid_1's l1: 0.863694\tvalid_1's l2: 1.35761\n",
      "[312]\ttraining's l1: 0.204588\ttraining's l2: 0.23593\tvalid_1's l1: 0.864479\tvalid_1's l2: 1.35994\n",
      "[313]\ttraining's l1: 0.204752\ttraining's l2: 0.23561\tvalid_1's l1: 0.864186\tvalid_1's l2: 1.35937\n",
      "[314]\ttraining's l1: 0.204726\ttraining's l2: 0.23522\tvalid_1's l1: 0.863982\tvalid_1's l2: 1.35876\n",
      "[315]\ttraining's l1: 0.204359\ttraining's l2: 0.234799\tvalid_1's l1: 0.864764\tvalid_1's l2: 1.36109\n",
      "[316]\ttraining's l1: 0.20397\ttraining's l2: 0.234568\tvalid_1's l1: 0.86471\tvalid_1's l2: 1.35986\n",
      "[317]\ttraining's l1: 0.203608\ttraining's l2: 0.234157\tvalid_1's l1: 0.865482\tvalid_1's l2: 1.36217\n",
      "[318]\ttraining's l1: 0.203593\ttraining's l2: 0.233805\tvalid_1's l1: 0.865631\tvalid_1's l2: 1.36242\n",
      "[319]\ttraining's l1: 0.203477\ttraining's l2: 0.233366\tvalid_1's l1: 0.865237\tvalid_1's l2: 1.36137\n",
      "[320]\ttraining's l1: 0.203058\ttraining's l2: 0.233016\tvalid_1's l1: 0.865789\tvalid_1's l2: 1.36375\n",
      "[321]\ttraining's l1: 0.202678\ttraining's l2: 0.232792\tvalid_1's l1: 0.865729\tvalid_1's l2: 1.36251\n",
      "[322]\ttraining's l1: 0.202672\ttraining's l2: 0.232413\tvalid_1's l1: 0.865441\tvalid_1's l2: 1.3618\n",
      "[323]\ttraining's l1: 0.202316\ttraining's l2: 0.232011\tvalid_1's l1: 0.866201\tvalid_1's l2: 1.36409\n",
      "[324]\ttraining's l1: 0.201982\ttraining's l2: 0.231618\tvalid_1's l1: 0.866953\tvalid_1's l2: 1.36637\n",
      "[325]\ttraining's l1: 0.201872\ttraining's l2: 0.231196\tvalid_1's l1: 0.866547\tvalid_1's l2: 1.36548\n",
      "[326]\ttraining's l1: 0.20152\ttraining's l2: 0.230979\tvalid_1's l1: 0.866484\tvalid_1's l2: 1.36426\n",
      "[327]\ttraining's l1: 0.201205\ttraining's l2: 0.230593\tvalid_1's l1: 0.867011\tvalid_1's l2: 1.36561\n",
      "[328]\ttraining's l1: 0.201312\ttraining's l2: 0.230343\tvalid_1's l1: 0.866847\tvalid_1's l2: 1.36514\n",
      "[329]\ttraining's l1: 0.201323\ttraining's l2: 0.229974\tvalid_1's l1: 0.866558\tvalid_1's l2: 1.36443\n",
      "[330]\ttraining's l1: 0.201051\ttraining's l2: 0.229591\tvalid_1's l1: 0.867301\tvalid_1's l2: 1.36669\n",
      "[331]\ttraining's l1: 0.200729\ttraining's l2: 0.22938\tvalid_1's l1: 0.867234\tvalid_1's l2: 1.36548\n",
      "[332]\ttraining's l1: 0.200446\ttraining's l2: 0.229004\tvalid_1's l1: 0.867752\tvalid_1's l2: 1.36682\n",
      "[333]\ttraining's l1: 0.200605\ttraining's l2: 0.228698\tvalid_1's l1: 0.867468\tvalid_1's l2: 1.36623\n",
      "[334]\ttraining's l1: 0.200528\ttraining's l2: 0.22829\tvalid_1's l1: 0.867067\tvalid_1's l2: 1.36537\n",
      "[335]\ttraining's l1: 0.200138\ttraining's l2: 0.227954\tvalid_1's l1: 0.867595\tvalid_1's l2: 1.36769\n",
      "[336]\ttraining's l1: 0.199826\ttraining's l2: 0.227748\tvalid_1's l1: 0.867527\tvalid_1's l2: 1.36648\n",
      "[337]\ttraining's l1: 0.19957\ttraining's l2: 0.227378\tvalid_1's l1: 0.868253\tvalid_1's l2: 1.36871\n",
      "[338]\ttraining's l1: 0.199595\ttraining's l2: 0.227018\tvalid_1's l1: 0.868039\tvalid_1's l2: 1.36809\n",
      "[339]\ttraining's l1: 0.199318\ttraining's l2: 0.226653\tvalid_1's l1: 0.868548\tvalid_1's l2: 1.36943\n",
      "[340]\ttraining's l1: 0.199012\ttraining's l2: 0.226453\tvalid_1's l1: 0.868473\tvalid_1's l2: 1.36823\n",
      "[341]\ttraining's l1: 0.198794\ttraining's l2: 0.225881\tvalid_1's l1: 0.86887\tvalid_1's l2: 1.36918\n",
      "[342]\ttraining's l1: 0.198543\ttraining's l2: 0.225524\tvalid_1's l1: 0.869582\tvalid_1's l2: 1.37139\n",
      "[343]\ttraining's l1: 0.198681\ttraining's l2: 0.225285\tvalid_1's l1: 0.869408\tvalid_1's l2: 1.3709\n",
      "[344]\ttraining's l1: 0.198381\ttraining's l2: 0.225091\tvalid_1's l1: 0.869331\tvalid_1's l2: 1.3697\n",
      "[345]\ttraining's l1: 0.19828\ttraining's l2: 0.224675\tvalid_1's l1: 0.869157\tvalid_1's l2: 1.36929\n",
      "[346]\ttraining's l1: 0.198009\ttraining's l2: 0.224323\tvalid_1's l1: 0.869654\tvalid_1's l2: 1.37062\n",
      "[347]\ttraining's l1: 0.197795\ttraining's l2: 0.223774\tvalid_1's l1: 0.870044\tvalid_1's l2: 1.37157\n",
      "[348]\ttraining's l1: 0.197494\ttraining's l2: 0.223585\tvalid_1's l1: 0.869964\tvalid_1's l2: 1.37038\n",
      "[349]\ttraining's l1: 0.197394\ttraining's l2: 0.223183\tvalid_1's l1: 0.869795\tvalid_1's l2: 1.36998\n",
      "[350]\ttraining's l1: 0.197152\ttraining's l2: 0.222839\tvalid_1's l1: 0.870492\tvalid_1's l2: 1.37216\n",
      "[351]\ttraining's l1: 0.196862\ttraining's l2: 0.222655\tvalid_1's l1: 0.870411\tvalid_1's l2: 1.37098\n",
      "[352]\ttraining's l1: 0.196908\ttraining's l2: 0.222338\tvalid_1's l1: 0.870427\tvalid_1's l2: 1.37128\n",
      "[353]\ttraining's l1: 0.196812\ttraining's l2: 0.221945\tvalid_1's l1: 0.87026\tvalid_1's l2: 1.37089\n",
      "[354]\ttraining's l1: 0.19656\ttraining's l2: 0.221608\tvalid_1's l1: 0.870744\tvalid_1's l2: 1.3722\n",
      "[355]\ttraining's l1: 0.196273\ttraining's l2: 0.221428\tvalid_1's l1: 0.870722\tvalid_1's l2: 1.371\n",
      "[356]\ttraining's l1: 0.196208\ttraining's l2: 0.221044\tvalid_1's l1: 0.870556\tvalid_1's l2: 1.37062\n",
      "[357]\ttraining's l1: 0.196181\ttraining's l2: 0.220584\tvalid_1's l1: 0.869999\tvalid_1's l2: 1.36874\n",
      "[358]\ttraining's l1: 0.195892\ttraining's l2: 0.220408\tvalid_1's l1: 0.869981\tvalid_1's l2: 1.36756\n",
      "[359]\ttraining's l1: 0.196045\ttraining's l2: 0.220121\tvalid_1's l1: 0.869698\tvalid_1's l2: 1.36695\n",
      "[360]\ttraining's l1: 0.195623\ttraining's l2: 0.219561\tvalid_1's l1: 0.869483\tvalid_1's l2: 1.36662\n",
      "[361]\ttraining's l1: 0.195391\ttraining's l2: 0.219228\tvalid_1's l1: 0.870171\tvalid_1's l2: 1.36878\n",
      "[362]\ttraining's l1: 0.195107\ttraining's l2: 0.219056\tvalid_1's l1: 0.870154\tvalid_1's l2: 1.36763\n",
      "[363]\ttraining's l1: 0.194869\ttraining's l2: 0.218728\tvalid_1's l1: 0.870633\tvalid_1's l2: 1.36894\n",
      "[364]\ttraining's l1: 0.194813\ttraining's l2: 0.218355\tvalid_1's l1: 0.870468\tvalid_1's l2: 1.36857\n",
      "[365]\ttraining's l1: 0.194983\ttraining's l2: 0.218073\tvalid_1's l1: 0.870186\tvalid_1's l2: 1.36795\n",
      "[366]\ttraining's l1: 0.194968\ttraining's l2: 0.217629\tvalid_1's l1: 0.869634\tvalid_1's l2: 1.3661\n",
      "[367]\ttraining's l1: 0.194548\ttraining's l2: 0.217081\tvalid_1's l1: 0.869335\tvalid_1's l2: 1.36559\n",
      "[368]\ttraining's l1: 0.194338\ttraining's l2: 0.21657\tvalid_1's l1: 0.86892\tvalid_1's l2: 1.36454\n",
      "[369]\ttraining's l1: 0.194129\ttraining's l2: 0.216244\tvalid_1's l1: 0.869604\tvalid_1's l2: 1.3667\n",
      "[370]\ttraining's l1: 0.193862\ttraining's l2: 0.216078\tvalid_1's l1: 0.86959\tvalid_1's l2: 1.36558\n",
      "[371]\ttraining's l1: 0.193644\ttraining's l2: 0.215757\tvalid_1's l1: 0.870069\tvalid_1's l2: 1.3669\n",
      "[372]\ttraining's l1: 0.193384\ttraining's l2: 0.215594\tvalid_1's l1: 0.870074\tvalid_1's l2: 1.3658\n",
      "[373]\ttraining's l1: 0.193364\ttraining's l2: 0.215208\tvalid_1's l1: 0.869822\tvalid_1's l2: 1.36563\n",
      "[374]\ttraining's l1: 0.193152\ttraining's l2: 0.214716\tvalid_1's l1: 0.869302\tvalid_1's l2: 1.36465\n",
      "[375]\ttraining's l1: 0.192937\ttraining's l2: 0.214402\tvalid_1's l1: 0.869777\tvalid_1's l2: 1.36597\n",
      "[376]\ttraining's l1: 0.192889\ttraining's l2: 0.214045\tvalid_1's l1: 0.869618\tvalid_1's l2: 1.36562\n",
      "[377]\ttraining's l1: 0.19287\ttraining's l2: 0.213668\tvalid_1's l1: 0.86937\tvalid_1's l2: 1.36546\n",
      "[378]\ttraining's l1: 0.192478\ttraining's l2: 0.213135\tvalid_1's l1: 0.869161\tvalid_1's l2: 1.36515\n",
      "[379]\ttraining's l1: 0.192268\ttraining's l2: 0.212655\tvalid_1's l1: 0.868652\tvalid_1's l2: 1.3642\n",
      "[380]\ttraining's l1: 0.192077\ttraining's l2: 0.212344\tvalid_1's l1: 0.869319\tvalid_1's l2: 1.36631\n",
      "[381]\ttraining's l1: 0.191827\ttraining's l2: 0.212188\tvalid_1's l1: 0.869323\tvalid_1's l2: 1.36523\n",
      "[382]\ttraining's l1: 0.191825\ttraining's l2: 0.211821\tvalid_1's l1: 0.869079\tvalid_1's l2: 1.36508\n",
      "[383]\ttraining's l1: 0.191618\ttraining's l2: 0.211349\tvalid_1's l1: 0.868573\tvalid_1's l2: 1.36415\n",
      "[384]\ttraining's l1: 0.191406\ttraining's l2: 0.211045\tvalid_1's l1: 0.869042\tvalid_1's l2: 1.36546\n",
      "[385]\ttraining's l1: 0.191381\ttraining's l2: 0.2107\tvalid_1's l1: 0.868888\tvalid_1's l2: 1.36512\n",
      "[386]\ttraining's l1: 0.191382\ttraining's l2: 0.210342\tvalid_1's l1: 0.868648\tvalid_1's l2: 1.36498\n",
      "[387]\ttraining's l1: 0.191025\ttraining's l2: 0.209823\tvalid_1's l1: 0.868433\tvalid_1's l2: 1.36468\n",
      "[388]\ttraining's l1: 0.190819\ttraining's l2: 0.209363\tvalid_1's l1: 0.867934\tvalid_1's l2: 1.36377\n",
      "[389]\ttraining's l1: 0.19063\ttraining's l2: 0.209063\tvalid_1's l1: 0.868591\tvalid_1's l2: 1.36586\n",
      "[390]\ttraining's l1: 0.190382\ttraining's l2: 0.208913\tvalid_1's l1: 0.868594\tvalid_1's l2: 1.3648\n",
      "[391]\ttraining's l1: 0.190393\ttraining's l2: 0.208564\tvalid_1's l1: 0.868357\tvalid_1's l2: 1.36467\n",
      "[392]\ttraining's l1: 0.190041\ttraining's l2: 0.208057\tvalid_1's l1: 0.868155\tvalid_1's l2: 1.36438\n",
      "[393]\ttraining's l1: 0.189828\ttraining's l2: 0.207762\tvalid_1's l1: 0.868617\tvalid_1's l2: 1.36569\n",
      "[394]\ttraining's l1: 0.189646\ttraining's l2: 0.207311\tvalid_1's l1: 0.868121\tvalid_1's l2: 1.3648\n",
      "[395]\ttraining's l1: 0.189407\ttraining's l2: 0.207166\tvalid_1's l1: 0.868125\tvalid_1's l2: 1.36377\n",
      "[396]\ttraining's l1: 0.189423\ttraining's l2: 0.206832\tvalid_1's l1: 0.867975\tvalid_1's l2: 1.36344\n",
      "[397]\ttraining's l1: 0.189456\ttraining's l2: 0.206422\tvalid_1's l1: 0.867501\tvalid_1's l2: 1.36261\n",
      "[398]\ttraining's l1: 0.189287\ttraining's l2: 0.205981\tvalid_1's l1: 0.867012\tvalid_1's l2: 1.36173\n",
      "[399]\ttraining's l1: 0.189298\ttraining's l2: 0.205646\tvalid_1's l1: 0.866816\tvalid_1's l2: 1.36161\n",
      "[400]\ttraining's l1: 0.188961\ttraining's l2: 0.205154\tvalid_1's l1: 0.866669\tvalid_1's l2: 1.36135\n",
      "[401]\ttraining's l1: 0.188783\ttraining's l2: 0.204864\tvalid_1's l1: 0.867317\tvalid_1's l2: 1.36342\n",
      "[402]\ttraining's l1: 0.188662\ttraining's l2: 0.204563\tvalid_1's l1: 0.867434\tvalid_1's l2: 1.3641\n",
      "[403]\ttraining's l1: 0.188451\ttraining's l2: 0.204269\tvalid_1's l1: 0.86782\tvalid_1's l2: 1.36537\n",
      "[404]\ttraining's l1: 0.188223\ttraining's l2: 0.204129\tvalid_1's l1: 0.867822\tvalid_1's l2: 1.36436\n",
      "[405]\ttraining's l1: 0.188069\ttraining's l2: 0.203701\tvalid_1's l1: 0.867328\tvalid_1's l2: 1.36351\n",
      "[406]\ttraining's l1: 0.188103\ttraining's l2: 0.203305\tvalid_1's l1: 0.866911\tvalid_1's l2: 1.3627\n",
      "[407]\ttraining's l1: 0.187991\ttraining's l2: 0.203138\tvalid_1's l1: 0.867269\tvalid_1's l2: 1.36389\n",
      "[408]\ttraining's l1: 0.188027\ttraining's l2: 0.202819\tvalid_1's l1: 0.867201\tvalid_1's l2: 1.36358\n",
      "[409]\ttraining's l1: 0.187708\ttraining's l2: 0.202339\tvalid_1's l1: 0.867042\tvalid_1's l2: 1.36332\n",
      "[410]\ttraining's l1: 0.187592\ttraining's l2: 0.202175\tvalid_1's l1: 0.867399\tvalid_1's l2: 1.36452\n",
      "[411]\ttraining's l1: 0.187366\ttraining's l2: 0.202038\tvalid_1's l1: 0.867405\tvalid_1's l2: 1.36354\n",
      "[412]\ttraining's l1: 0.187214\ttraining's l2: 0.201619\tvalid_1's l1: 0.866946\tvalid_1's l2: 1.3627\n",
      "[413]\ttraining's l1: 0.18707\ttraining's l2: 0.201457\tvalid_1's l1: 0.866837\tvalid_1's l2: 1.36279\n",
      "[414]\ttraining's l1: 0.186862\ttraining's l2: 0.201169\tvalid_1's l1: 0.867223\tvalid_1's l2: 1.36406\n",
      "[415]\ttraining's l1: 0.186872\ttraining's l2: 0.20085\tvalid_1's l1: 0.867041\tvalid_1's l2: 1.36387\n",
      "[416]\ttraining's l1: 0.186673\ttraining's l2: 0.200567\tvalid_1's l1: 0.867424\tvalid_1's l2: 1.3652\n",
      "[417]\ttraining's l1: 0.186713\ttraining's l2: 0.200256\tvalid_1's l1: 0.867359\tvalid_1's l2: 1.36489\n",
      "[418]\ttraining's l1: 0.186571\ttraining's l2: 0.199845\tvalid_1's l1: 0.866901\tvalid_1's l2: 1.36406\n",
      "[419]\ttraining's l1: 0.186288\ttraining's l2: 0.199376\tvalid_1's l1: 0.866739\tvalid_1's l2: 1.36379\n",
      "[420]\ttraining's l1: 0.186337\ttraining's l2: 0.198996\tvalid_1's l1: 0.866264\tvalid_1's l2: 1.36296\n",
      "[421]\ttraining's l1: 0.186224\ttraining's l2: 0.198834\tvalid_1's l1: 0.866615\tvalid_1's l2: 1.36414\n",
      "[422]\ttraining's l1: 0.185999\ttraining's l2: 0.198703\tvalid_1's l1: 0.866619\tvalid_1's l2: 1.36318\n",
      "[423]\ttraining's l1: 0.185713\ttraining's l2: 0.198243\tvalid_1's l1: 0.86638\tvalid_1's l2: 1.36274\n",
      "[424]\ttraining's l1: 0.185566\ttraining's l2: 0.198083\tvalid_1's l1: 0.86636\tvalid_1's l2: 1.36287\n",
      "[425]\ttraining's l1: 0.185573\ttraining's l2: 0.197777\tvalid_1's l1: 0.866218\tvalid_1's l2: 1.36278\n",
      "[426]\ttraining's l1: 0.185381\ttraining's l2: 0.197497\tvalid_1's l1: 0.866775\tvalid_1's l2: 1.36474\n",
      "[427]\ttraining's l1: 0.185246\ttraining's l2: 0.197098\tvalid_1's l1: 0.866324\tvalid_1's l2: 1.36393\n",
      "[428]\ttraining's l1: 0.185036\ttraining's l2: 0.196821\tvalid_1's l1: 0.866701\tvalid_1's l2: 1.36518\n",
      "[429]\ttraining's l1: 0.18506\ttraining's l2: 0.196474\tvalid_1's l1: 0.866342\tvalid_1's l2: 1.36483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[430]\ttraining's l1: 0.184833\ttraining's l2: 0.196346\tvalid_1's l1: 0.866286\tvalid_1's l2: 1.36386\n",
      "[431]\ttraining's l1: 0.18487\ttraining's l2: 0.196047\tvalid_1's l1: 0.866226\tvalid_1's l2: 1.36358\n",
      "[432]\ttraining's l1: 0.184884\ttraining's l2: 0.195752\tvalid_1's l1: 0.866055\tvalid_1's l2: 1.36342\n",
      "[433]\ttraining's l1: 0.184748\ttraining's l2: 0.195361\tvalid_1's l1: 0.865609\tvalid_1's l2: 1.36262\n",
      "[434]\ttraining's l1: 0.18448\ttraining's l2: 0.19491\tvalid_1's l1: 0.865452\tvalid_1's l2: 1.36237\n",
      "[435]\ttraining's l1: 0.184368\ttraining's l2: 0.194751\tvalid_1's l1: 0.865806\tvalid_1's l2: 1.36354\n",
      "[436]\ttraining's l1: 0.184133\ttraining's l2: 0.194309\tvalid_1's l1: 0.865649\tvalid_1's l2: 1.36329\n",
      "[437]\ttraining's l1: 0.184016\ttraining's l2: 0.194152\tvalid_1's l1: 0.866001\tvalid_1's l2: 1.36447\n",
      "[438]\ttraining's l1: 0.183851\ttraining's l2: 0.19388\tvalid_1's l1: 0.866377\tvalid_1's l2: 1.36578\n",
      "[439]\ttraining's l1: 0.183634\ttraining's l2: 0.193755\tvalid_1's l1: 0.866323\tvalid_1's l2: 1.36483\n",
      "[440]\ttraining's l1: 0.183484\ttraining's l2: 0.193343\tvalid_1's l1: 0.86605\tvalid_1's l2: 1.36425\n",
      "[441]\ttraining's l1: 0.183325\ttraining's l2: 0.193075\tvalid_1's l1: 0.866427\tvalid_1's l2: 1.36552\n",
      "[442]\ttraining's l1: 0.183241\ttraining's l2: 0.192817\tvalid_1's l1: 0.866182\tvalid_1's l2: 1.36423\n",
      "[443]\ttraining's l1: 0.18316\ttraining's l2: 0.192409\tvalid_1's l1: 0.865936\tvalid_1's l2: 1.36392\n",
      "[444]\ttraining's l1: 0.183051\ttraining's l2: 0.192255\tvalid_1's l1: 0.866283\tvalid_1's l2: 1.36507\n",
      "[445]\ttraining's l1: 0.182935\ttraining's l2: 0.191974\tvalid_1's l1: 0.866167\tvalid_1's l2: 1.3653\n",
      "[446]\ttraining's l1: 0.182826\ttraining's l2: 0.191823\tvalid_1's l1: 0.866512\tvalid_1's l2: 1.36645\n",
      "[447]\ttraining's l1: 0.182684\ttraining's l2: 0.191419\tvalid_1's l1: 0.866152\tvalid_1's l2: 1.3656\n",
      "[448]\ttraining's l1: 0.182481\ttraining's l2: 0.191152\tvalid_1's l1: 0.866696\tvalid_1's l2: 1.36753\n",
      "[449]\ttraining's l1: 0.182392\ttraining's l2: 0.190883\tvalid_1's l1: 0.866832\tvalid_1's l2: 1.36817\n",
      "[450]\ttraining's l1: 0.182232\ttraining's l2: 0.19062\tvalid_1's l1: 0.867202\tvalid_1's l2: 1.36947\n",
      "[451]\ttraining's l1: 0.182099\ttraining's l2: 0.190411\tvalid_1's l1: 0.867011\tvalid_1's l2: 1.36864\n",
      "[452]\ttraining's l1: 0.181906\ttraining's l2: 0.190292\tvalid_1's l1: 0.867007\tvalid_1's l2: 1.36772\n",
      "[453]\ttraining's l1: 0.18172\ttraining's l2: 0.189895\tvalid_1's l1: 0.866828\tvalid_1's l2: 1.36738\n",
      "[454]\ttraining's l1: 0.181528\ttraining's l2: 0.189634\tvalid_1's l1: 0.867367\tvalid_1's l2: 1.36929\n",
      "[455]\ttraining's l1: 0.181466\ttraining's l2: 0.189386\tvalid_1's l1: 0.867125\tvalid_1's l2: 1.36802\n",
      "[456]\ttraining's l1: 0.18135\ttraining's l2: 0.189022\tvalid_1's l1: 0.866694\tvalid_1's l2: 1.36727\n",
      "[457]\ttraining's l1: 0.181242\ttraining's l2: 0.188872\tvalid_1's l1: 0.866962\tvalid_1's l2: 1.36835\n",
      "[458]\ttraining's l1: 0.181155\ttraining's l2: 0.188599\tvalid_1's l1: 0.866847\tvalid_1's l2: 1.36858\n",
      "[459]\ttraining's l1: 0.181042\ttraining's l2: 0.188451\tvalid_1's l1: 0.867116\tvalid_1's l2: 1.36967\n",
      "[460]\ttraining's l1: 0.18087\ttraining's l2: 0.188194\tvalid_1's l1: 0.86748\tvalid_1's l2: 1.3709\n",
      "[461]\ttraining's l1: 0.180787\ttraining's l2: 0.187925\tvalid_1's l1: 0.867385\tvalid_1's l2: 1.37112\n",
      "[462]\ttraining's l1: 0.180683\ttraining's l2: 0.187568\tvalid_1's l1: 0.866956\tvalid_1's l2: 1.37038\n",
      "[463]\ttraining's l1: 0.180581\ttraining's l2: 0.187422\tvalid_1's l1: 0.867228\tvalid_1's l2: 1.37146\n",
      "[464]\ttraining's l1: 0.180559\ttraining's l2: 0.187085\tvalid_1's l1: 0.867075\tvalid_1's l2: 1.371\n",
      "[465]\ttraining's l1: 0.180456\ttraining's l2: 0.186941\tvalid_1's l1: 0.866985\tvalid_1's l2: 1.37108\n",
      "[466]\ttraining's l1: 0.180464\ttraining's l2: 0.186659\tvalid_1's l1: 0.866898\tvalid_1's l2: 1.37081\n",
      "[467]\ttraining's l1: 0.180342\ttraining's l2: 0.186461\tvalid_1's l1: 0.86672\tvalid_1's l2: 1.37\n",
      "[468]\ttraining's l1: 0.180324\ttraining's l2: 0.186133\tvalid_1's l1: 0.86657\tvalid_1's l2: 1.36956\n",
      "[469]\ttraining's l1: 0.180255\ttraining's l2: 0.185991\tvalid_1's l1: 0.866868\tvalid_1's l2: 1.37065\n",
      "[470]\ttraining's l1: 0.180143\ttraining's l2: 0.185574\tvalid_1's l1: 0.86672\tvalid_1's l2: 1.37042\n",
      "[471]\ttraining's l1: 0.180069\ttraining's l2: 0.185434\tvalid_1's l1: 0.867017\tvalid_1's l2: 1.37151\n",
      "[472]\ttraining's l1: 0.180017\ttraining's l2: 0.185055\tvalid_1's l1: 0.866741\tvalid_1's l2: 1.37097\n",
      "[473]\ttraining's l1: 0.179942\ttraining's l2: 0.184916\tvalid_1's l1: 0.866681\tvalid_1's l2: 1.37108\n",
      "[474]\ttraining's l1: 0.179852\ttraining's l2: 0.184777\tvalid_1's l1: 0.866943\tvalid_1's l2: 1.37217\n",
      "[475]\ttraining's l1: 0.179793\ttraining's l2: 0.184515\tvalid_1's l1: 0.866816\tvalid_1's l2: 1.37227\n",
      "[476]\ttraining's l1: 0.179719\ttraining's l2: 0.184378\tvalid_1's l1: 0.866754\tvalid_1's l2: 1.37237\n",
      "[477]\ttraining's l1: 0.179674\ttraining's l2: 0.184007\tvalid_1's l1: 0.866479\tvalid_1's l2: 1.37184\n",
      "[478]\ttraining's l1: 0.179483\ttraining's l2: 0.183755\tvalid_1's l1: 0.867027\tvalid_1's l2: 1.37374\n",
      "[479]\ttraining's l1: 0.179328\ttraining's l2: 0.183508\tvalid_1's l1: 0.867405\tvalid_1's l2: 1.37503\n",
      "[480]\ttraining's l1: 0.179246\ttraining's l2: 0.183315\tvalid_1's l1: 0.867228\tvalid_1's l2: 1.37423\n",
      "[481]\ttraining's l1: 0.179062\ttraining's l2: 0.183203\tvalid_1's l1: 0.867208\tvalid_1's l2: 1.37332\n",
      "[482]\ttraining's l1: 0.179028\ttraining's l2: 0.182934\tvalid_1's l1: 0.867038\tvalid_1's l2: 1.37271\n",
      "[483]\ttraining's l1: 0.178884\ttraining's l2: 0.182568\tvalid_1's l1: 0.866852\tvalid_1's l2: 1.37241\n",
      "[484]\ttraining's l1: 0.178698\ttraining's l2: 0.182323\tvalid_1's l1: 0.867392\tvalid_1's l2: 1.37429\n",
      "[485]\ttraining's l1: 0.178636\ttraining's l2: 0.182134\tvalid_1's l1: 0.867218\tvalid_1's l2: 1.3735\n",
      "[486]\ttraining's l1: 0.178561\ttraining's l2: 0.181878\tvalid_1's l1: 0.867093\tvalid_1's l2: 1.3736\n",
      "[487]\ttraining's l1: 0.178524\ttraining's l2: 0.181519\tvalid_1's l1: 0.866824\tvalid_1's l2: 1.3731\n",
      "[488]\ttraining's l1: 0.178354\ttraining's l2: 0.181275\tvalid_1's l1: 0.867206\tvalid_1's l2: 1.37435\n",
      "[489]\ttraining's l1: 0.17837\ttraining's l2: 0.180963\tvalid_1's l1: 0.866875\tvalid_1's l2: 1.37405\n",
      "[490]\ttraining's l1: 0.178219\ttraining's l2: 0.180723\tvalid_1's l1: 0.867246\tvalid_1's l2: 1.37533\n",
      "[491]\ttraining's l1: 0.178158\ttraining's l2: 0.180538\tvalid_1's l1: 0.867076\tvalid_1's l2: 1.37456\n",
      "[492]\ttraining's l1: 0.178019\ttraining's l2: 0.180185\tvalid_1's l1: 0.866894\tvalid_1's l2: 1.37427\n",
      "[493]\ttraining's l1: 0.177837\ttraining's l2: 0.179947\tvalid_1's l1: 0.867435\tvalid_1's l2: 1.37615\n",
      "[494]\ttraining's l1: 0.177853\ttraining's l2: 0.179655\tvalid_1's l1: 0.867048\tvalid_1's l2: 1.37533\n",
      "[495]\ttraining's l1: 0.177826\ttraining's l2: 0.179433\tvalid_1's l1: 0.866805\tvalid_1's l2: 1.3741\n",
      "[496]\ttraining's l1: 0.177762\ttraining's l2: 0.179296\tvalid_1's l1: 0.867091\tvalid_1's l2: 1.37516\n",
      "[497]\ttraining's l1: 0.177702\ttraining's l2: 0.179045\tvalid_1's l1: 0.866968\tvalid_1's l2: 1.37527\n",
      "[498]\ttraining's l1: 0.177632\ttraining's l2: 0.17891\tvalid_1's l1: 0.867252\tvalid_1's l2: 1.37633\n",
      "[499]\ttraining's l1: 0.177615\ttraining's l2: 0.178561\tvalid_1's l1: 0.866988\tvalid_1's l2: 1.37585\n",
      "[500]\ttraining's l1: 0.177546\ttraining's l2: 0.178428\tvalid_1's l1: 0.867272\tvalid_1's l2: 1.3769\n",
      "[501]\ttraining's l1: 0.177493\ttraining's l2: 0.178182\tvalid_1's l1: 0.867149\tvalid_1's l2: 1.37701\n",
      "[502]\ttraining's l1: 0.177337\ttraining's l2: 0.178049\tvalid_1's l1: 0.867462\tvalid_1's l2: 1.37816\n",
      "[503]\ttraining's l1: 0.177218\ttraining's l2: 0.177705\tvalid_1's l1: 0.867282\tvalid_1's l2: 1.37789\n",
      "[504]\ttraining's l1: 0.177149\ttraining's l2: 0.177573\tvalid_1's l1: 0.867564\tvalid_1's l2: 1.37894\n",
      "[505]\ttraining's l1: 0.176983\ttraining's l2: 0.177337\tvalid_1's l1: 0.867937\tvalid_1's l2: 1.38018\n",
      "[506]\ttraining's l1: 0.177068\ttraining's l2: 0.177035\tvalid_1's l1: 0.867786\tvalid_1's l2: 1.37975\n",
      "[507]\ttraining's l1: 0.177051\ttraining's l2: 0.176696\tvalid_1's l1: 0.867523\tvalid_1's l2: 1.37928\n",
      "[508]\ttraining's l1: 0.176902\ttraining's l2: 0.176566\tvalid_1's l1: 0.86783\tvalid_1's l2: 1.38045\n",
      "[509]\ttraining's l1: 0.176724\ttraining's l2: 0.176204\tvalid_1's l1: 0.867874\tvalid_1's l2: 1.38139\n",
      "[510]\ttraining's l1: 0.176714\ttraining's l2: 0.176028\tvalid_1's l1: 0.86771\tvalid_1's l2: 1.38064\n",
      "[511]\ttraining's l1: 0.176648\ttraining's l2: 0.1759\tvalid_1's l1: 0.86796\tvalid_1's l2: 1.38165\n",
      "[512]\ttraining's l1: 0.176685\ttraining's l2: 0.175647\tvalid_1's l1: 0.867795\tvalid_1's l2: 1.38107\n",
      "[513]\ttraining's l1: 0.176629\ttraining's l2: 0.175407\tvalid_1's l1: 0.867674\tvalid_1's l2: 1.38118\n",
      "[514]\ttraining's l1: 0.176478\ttraining's l2: 0.175279\tvalid_1's l1: 0.867978\tvalid_1's l2: 1.38235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[515]\ttraining's l1: 0.176412\ttraining's l2: 0.175153\tvalid_1's l1: 0.868224\tvalid_1's l2: 1.38335\n",
      "[516]\ttraining's l1: 0.176296\ttraining's l2: 0.174819\tvalid_1's l1: 0.868045\tvalid_1's l2: 1.38309\n",
      "[517]\ttraining's l1: 0.176148\ttraining's l2: 0.174588\tvalid_1's l1: 0.868411\tvalid_1's l2: 1.38437\n",
      "[518]\ttraining's l1: 0.175957\ttraining's l2: 0.174483\tvalid_1's l1: 0.868399\tvalid_1's l2: 1.3835\n",
      "[519]\ttraining's l1: 0.175777\ttraining's l2: 0.174256\tvalid_1's l1: 0.868916\tvalid_1's l2: 1.38532\n",
      "[520]\ttraining's l1: 0.175657\ttraining's l2: 0.17394\tvalid_1's l1: 0.868514\tvalid_1's l2: 1.38466\n",
      "[521]\ttraining's l1: 0.175647\ttraining's l2: 0.173767\tvalid_1's l1: 0.868351\tvalid_1's l2: 1.38391\n",
      "[522]\ttraining's l1: 0.175607\ttraining's l2: 0.173533\tvalid_1's l1: 0.868231\tvalid_1's l2: 1.38402\n",
      "[523]\ttraining's l1: 0.1753\ttraining's l2: 0.173056\tvalid_1's l1: 0.868681\tvalid_1's l2: 1.38579\n",
      "[524]\ttraining's l1: 0.175293\ttraining's l2: 0.172886\tvalid_1's l1: 0.868519\tvalid_1's l2: 1.38505\n",
      "[525]\ttraining's l1: 0.175297\ttraining's l2: 0.172561\tvalid_1's l1: 0.868261\tvalid_1's l2: 1.38459\n",
      "[526]\ttraining's l1: 0.175133\ttraining's l2: 0.172333\tvalid_1's l1: 0.868628\tvalid_1's l2: 1.38586\n",
      "[527]\ttraining's l1: 0.174961\ttraining's l2: 0.172232\tvalid_1's l1: 0.868616\tvalid_1's l2: 1.38501\n",
      "[528]\ttraining's l1: 0.174967\ttraining's l2: 0.172066\tvalid_1's l1: 0.868457\tvalid_1's l2: 1.38428\n",
      "[529]\ttraining's l1: 0.175017\ttraining's l2: 0.17178\tvalid_1's l1: 0.868226\tvalid_1's l2: 1.38373\n",
      "[530]\ttraining's l1: 0.17484\ttraining's l2: 0.171554\tvalid_1's l1: 0.868589\tvalid_1's l2: 1.38495\n",
      "[531]\ttraining's l1: 0.174648\ttraining's l2: 0.171331\tvalid_1's l1: 0.869105\tvalid_1's l2: 1.38675\n",
      "[532]\ttraining's l1: 0.174601\ttraining's l2: 0.171219\tvalid_1's l1: 0.868949\tvalid_1's l2: 1.38596\n",
      "[533]\ttraining's l1: 0.174506\ttraining's l2: 0.170951\tvalid_1's l1: 0.868891\tvalid_1's l2: 1.38645\n",
      "[534]\ttraining's l1: 0.174511\ttraining's l2: 0.170634\tvalid_1's l1: 0.868635\tvalid_1's l2: 1.386\n",
      "[535]\ttraining's l1: 0.174359\ttraining's l2: 0.170414\tvalid_1's l1: 0.868996\tvalid_1's l2: 1.38725\n",
      "[536]\ttraining's l1: 0.174328\ttraining's l2: 0.170302\tvalid_1's l1: 0.868827\tvalid_1's l2: 1.38645\n",
      "[537]\ttraining's l1: 0.17428\ttraining's l2: 0.170076\tvalid_1's l1: 0.868713\tvalid_1's l2: 1.38658\n",
      "[538]\ttraining's l1: 0.174179\ttraining's l2: 0.169803\tvalid_1's l1: 0.868599\tvalid_1's l2: 1.38637\n",
      "[539]\ttraining's l1: 0.174181\ttraining's l2: 0.169526\tvalid_1's l1: 0.86822\tvalid_1's l2: 1.38558\n",
      "[540]\ttraining's l1: 0.174041\ttraining's l2: 0.169307\tvalid_1's l1: 0.868578\tvalid_1's l2: 1.38678\n",
      "[541]\ttraining's l1: 0.173973\ttraining's l2: 0.169047\tvalid_1's l1: 0.868524\tvalid_1's l2: 1.38728\n",
      "[542]\ttraining's l1: 0.173833\ttraining's l2: 0.168705\tvalid_1's l1: 0.868566\tvalid_1's l2: 1.38822\n",
      "[543]\ttraining's l1: 0.173797\ttraining's l2: 0.168594\tvalid_1's l1: 0.868411\tvalid_1's l2: 1.38743\n",
      "[544]\ttraining's l1: 0.173728\ttraining's l2: 0.168486\tvalid_1's l1: 0.868236\tvalid_1's l2: 1.38688\n",
      "[545]\ttraining's l1: 0.173657\ttraining's l2: 0.168178\tvalid_1's l1: 0.868066\tvalid_1's l2: 1.38666\n",
      "[546]\ttraining's l1: 0.173605\ttraining's l2: 0.168054\tvalid_1's l1: 0.868305\tvalid_1's l2: 1.38764\n",
      "[547]\ttraining's l1: 0.173421\ttraining's l2: 0.167837\tvalid_1's l1: 0.868816\tvalid_1's l2: 1.38943\n",
      "[548]\ttraining's l1: 0.17326\ttraining's l2: 0.16774\tvalid_1's l1: 0.8688\tvalid_1's l2: 1.38859\n",
      "[549]\ttraining's l1: 0.173281\ttraining's l2: 0.167582\tvalid_1's l1: 0.868645\tvalid_1's l2: 1.38788\n",
      "[550]\ttraining's l1: 0.173349\ttraining's l2: 0.167307\tvalid_1's l1: 0.868501\tvalid_1's l2: 1.38748\n",
      "[551]\ttraining's l1: 0.173263\ttraining's l2: 0.167044\tvalid_1's l1: 0.86839\tvalid_1's l2: 1.38728\n",
      "[552]\ttraining's l1: 0.173143\ttraining's l2: 0.166829\tvalid_1's l1: 0.868748\tvalid_1's l2: 1.38853\n",
      "[553]\ttraining's l1: 0.173083\ttraining's l2: 0.166609\tvalid_1's l1: 0.868639\tvalid_1's l2: 1.38867\n",
      "[554]\ttraining's l1: 0.173021\ttraining's l2: 0.166504\tvalid_1's l1: 0.868438\tvalid_1's l2: 1.3881\n",
      "[555]\ttraining's l1: 0.17293\ttraining's l2: 0.166245\tvalid_1's l1: 0.868328\tvalid_1's l2: 1.38791\n",
      "[556]\ttraining's l1: 0.172941\ttraining's l2: 0.165977\tvalid_1's l1: 0.867956\tvalid_1's l2: 1.38713\n",
      "[557]\ttraining's l1: 0.172888\ttraining's l2: 0.165857\tvalid_1's l1: 0.868193\tvalid_1's l2: 1.38811\n",
      "[558]\ttraining's l1: 0.172822\ttraining's l2: 0.16564\tvalid_1's l1: 0.868086\tvalid_1's l2: 1.38825\n",
      "[559]\ttraining's l1: 0.172694\ttraining's l2: 0.165522\tvalid_1's l1: 0.868351\tvalid_1's l2: 1.38932\n",
      "[560]\ttraining's l1: 0.172619\ttraining's l2: 0.165225\tvalid_1's l1: 0.868182\tvalid_1's l2: 1.38911\n",
      "[561]\ttraining's l1: 0.172512\ttraining's l2: 0.165011\tvalid_1's l1: 0.868537\tvalid_1's l2: 1.39031\n",
      "[562]\ttraining's l1: 0.172418\ttraining's l2: 0.164682\tvalid_1's l1: 0.868575\tvalid_1's l2: 1.39077\n",
      "[563]\ttraining's l1: 0.172263\ttraining's l2: 0.16447\tvalid_1's l1: 0.869078\tvalid_1's l2: 1.39255\n",
      "[564]\ttraining's l1: 0.172275\ttraining's l2: 0.164316\tvalid_1's l1: 0.868927\tvalid_1's l2: 1.39184\n",
      "[565]\ttraining's l1: 0.172186\ttraining's l2: 0.164108\tvalid_1's l1: 0.86928\tvalid_1's l2: 1.39307\n",
      "[566]\ttraining's l1: 0.172128\ttraining's l2: 0.164005\tvalid_1's l1: 0.869075\tvalid_1's l2: 1.3925\n",
      "[567]\ttraining's l1: 0.171983\ttraining's l2: 0.163912\tvalid_1's l1: 0.869065\tvalid_1's l2: 1.39167\n",
      "[568]\ttraining's l1: 0.17203\ttraining's l2: 0.163646\tvalid_1's l1: 0.86894\tvalid_1's l2: 1.39127\n",
      "[569]\ttraining's l1: 0.171941\ttraining's l2: 0.163391\tvalid_1's l1: 0.868916\tvalid_1's l2: 1.39121\n",
      "[570]\ttraining's l1: 0.171852\ttraining's l2: 0.163141\tvalid_1's l1: 0.868836\tvalid_1's l2: 1.39103\n",
      "[571]\ttraining's l1: 0.171791\ttraining's l2: 0.16304\tvalid_1's l1: 0.868635\tvalid_1's l2: 1.39047\n",
      "[572]\ttraining's l1: 0.171735\ttraining's l2: 0.162923\tvalid_1's l1: 0.868875\tvalid_1's l2: 1.39142\n",
      "[573]\ttraining's l1: 0.171723\ttraining's l2: 0.162696\tvalid_1's l1: 0.868821\tvalid_1's l2: 1.39095\n",
      "[574]\ttraining's l1: 0.171673\ttraining's l2: 0.162485\tvalid_1's l1: 0.868685\tvalid_1's l2: 1.3911\n",
      "[575]\ttraining's l1: 0.171584\ttraining's l2: 0.162239\tvalid_1's l1: 0.868606\tvalid_1's l2: 1.39092\n",
      "[576]\ttraining's l1: 0.171431\ttraining's l2: 0.162031\tvalid_1's l1: 0.86912\tvalid_1's l2: 1.39269\n",
      "[577]\ttraining's l1: 0.171132\ttraining's l2: 0.161719\tvalid_1's l1: 0.868997\tvalid_1's l2: 1.3922\n",
      "[578]\ttraining's l1: 0.170983\ttraining's l2: 0.161467\tvalid_1's l1: 0.86871\tvalid_1's l2: 1.39213\n",
      "[579]\ttraining's l1: 0.170997\ttraining's l2: 0.161319\tvalid_1's l1: 0.868573\tvalid_1's l2: 1.39144\n",
      "[580]\ttraining's l1: 0.170905\ttraining's l2: 0.161115\tvalid_1's l1: 0.868929\tvalid_1's l2: 1.39263\n",
      "[581]\ttraining's l1: 0.170764\ttraining's l2: 0.161024\tvalid_1's l1: 0.868921\tvalid_1's l2: 1.39182\n",
      "[582]\ttraining's l1: 0.170758\ttraining's l2: 0.160766\tvalid_1's l1: 0.868556\tvalid_1's l2: 1.39106\n",
      "[583]\ttraining's l1: 0.170701\ttraining's l2: 0.160668\tvalid_1's l1: 0.868357\tvalid_1's l2: 1.39051\n",
      "[584]\ttraining's l1: 0.170582\ttraining's l2: 0.160554\tvalid_1's l1: 0.868623\tvalid_1's l2: 1.39156\n",
      "[585]\ttraining's l1: 0.170577\ttraining's l2: 0.160349\tvalid_1's l1: 0.868481\tvalid_1's l2: 1.39175\n",
      "[586]\ttraining's l1: 0.170525\ttraining's l2: 0.160235\tvalid_1's l1: 0.868717\tvalid_1's l2: 1.39269\n",
      "[587]\ttraining's l1: 0.170437\ttraining's l2: 0.159995\tvalid_1's l1: 0.868639\tvalid_1's l2: 1.39252\n",
      "[588]\ttraining's l1: 0.170143\ttraining's l2: 0.159692\tvalid_1's l1: 0.868687\tvalid_1's l2: 1.3923\n",
      "[589]\ttraining's l1: 0.170069\ttraining's l2: 0.15949\tvalid_1's l1: 0.869041\tvalid_1's l2: 1.39352\n",
      "[590]\ttraining's l1: 0.169972\ttraining's l2: 0.159177\tvalid_1's l1: 0.869102\tvalid_1's l2: 1.39398\n",
      "[591]\ttraining's l1: 0.169834\ttraining's l2: 0.158979\tvalid_1's l1: 0.869599\tvalid_1's l2: 1.39572\n",
      "[592]\ttraining's l1: 0.169798\ttraining's l2: 0.158877\tvalid_1's l1: 0.86944\tvalid_1's l2: 1.39493\n",
      "[593]\ttraining's l1: 0.169846\ttraining's l2: 0.158651\tvalid_1's l1: 0.869415\tvalid_1's l2: 1.39484\n",
      "[594]\ttraining's l1: 0.169891\ttraining's l2: 0.158396\tvalid_1's l1: 0.869291\tvalid_1's l2: 1.39444\n",
      "[595]\ttraining's l1: 0.16982\ttraining's l2: 0.158201\tvalid_1's l1: 0.869185\tvalid_1's l2: 1.39406\n",
      "[596]\ttraining's l1: 0.169702\ttraining's l2: 0.158088\tvalid_1's l1: 0.86947\tvalid_1's l2: 1.39517\n",
      "[597]\ttraining's l1: 0.169401\ttraining's l2: 0.157791\tvalid_1's l1: 0.869517\tvalid_1's l2: 1.39495\n",
      "[598]\ttraining's l1: 0.169283\ttraining's l2: 0.157485\tvalid_1's l1: 0.869583\tvalid_1's l2: 1.39587\n",
      "[599]\ttraining's l1: 0.169283\ttraining's l2: 0.157337\tvalid_1's l1: 0.869473\tvalid_1's l2: 1.39524\n",
      "[600]\ttraining's l1: 0.169298\ttraining's l2: 0.157192\tvalid_1's l1: 0.869364\tvalid_1's l2: 1.39463\n",
      "[601]\ttraining's l1: 0.169348\ttraining's l2: 0.156943\tvalid_1's l1: 0.869107\tvalid_1's l2: 1.39412\n",
      "[602]\ttraining's l1: 0.169238\ttraining's l2: 0.156831\tvalid_1's l1: 0.869392\tvalid_1's l2: 1.39522\n",
      "[603]\ttraining's l1: 0.169097\ttraining's l2: 0.156634\tvalid_1's l1: 0.869889\tvalid_1's l2: 1.39697\n",
      "[604]\ttraining's l1: 0.169042\ttraining's l2: 0.156396\tvalid_1's l1: 0.869728\tvalid_1's l2: 1.39685\n",
      "[605]\ttraining's l1: 0.168861\ttraining's l2: 0.156099\tvalid_1's l1: 0.869602\tvalid_1's l2: 1.39679\n",
      "[606]\ttraining's l1: 0.168764\ttraining's l2: 0.155905\tvalid_1's l1: 0.869946\tvalid_1's l2: 1.39796\n",
      "[607]\ttraining's l1: 0.168691\ttraining's l2: 0.155706\tvalid_1's l1: 0.869812\tvalid_1's l2: 1.3981\n",
      "[608]\ttraining's l1: 0.168608\ttraining's l2: 0.155408\tvalid_1's l1: 0.869877\tvalid_1's l2: 1.39902\n",
      "[609]\ttraining's l1: 0.168566\ttraining's l2: 0.155309\tvalid_1's l1: 0.869723\tvalid_1's l2: 1.39825\n",
      "[610]\ttraining's l1: 0.16852\ttraining's l2: 0.155215\tvalid_1's l1: 0.869525\tvalid_1's l2: 1.39769\n",
      "[611]\ttraining's l1: 0.168582\ttraining's l2: 0.154973\tvalid_1's l1: 0.869403\tvalid_1's l2: 1.39732\n",
      "[612]\ttraining's l1: 0.168466\ttraining's l2: 0.154863\tvalid_1's l1: 0.869686\tvalid_1's l2: 1.39842\n",
      "[613]\ttraining's l1: 0.168346\ttraining's l2: 0.154755\tvalid_1's l1: 0.869943\tvalid_1's l2: 1.39945\n",
      "[614]\ttraining's l1: 0.168405\ttraining's l2: 0.154539\tvalid_1's l1: 0.869924\tvalid_1's l2: 1.39936\n",
      "[615]\ttraining's l1: 0.168359\ttraining's l2: 0.15432\tvalid_1's l1: 0.869806\tvalid_1's l2: 1.39965\n",
      "[616]\ttraining's l1: 0.168308\ttraining's l2: 0.154213\tvalid_1's l1: 0.870033\tvalid_1's l2: 1.40056\n",
      "[617]\ttraining's l1: 0.168213\ttraining's l2: 0.153986\tvalid_1's l1: 0.869942\tvalid_1's l2: 1.4004\n",
      "[618]\ttraining's l1: 0.16806\ttraining's l2: 0.153794\tvalid_1's l1: 0.870432\tvalid_1's l2: 1.40212\n",
      "[619]\ttraining's l1: 0.16792\ttraining's l2: 0.153711\tvalid_1's l1: 0.870421\tvalid_1's l2: 1.40134\n",
      "[620]\ttraining's l1: 0.167936\ttraining's l2: 0.153466\tvalid_1's l1: 0.870302\tvalid_1's l2: 1.40078\n",
      "[621]\ttraining's l1: 0.167953\ttraining's l2: 0.153256\tvalid_1's l1: 0.870269\tvalid_1's l2: 1.40034\n",
      "[622]\ttraining's l1: 0.167821\ttraining's l2: 0.152971\tvalid_1's l1: 0.870153\tvalid_1's l2: 1.40029\n",
      "[623]\ttraining's l1: 0.16781\ttraining's l2: 0.152756\tvalid_1's l1: 0.870009\tvalid_1's l2: 1.40048\n",
      "[624]\ttraining's l1: 0.167719\ttraining's l2: 0.152566\tvalid_1's l1: 0.870352\tvalid_1's l2: 1.40167\n",
      "[625]\ttraining's l1: 0.167615\ttraining's l2: 0.152292\tvalid_1's l1: 0.870574\tvalid_1's l2: 1.40244\n",
      "[626]\ttraining's l1: 0.167578\ttraining's l2: 0.15208\tvalid_1's l1: 0.870417\tvalid_1's l2: 1.40258\n",
      "[627]\ttraining's l1: 0.167461\ttraining's l2: 0.151849\tvalid_1's l1: 0.870164\tvalid_1's l2: 1.40252\n",
      "[628]\ttraining's l1: 0.167468\ttraining's l2: 0.151711\tvalid_1's l1: 0.870068\tvalid_1's l2: 1.40192\n",
      "[629]\ttraining's l1: 0.167522\ttraining's l2: 0.151488\tvalid_1's l1: 0.869955\tvalid_1's l2: 1.40175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[630]\ttraining's l1: 0.167376\ttraining's l2: 0.151377\tvalid_1's l1: 0.870205\tvalid_1's l2: 1.40282\n",
      "[631]\ttraining's l1: 0.167266\ttraining's l2: 0.15119\tvalid_1's l1: 0.870544\tvalid_1's l2: 1.40398\n",
      "[632]\ttraining's l1: 0.167024\ttraining's l2: 0.150907\tvalid_1's l1: 0.870575\tvalid_1's l2: 1.40378\n",
      "[633]\ttraining's l1: 0.167044\ttraining's l2: 0.150671\tvalid_1's l1: 0.870458\tvalid_1's l2: 1.40324\n",
      "[634]\ttraining's l1: 0.166924\ttraining's l2: 0.150413\tvalid_1's l1: 0.870938\tvalid_1's l2: 1.40471\n",
      "[635]\ttraining's l1: 0.166813\ttraining's l2: 0.150137\tvalid_1's l1: 0.870824\tvalid_1's l2: 1.40466\n",
      "[636]\ttraining's l1: 0.166654\ttraining's l2: 0.149953\tvalid_1's l1: 0.871299\tvalid_1's l2: 1.40635\n",
      "[637]\ttraining's l1: 0.166583\ttraining's l2: 0.149668\tvalid_1's l1: 0.871411\tvalid_1's l2: 1.40681\n",
      "[638]\ttraining's l1: 0.166489\ttraining's l2: 0.149486\tvalid_1's l1: 0.87174\tvalid_1's l2: 1.40797\n",
      "[639]\ttraining's l1: 0.16645\ttraining's l2: 0.149394\tvalid_1's l1: 0.87152\tvalid_1's l2: 1.4074\n",
      "[640]\ttraining's l1: 0.166315\ttraining's l2: 0.149316\tvalid_1's l1: 0.871501\tvalid_1's l2: 1.40662\n",
      "[641]\ttraining's l1: 0.166359\ttraining's l2: 0.149173\tvalid_1's l1: 0.871244\tvalid_1's l2: 1.40571\n",
      "[642]\ttraining's l1: 0.166189\ttraining's l2: 0.148915\tvalid_1's l1: 0.871604\tvalid_1's l2: 1.40692\n",
      "[643]\ttraining's l1: 0.166219\ttraining's l2: 0.148685\tvalid_1's l1: 0.871488\tvalid_1's l2: 1.40639\n",
      "[644]\ttraining's l1: 0.166109\ttraining's l2: 0.148416\tvalid_1's l1: 0.871376\tvalid_1's l2: 1.40634\n",
      "[645]\ttraining's l1: 0.166064\ttraining's l2: 0.14821\tvalid_1's l1: 0.87126\tvalid_1's l2: 1.40663\n",
      "[646]\ttraining's l1: 0.165952\ttraining's l2: 0.14803\tvalid_1's l1: 0.871584\tvalid_1's l2: 1.40775\n",
      "[647]\ttraining's l1: 0.165919\ttraining's l2: 0.147752\tvalid_1's l1: 0.871763\tvalid_1's l2: 1.40876\n",
      "[648]\ttraining's l1: 0.165876\ttraining's l2: 0.147662\tvalid_1's l1: 0.871545\tvalid_1's l2: 1.4082\n",
      "[649]\ttraining's l1: 0.165845\ttraining's l2: 0.147461\tvalid_1's l1: 0.87143\tvalid_1's l2: 1.40848\n",
      "[650]\ttraining's l1: 0.165925\ttraining's l2: 0.147249\tvalid_1's l1: 0.871317\tvalid_1's l2: 1.40832\n",
      "[651]\ttraining's l1: 0.165966\ttraining's l2: 0.147112\tvalid_1's l1: 0.871083\tvalid_1's l2: 1.40742\n",
      "[652]\ttraining's l1: 0.165808\ttraining's l2: 0.14686\tvalid_1's l1: 0.871478\tvalid_1's l2: 1.40871\n",
      "[653]\ttraining's l1: 0.165722\ttraining's l2: 0.146597\tvalid_1's l1: 0.871369\tvalid_1's l2: 1.40867\n",
      "[654]\ttraining's l1: 0.165565\ttraining's l2: 0.146418\tvalid_1's l1: 0.871833\tvalid_1's l2: 1.41033\n",
      "[655]\ttraining's l1: 0.165326\ttraining's l2: 0.146145\tvalid_1's l1: 0.871865\tvalid_1's l2: 1.41014\n",
      "[656]\ttraining's l1: 0.165354\ttraining's l2: 0.145923\tvalid_1's l1: 0.871744\tvalid_1's l2: 1.4096\n",
      "[657]\ttraining's l1: 0.165387\ttraining's l2: 0.145759\tvalid_1's l1: 0.871552\tvalid_1's l2: 1.40954\n",
      "[658]\ttraining's l1: 0.165295\ttraining's l2: 0.145582\tvalid_1's l1: 0.871875\tvalid_1's l2: 1.41068\n",
      "[659]\ttraining's l1: 0.165267\ttraining's l2: 0.145312\tvalid_1's l1: 0.872047\tvalid_1's l2: 1.41125\n",
      "[660]\ttraining's l1: 0.165228\ttraining's l2: 0.145224\tvalid_1's l1: 0.871831\tvalid_1's l2: 1.41069\n",
      "[661]\ttraining's l1: 0.165277\ttraining's l2: 0.145006\tvalid_1's l1: 0.871715\tvalid_1's l2: 1.41017\n",
      "[662]\ttraining's l1: 0.165207\ttraining's l2: 0.144751\tvalid_1's l1: 0.871607\tvalid_1's l2: 1.41013\n",
      "[663]\ttraining's l1: 0.165098\ttraining's l2: 0.144576\tvalid_1's l1: 0.871925\tvalid_1's l2: 1.41124\n",
      "[664]\ttraining's l1: 0.165015\ttraining's l2: 0.144353\tvalid_1's l1: 0.87187\tvalid_1's l2: 1.41159\n",
      "[665]\ttraining's l1: 0.16486\ttraining's l2: 0.144106\tvalid_1's l1: 0.872259\tvalid_1's l2: 1.41286\n",
      "[666]\ttraining's l1: 0.164907\ttraining's l2: 0.143902\tvalid_1's l1: 0.872173\tvalid_1's l2: 1.41272\n",
      "[667]\ttraining's l1: 0.164816\ttraining's l2: 0.14373\tvalid_1's l1: 0.87249\tvalid_1's l2: 1.41385\n",
      "[668]\ttraining's l1: 0.164769\ttraining's l2: 0.143465\tvalid_1's l1: 0.872692\tvalid_1's l2: 1.41484\n",
      "[669]\ttraining's l1: 0.164634\ttraining's l2: 0.143224\tvalid_1's l1: 0.873038\tvalid_1's l2: 1.41601\n",
      "[670]\ttraining's l1: 0.164594\ttraining's l2: 0.143136\tvalid_1's l1: 0.872815\tvalid_1's l2: 1.41545\n",
      "[671]\ttraining's l1: 0.164626\ttraining's l2: 0.143005\tvalid_1's l1: 0.872581\tvalid_1's l2: 1.41456\n",
      "[672]\ttraining's l1: 0.164556\ttraining's l2: 0.142755\tvalid_1's l1: 0.872478\tvalid_1's l2: 1.41453\n",
      "[673]\ttraining's l1: 0.164604\ttraining's l2: 0.142601\tvalid_1's l1: 0.872345\tvalid_1's l2: 1.41458\n",
      "[674]\ttraining's l1: 0.164636\ttraining's l2: 0.142445\tvalid_1's l1: 0.872155\tvalid_1's l2: 1.41451\n",
      "[675]\ttraining's l1: 0.164485\ttraining's l2: 0.142274\tvalid_1's l1: 0.872606\tvalid_1's l2: 1.41613\n",
      "[676]\ttraining's l1: 0.16454\ttraining's l2: 0.142076\tvalid_1's l1: 0.872443\tvalid_1's l2: 1.41577\n",
      "[677]\ttraining's l1: 0.164394\ttraining's l2: 0.141839\tvalid_1's l1: 0.872823\tvalid_1's l2: 1.41702\n",
      "[678]\ttraining's l1: 0.164175\ttraining's l2: 0.141575\tvalid_1's l1: 0.872858\tvalid_1's l2: 1.41684\n",
      "[679]\ttraining's l1: 0.164097\ttraining's l2: 0.141362\tvalid_1's l1: 0.872696\tvalid_1's l2: 1.41688\n",
      "[680]\ttraining's l1: 0.164049\ttraining's l2: 0.141273\tvalid_1's l1: 0.872559\tvalid_1's l2: 1.41613\n",
      "[681]\ttraining's l1: 0.164145\ttraining's l2: 0.14108\tvalid_1's l1: 0.872448\tvalid_1's l2: 1.41598\n",
      "[682]\ttraining's l1: 0.164094\ttraining's l2: 0.140823\tvalid_1's l1: 0.872292\tvalid_1's l2: 1.41581\n",
      "[683]\ttraining's l1: 0.163984\ttraining's l2: 0.140654\tvalid_1's l1: 0.872604\tvalid_1's l2: 1.41691\n",
      "[684]\ttraining's l1: 0.163941\ttraining's l2: 0.140567\tvalid_1's l1: 0.872468\tvalid_1's l2: 1.41617\n",
      "[685]\ttraining's l1: 0.163798\ttraining's l2: 0.140335\tvalid_1's l1: 0.872844\tvalid_1's l2: 1.41741\n",
      "[686]\ttraining's l1: 0.163859\ttraining's l2: 0.140187\tvalid_1's l1: 0.872684\tvalid_1's l2: 1.41748\n",
      "[687]\ttraining's l1: 0.163903\ttraining's l2: 0.139983\tvalid_1's l1: 0.872566\tvalid_1's l2: 1.41697\n",
      "[688]\ttraining's l1: 0.163842\ttraining's l2: 0.139741\tvalid_1's l1: 0.872463\tvalid_1's l2: 1.41695\n",
      "[689]\ttraining's l1: 0.163761\ttraining's l2: 0.139531\tvalid_1's l1: 0.872409\tvalid_1's l2: 1.41729\n",
      "[690]\ttraining's l1: 0.163783\ttraining's l2: 0.139403\tvalid_1's l1: 0.872171\tvalid_1's l2: 1.41642\n",
      "[691]\ttraining's l1: 0.16365\ttraining's l2: 0.139174\tvalid_1's l1: 0.872543\tvalid_1's l2: 1.41765\n",
      "[692]\ttraining's l1: 0.163553\ttraining's l2: 0.138962\tvalid_1's l1: 0.872359\tvalid_1's l2: 1.41745\n",
      "[693]\ttraining's l1: 0.163593\ttraining's l2: 0.138762\tvalid_1's l1: 0.87224\tvalid_1's l2: 1.41694\n",
      "[694]\ttraining's l1: 0.163558\ttraining's l2: 0.138544\tvalid_1's l1: 0.872046\tvalid_1's l2: 1.41674\n",
      "[695]\ttraining's l1: 0.16346\ttraining's l2: 0.138376\tvalid_1's l1: 0.872358\tvalid_1's l2: 1.41786\n",
      "[696]\ttraining's l1: 0.16341\ttraining's l2: 0.138293\tvalid_1's l1: 0.872144\tvalid_1's l2: 1.41732\n",
      "[697]\ttraining's l1: 0.16332\ttraining's l2: 0.138087\tvalid_1's l1: 0.871962\tvalid_1's l2: 1.41712\n",
      "[698]\ttraining's l1: 0.163281\ttraining's l2: 0.137838\tvalid_1's l1: 0.872186\tvalid_1's l2: 1.41809\n",
      "[699]\ttraining's l1: 0.163341\ttraining's l2: 0.137653\tvalid_1's l1: 0.872084\tvalid_1's l2: 1.41796\n",
      "[700]\ttraining's l1: 0.163185\ttraining's l2: 0.137486\tvalid_1's l1: 0.872529\tvalid_1's l2: 1.41956\n",
      "[701]\ttraining's l1: 0.163201\ttraining's l2: 0.137363\tvalid_1's l1: 0.872425\tvalid_1's l2: 1.41898\n",
      "[702]\ttraining's l1: 0.163071\ttraining's l2: 0.137139\tvalid_1's l1: 0.872793\tvalid_1's l2: 1.42021\n",
      "[703]\ttraining's l1: 0.163039\ttraining's l2: 0.136927\tvalid_1's l1: 0.872599\tvalid_1's l2: 1.42001\n",
      "[704]\ttraining's l1: 0.163077\ttraining's l2: 0.136809\tvalid_1's l1: 0.872482\tvalid_1's l2: 1.41939\n",
      "[705]\ttraining's l1: 0.163122\ttraining's l2: 0.136668\tvalid_1's l1: 0.872357\tvalid_1's l2: 1.41944\n",
      "[706]\ttraining's l1: 0.163023\ttraining's l2: 0.136503\tvalid_1's l1: 0.872668\tvalid_1's l2: 1.42056\n",
      "[707]\ttraining's l1: 0.16298\ttraining's l2: 0.13642\tvalid_1's l1: 0.87254\tvalid_1's l2: 1.41984\n",
      "[708]\ttraining's l1: 0.16298\ttraining's l2: 0.136205\tvalid_1's l1: 0.872297\tvalid_1's l2: 1.41949\n",
      "[709]\ttraining's l1: 0.162925\ttraining's l2: 0.135976\tvalid_1's l1: 0.872197\tvalid_1's l2: 1.41948\n",
      "[710]\ttraining's l1: 0.162829\ttraining's l2: 0.135767\tvalid_1's l1: 0.872191\tvalid_1's l2: 1.41948\n",
      "[711]\ttraining's l1: 0.162845\ttraining's l2: 0.135649\tvalid_1's l1: 0.872101\tvalid_1's l2: 1.41892\n",
      "[712]\ttraining's l1: 0.162716\ttraining's l2: 0.135427\tvalid_1's l1: 0.872467\tvalid_1's l2: 1.42014\n",
      "[713]\ttraining's l1: 0.162603\ttraining's l2: 0.135264\tvalid_1's l1: 0.872774\tvalid_1's l2: 1.42123\n",
      "[714]\ttraining's l1: 0.162631\ttraining's l2: 0.135121\tvalid_1's l1: 0.872595\tvalid_1's l2: 1.42118\n",
      "[715]\ttraining's l1: 0.162587\ttraining's l2: 0.13504\tvalid_1's l1: 0.872468\tvalid_1's l2: 1.42047\n",
      "[716]\ttraining's l1: 0.162492\ttraining's l2: 0.134843\tvalid_1's l1: 0.872291\tvalid_1's l2: 1.42028\n",
      "[717]\ttraining's l1: 0.162583\ttraining's l2: 0.134666\tvalid_1's l1: 0.872182\tvalid_1's l2: 1.42013\n",
      "[718]\ttraining's l1: 0.162472\ttraining's l2: 0.134449\tvalid_1's l1: 0.872508\tvalid_1's l2: 1.42126\n",
      "[719]\ttraining's l1: 0.162441\ttraining's l2: 0.134246\tvalid_1's l1: 0.872318\tvalid_1's l2: 1.42108\n",
      "[720]\ttraining's l1: 0.162396\ttraining's l2: 0.134132\tvalid_1's l1: 0.872361\tvalid_1's l2: 1.42092\n",
      "[721]\ttraining's l1: 0.162302\ttraining's l2: 0.13397\tvalid_1's l1: 0.872672\tvalid_1's l2: 1.42203\n",
      "[722]\ttraining's l1: 0.162302\ttraining's l2: 0.13381\tvalid_1's l1: 0.872638\tvalid_1's l2: 1.42228\n",
      "[723]\ttraining's l1: 0.162265\ttraining's l2: 0.133731\tvalid_1's l1: 0.872495\tvalid_1's l2: 1.42156\n",
      "[724]\ttraining's l1: 0.162248\ttraining's l2: 0.133532\tvalid_1's l1: 0.872322\tvalid_1's l2: 1.42138\n",
      "[725]\ttraining's l1: 0.162193\ttraining's l2: 0.133298\tvalid_1's l1: 0.872262\tvalid_1's l2: 1.42161\n",
      "[726]\ttraining's l1: 0.162141\ttraining's l2: 0.133164\tvalid_1's l1: 0.871975\tvalid_1's l2: 1.42048\n",
      "[727]\ttraining's l1: 0.161994\ttraining's l2: 0.133066\tvalid_1's l1: 0.87219\tvalid_1's l2: 1.42143\n",
      "[728]\ttraining's l1: 0.161854\ttraining's l2: 0.132969\tvalid_1's l1: 0.872403\tvalid_1's l2: 1.42239\n",
      "[729]\ttraining's l1: 0.161767\ttraining's l2: 0.132769\tvalid_1's l1: 0.872385\tvalid_1's l2: 1.4224\n",
      "[730]\ttraining's l1: 0.161878\ttraining's l2: 0.132598\tvalid_1's l1: 0.872278\tvalid_1's l2: 1.42226\n",
      "[731]\ttraining's l1: 0.161746\ttraining's l2: 0.132385\tvalid_1's l1: 0.872637\tvalid_1's l2: 1.42346\n",
      "[732]\ttraining's l1: 0.161603\ttraining's l2: 0.132224\tvalid_1's l1: 0.873076\tvalid_1's l2: 1.42505\n",
      "[733]\ttraining's l1: 0.161662\ttraining's l2: 0.13204\tvalid_1's l1: 0.87296\tvalid_1's l2: 1.42456\n",
      "[734]\ttraining's l1: 0.16159\ttraining's l2: 0.131852\tvalid_1's l1: 0.8728\tvalid_1's l2: 1.42438\n",
      "[735]\ttraining's l1: 0.161547\ttraining's l2: 0.131618\tvalid_1's l1: 0.873017\tvalid_1's l2: 1.42493\n",
      "[736]\ttraining's l1: 0.161506\ttraining's l2: 0.131475\tvalid_1's l1: 0.87277\tvalid_1's l2: 1.42424\n",
      "[737]\ttraining's l1: 0.161395\ttraining's l2: 0.131267\tvalid_1's l1: 0.873071\tvalid_1's l2: 1.42535\n",
      "[738]\ttraining's l1: 0.161437\ttraining's l2: 0.131135\tvalid_1's l1: 0.873103\tvalid_1's l2: 1.42564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[739]\ttraining's l1: 0.161351\ttraining's l2: 0.130978\tvalid_1's l1: 0.873407\tvalid_1's l2: 1.42674\n",
      "[740]\ttraining's l1: 0.161338\ttraining's l2: 0.130783\tvalid_1's l1: 0.873216\tvalid_1's l2: 1.42655\n",
      "[741]\ttraining's l1: 0.1613\ttraining's l2: 0.130709\tvalid_1's l1: 0.872989\tvalid_1's l2: 1.42574\n",
      "[742]\ttraining's l1: 0.161254\ttraining's l2: 0.130542\tvalid_1's l1: 0.872848\tvalid_1's l2: 1.42589\n",
      "[743]\ttraining's l1: 0.161217\ttraining's l2: 0.13047\tvalid_1's l1: 0.87262\tvalid_1's l2: 1.42509\n",
      "[744]\ttraining's l1: 0.161091\ttraining's l2: 0.130264\tvalid_1's l1: 0.872966\tvalid_1's l2: 1.42627\n",
      "[745]\ttraining's l1: 0.161056\ttraining's l2: 0.13014\tvalid_1's l1: 0.872957\tvalid_1's l2: 1.42657\n",
      "[746]\ttraining's l1: 0.160982\ttraining's l2: 0.129935\tvalid_1's l1: 0.872833\tvalid_1's l2: 1.42657\n",
      "[747]\ttraining's l1: 0.16084\ttraining's l2: 0.129778\tvalid_1's l1: 0.87327\tvalid_1's l2: 1.42813\n",
      "[748]\ttraining's l1: 0.160812\ttraining's l2: 0.129671\tvalid_1's l1: 0.873308\tvalid_1's l2: 1.42798\n",
      "[749]\ttraining's l1: 0.160729\ttraining's l2: 0.12948\tvalid_1's l1: 0.873306\tvalid_1's l2: 1.42799\n",
      "[750]\ttraining's l1: 0.160699\ttraining's l2: 0.129408\tvalid_1's l1: 0.873086\tvalid_1's l2: 1.42718\n",
      "[751]\ttraining's l1: 0.160626\ttraining's l2: 0.129221\tvalid_1's l1: 0.873067\tvalid_1's l2: 1.42714\n",
      "[752]\ttraining's l1: 0.160506\ttraining's l2: 0.129019\tvalid_1's l1: 0.873399\tvalid_1's l2: 1.42833\n",
      "[753]\ttraining's l1: 0.160354\ttraining's l2: 0.128813\tvalid_1's l1: 0.873224\tvalid_1's l2: 1.42777\n",
      "[754]\ttraining's l1: 0.160354\ttraining's l2: 0.128625\tvalid_1's l1: 0.873042\tvalid_1's l2: 1.42759\n",
      "[755]\ttraining's l1: 0.160254\ttraining's l2: 0.128471\tvalid_1's l1: 0.873347\tvalid_1's l2: 1.42865\n",
      "[756]\ttraining's l1: 0.160224\ttraining's l2: 0.128399\tvalid_1's l1: 0.873129\tvalid_1's l2: 1.42785\n",
      "[757]\ttraining's l1: 0.160244\ttraining's l2: 0.12827\tvalid_1's l1: 0.872998\tvalid_1's l2: 1.42791\n",
      "[758]\ttraining's l1: 0.160211\ttraining's l2: 0.128133\tvalid_1's l1: 0.87275\tvalid_1's l2: 1.42723\n",
      "[759]\ttraining's l1: 0.160092\ttraining's l2: 0.128044\tvalid_1's l1: 0.872979\tvalid_1's l2: 1.42818\n",
      "[760]\ttraining's l1: 0.160019\ttraining's l2: 0.127869\tvalid_1's l1: 0.872815\tvalid_1's l2: 1.42801\n",
      "[761]\ttraining's l1: 0.159929\ttraining's l2: 0.127682\tvalid_1's l1: 0.8728\tvalid_1's l2: 1.42806\n",
      "[762]\ttraining's l1: 0.159816\ttraining's l2: 0.127595\tvalid_1's l1: 0.873038\tvalid_1's l2: 1.42905\n",
      "[763]\ttraining's l1: 0.15979\ttraining's l2: 0.127523\tvalid_1's l1: 0.872817\tvalid_1's l2: 1.42826\n",
      "[764]\ttraining's l1: 0.159687\ttraining's l2: 0.127325\tvalid_1's l1: 0.873151\tvalid_1's l2: 1.42936\n",
      "[765]\ttraining's l1: 0.159502\ttraining's l2: 0.127158\tvalid_1's l1: 0.873172\tvalid_1's l2: 1.42955\n",
      "[766]\ttraining's l1: 0.159523\ttraining's l2: 0.127032\tvalid_1's l1: 0.873044\tvalid_1's l2: 1.42961\n",
      "[767]\ttraining's l1: 0.159501\ttraining's l2: 0.126962\tvalid_1's l1: 0.872829\tvalid_1's l2: 1.42882\n",
      "[768]\ttraining's l1: 0.159417\ttraining's l2: 0.12679\tvalid_1's l1: 0.872664\tvalid_1's l2: 1.42871\n",
      "[769]\ttraining's l1: 0.159408\ttraining's l2: 0.126568\tvalid_1's l1: 0.872871\tvalid_1's l2: 1.42965\n",
      "[770]\ttraining's l1: 0.159283\ttraining's l2: 0.126478\tvalid_1's l1: 0.873093\tvalid_1's l2: 1.43062\n",
      "[771]\ttraining's l1: 0.159113\ttraining's l2: 0.126315\tvalid_1's l1: 0.873115\tvalid_1's l2: 1.4308\n",
      "[772]\ttraining's l1: 0.159138\ttraining's l2: 0.126207\tvalid_1's l1: 0.873021\tvalid_1's l2: 1.43027\n",
      "[773]\ttraining's l1: 0.159122\ttraining's l2: 0.126034\tvalid_1's l1: 0.873249\tvalid_1's l2: 1.43112\n",
      "[774]\ttraining's l1: 0.159161\ttraining's l2: 0.125859\tvalid_1's l1: 0.872919\tvalid_1's l2: 1.42994\n",
      "[775]\ttraining's l1: 0.159061\ttraining's l2: 0.125666\tvalid_1's l1: 0.873246\tvalid_1's l2: 1.43103\n",
      "[776]\ttraining's l1: 0.158905\ttraining's l2: 0.125506\tvalid_1's l1: 0.873268\tvalid_1's l2: 1.43121\n",
      "[777]\ttraining's l1: 0.15886\ttraining's l2: 0.125349\tvalid_1's l1: 0.873102\tvalid_1's l2: 1.43135\n",
      "[778]\ttraining's l1: 0.158783\ttraining's l2: 0.125152\tvalid_1's l1: 0.872973\tvalid_1's l2: 1.43136\n",
      "[779]\ttraining's l1: 0.158766\ttraining's l2: 0.125084\tvalid_1's l1: 0.872758\tvalid_1's l2: 1.43059\n",
      "[780]\ttraining's l1: 0.158636\ttraining's l2: 0.124995\tvalid_1's l1: 0.872981\tvalid_1's l2: 1.43155\n",
      "[781]\ttraining's l1: 0.158608\ttraining's l2: 0.124827\tvalid_1's l1: 0.872828\tvalid_1's l2: 1.43113\n",
      "[782]\ttraining's l1: 0.158521\ttraining's l2: 0.124659\tvalid_1's l1: 0.872666\tvalid_1's l2: 1.43097\n",
      "[783]\ttraining's l1: 0.158524\ttraining's l2: 0.124443\tvalid_1's l1: 0.872878\tvalid_1's l2: 1.43189\n",
      "[784]\ttraining's l1: 0.158515\ttraining's l2: 0.12431\tvalid_1's l1: 0.872549\tvalid_1's l2: 1.43073\n",
      "[785]\ttraining's l1: 0.158388\ttraining's l2: 0.124222\tvalid_1's l1: 0.872748\tvalid_1's l2: 1.43165\n",
      "[786]\ttraining's l1: 0.158266\ttraining's l2: 0.124135\tvalid_1's l1: 0.872964\tvalid_1's l2: 1.43261\n",
      "[787]\ttraining's l1: 0.158239\ttraining's l2: 0.123936\tvalid_1's l1: 0.873516\tvalid_1's l2: 1.43414\n",
      "[788]\ttraining's l1: 0.158172\ttraining's l2: 0.123744\tvalid_1's l1: 0.873411\tvalid_1's l2: 1.43391\n",
      "[789]\ttraining's l1: 0.158099\ttraining's l2: 0.123551\tvalid_1's l1: 0.8733\tvalid_1's l2: 1.43391\n",
      "[790]\ttraining's l1: 0.15809\ttraining's l2: 0.123418\tvalid_1's l1: 0.872972\tvalid_1's l2: 1.43275\n",
      "[791]\ttraining's l1: 0.157968\ttraining's l2: 0.123333\tvalid_1's l1: 0.873188\tvalid_1's l2: 1.43371\n",
      "[792]\ttraining's l1: 0.157844\ttraining's l2: 0.123248\tvalid_1's l1: 0.873384\tvalid_1's l2: 1.43463\n",
      "[793]\ttraining's l1: 0.157824\ttraining's l2: 0.123037\tvalid_1's l1: 0.87359\tvalid_1's l2: 1.43517\n",
      "[794]\ttraining's l1: 0.157853\ttraining's l2: 0.122868\tvalid_1's l1: 0.873273\tvalid_1's l2: 1.43401\n",
      "[795]\ttraining's l1: 0.157757\ttraining's l2: 0.122682\tvalid_1's l1: 0.873553\tvalid_1's l2: 1.43508\n",
      "[796]\ttraining's l1: 0.157617\ttraining's l2: 0.122526\tvalid_1's l1: 0.873573\tvalid_1's l2: 1.43527\n",
      "[797]\ttraining's l1: 0.157521\ttraining's l2: 0.122343\tvalid_1's l1: 0.873871\tvalid_1's l2: 1.43632\n",
      "[798]\ttraining's l1: 0.157485\ttraining's l2: 0.122228\tvalid_1's l1: 0.873876\tvalid_1's l2: 1.43664\n",
      "[799]\ttraining's l1: 0.157431\ttraining's l2: 0.122055\tvalid_1's l1: 0.873844\tvalid_1's l2: 1.43668\n",
      "[800]\ttraining's l1: 0.157393\ttraining's l2: 0.121925\tvalid_1's l1: 0.873595\tvalid_1's l2: 1.43602\n",
      "[801]\ttraining's l1: 0.157422\ttraining's l2: 0.12176\tvalid_1's l1: 0.873274\tvalid_1's l2: 1.43488\n",
      "[802]\ttraining's l1: 0.15728\ttraining's l2: 0.121676\tvalid_1's l1: 0.87351\tvalid_1's l2: 1.43582\n",
      "[803]\ttraining's l1: 0.157207\ttraining's l2: 0.121486\tvalid_1's l1: 0.873941\tvalid_1's l2: 1.43705\n",
      "[804]\ttraining's l1: 0.157134\ttraining's l2: 0.121295\tvalid_1's l1: 0.873827\tvalid_1's l2: 1.43705\n",
      "[805]\ttraining's l1: 0.156992\ttraining's l2: 0.121144\tvalid_1's l1: 0.873883\tvalid_1's l2: 1.43726\n",
      "[806]\ttraining's l1: 0.156997\ttraining's l2: 0.120938\tvalid_1's l1: 0.874091\tvalid_1's l2: 1.43817\n",
      "[807]\ttraining's l1: 0.156959\ttraining's l2: 0.120811\tvalid_1's l1: 0.873856\tvalid_1's l2: 1.43752\n",
      "[808]\ttraining's l1: 0.156819\ttraining's l2: 0.120729\tvalid_1's l1: 0.874087\tvalid_1's l2: 1.43846\n",
      "[809]\ttraining's l1: 0.156696\ttraining's l2: 0.120529\tvalid_1's l1: 0.87398\tvalid_1's l2: 1.43791\n",
      "[810]\ttraining's l1: 0.156602\ttraining's l2: 0.120352\tvalid_1's l1: 0.874252\tvalid_1's l2: 1.43895\n",
      "[811]\ttraining's l1: 0.156529\ttraining's l2: 0.120164\tvalid_1's l1: 0.874138\tvalid_1's l2: 1.43895\n",
      "[812]\ttraining's l1: 0.156502\ttraining's l2: 0.12004\tvalid_1's l1: 0.874182\tvalid_1's l2: 1.43883\n",
      "[813]\ttraining's l1: 0.156461\ttraining's l2: 0.119875\tvalid_1's l1: 0.874149\tvalid_1's l2: 1.43882\n",
      "[814]\ttraining's l1: 0.156426\ttraining's l2: 0.119763\tvalid_1's l1: 0.874146\tvalid_1's l2: 1.43914\n",
      "[815]\ttraining's l1: 0.156287\ttraining's l2: 0.11962\tvalid_1's l1: 0.87456\tvalid_1's l2: 1.44064\n",
      "[816]\ttraining's l1: 0.156268\ttraining's l2: 0.119419\tvalid_1's l1: 0.874763\tvalid_1's l2: 1.44117\n",
      "[817]\ttraining's l1: 0.156146\ttraining's l2: 0.119223\tvalid_1's l1: 0.874653\tvalid_1's l2: 1.44063\n",
      "[818]\ttraining's l1: 0.156163\ttraining's l2: 0.119061\tvalid_1's l1: 0.874351\tvalid_1's l2: 1.43952\n",
      "[819]\ttraining's l1: 0.156084\ttraining's l2: 0.118878\tvalid_1's l1: 0.874783\tvalid_1's l2: 1.44079\n",
      "[820]\ttraining's l1: 0.156003\ttraining's l2: 0.118693\tvalid_1's l1: 0.874668\tvalid_1's l2: 1.44078\n",
      "[821]\ttraining's l1: 0.155966\ttraining's l2: 0.118568\tvalid_1's l1: 0.874435\tvalid_1's l2: 1.44014\n",
      "[822]\ttraining's l1: 0.155845\ttraining's l2: 0.118487\tvalid_1's l1: 0.874649\tvalid_1's l2: 1.44106\n",
      "[823]\ttraining's l1: 0.155852\ttraining's l2: 0.11829\tvalid_1's l1: 0.874853\tvalid_1's l2: 1.44196\n",
      "[824]\ttraining's l1: 0.155722\ttraining's l2: 0.118145\tvalid_1's l1: 0.874867\tvalid_1's l2: 1.44215\n",
      "[825]\ttraining's l1: 0.155688\ttraining's l2: 0.118021\tvalid_1's l1: 0.874636\tvalid_1's l2: 1.44151\n",
      "[826]\ttraining's l1: 0.155594\ttraining's l2: 0.117849\tvalid_1's l1: 0.874902\tvalid_1's l2: 1.44253\n",
      "[827]\ttraining's l1: 0.155565\ttraining's l2: 0.117741\tvalid_1's l1: 0.874899\tvalid_1's l2: 1.44285\n",
      "[828]\ttraining's l1: 0.155584\ttraining's l2: 0.117582\tvalid_1's l1: 0.874602\tvalid_1's l2: 1.44176\n",
      "[829]\ttraining's l1: 0.155471\ttraining's l2: 0.117413\tvalid_1's l1: 0.874647\tvalid_1's l2: 1.44178\n",
      "[830]\ttraining's l1: 0.155361\ttraining's l2: 0.117335\tvalid_1's l1: 0.874874\tvalid_1's l2: 1.44273\n",
      "[831]\ttraining's l1: 0.155393\ttraining's l2: 0.117142\tvalid_1's l1: 0.875052\tvalid_1's l2: 1.44362\n",
      "[832]\ttraining's l1: 0.155411\ttraining's l2: 0.117043\tvalid_1's l1: 0.874949\tvalid_1's l2: 1.4431\n",
      "[833]\ttraining's l1: 0.155309\ttraining's l2: 0.116862\tvalid_1's l1: 0.874836\tvalid_1's l2: 1.4431\n",
      "[834]\ttraining's l1: 0.155195\ttraining's l2: 0.116785\tvalid_1's l1: 0.875044\tvalid_1's l2: 1.44401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[835]\ttraining's l1: 0.155189\ttraining's l2: 0.116673\tvalid_1's l1: 0.874926\tvalid_1's l2: 1.44401\n",
      "[836]\ttraining's l1: 0.155081\ttraining's l2: 0.116598\tvalid_1's l1: 0.875152\tvalid_1's l2: 1.44495\n",
      "[837]\ttraining's l1: 0.155099\ttraining's l2: 0.116494\tvalid_1's l1: 0.874942\tvalid_1's l2: 1.44406\n",
      "[838]\ttraining's l1: 0.155016\ttraining's l2: 0.116327\tvalid_1's l1: 0.874924\tvalid_1's l2: 1.44411\n",
      "[839]\ttraining's l1: 0.154896\ttraining's l2: 0.11625\tvalid_1's l1: 0.875116\tvalid_1's l2: 1.44499\n",
      "[840]\ttraining's l1: 0.154834\ttraining's l2: 0.116075\tvalid_1's l1: 0.87502\tvalid_1's l2: 1.44478\n",
      "[841]\ttraining's l1: 0.154743\ttraining's l2: 0.115906\tvalid_1's l1: 0.875285\tvalid_1's l2: 1.4458\n",
      "[842]\ttraining's l1: 0.154761\ttraining's l2: 0.115751\tvalid_1's l1: 0.87499\tvalid_1's l2: 1.44472\n",
      "[843]\ttraining's l1: 0.154716\ttraining's l2: 0.115676\tvalid_1's l1: 0.87492\tvalid_1's l2: 1.44485\n",
      "[844]\ttraining's l1: 0.154686\ttraining's l2: 0.115508\tvalid_1's l1: 0.874631\tvalid_1's l2: 1.44424\n",
      "[845]\ttraining's l1: 0.154579\ttraining's l2: 0.115434\tvalid_1's l1: 0.874855\tvalid_1's l2: 1.44518\n",
      "[846]\ttraining's l1: 0.154584\ttraining's l2: 0.115245\tvalid_1's l1: 0.875028\tvalid_1's l2: 1.4457\n",
      "[847]\ttraining's l1: 0.154454\ttraining's l2: 0.115107\tvalid_1's l1: 0.875429\tvalid_1's l2: 1.44716\n",
      "[848]\ttraining's l1: 0.154472\ttraining's l2: 0.11501\tvalid_1's l1: 0.875327\tvalid_1's l2: 1.44665\n",
      "[849]\ttraining's l1: 0.154278\ttraining's l2: 0.114837\tvalid_1's l1: 0.87586\tvalid_1's l2: 1.44817\n",
      "[850]\ttraining's l1: 0.154238\ttraining's l2: 0.114775\tvalid_1's l1: 0.875682\tvalid_1's l2: 1.44768\n",
      "[851]\ttraining's l1: 0.154264\ttraining's l2: 0.114602\tvalid_1's l1: 0.875468\tvalid_1's l2: 1.44726\n",
      "[852]\ttraining's l1: 0.154131\ttraining's l2: 0.114466\tvalid_1's l1: 0.875863\tvalid_1's l2: 1.4487\n",
      "[853]\ttraining's l1: 0.154101\ttraining's l2: 0.1143\tvalid_1's l1: 0.875576\tvalid_1's l2: 1.4481\n",
      "[854]\ttraining's l1: 0.154117\ttraining's l2: 0.1142\tvalid_1's l1: 0.875368\tvalid_1's l2: 1.44723\n",
      "[855]\ttraining's l1: 0.154032\ttraining's l2: 0.11404\tvalid_1's l1: 0.875715\tvalid_1's l2: 1.44835\n",
      "[856]\ttraining's l1: 0.153935\ttraining's l2: 0.113865\tvalid_1's l1: 0.875602\tvalid_1's l2: 1.44836\n",
      "[857]\ttraining's l1: 0.1538\ttraining's l2: 0.113731\tvalid_1's l1: 0.875995\tvalid_1's l2: 1.44979\n",
      "[858]\ttraining's l1: 0.153777\ttraining's l2: 0.113669\tvalid_1's l1: 0.875777\tvalid_1's l2: 1.44904\n",
      "[859]\ttraining's l1: 0.153746\ttraining's l2: 0.113538\tvalid_1's l1: 0.875769\tvalid_1's l2: 1.44921\n",
      "[860]\ttraining's l1: 0.153617\ttraining's l2: 0.1134\tvalid_1's l1: 0.875823\tvalid_1's l2: 1.44942\n",
      "[861]\ttraining's l1: 0.15353\ttraining's l2: 0.113228\tvalid_1's l1: 0.875712\tvalid_1's l2: 1.44942\n",
      "[862]\ttraining's l1: 0.153508\ttraining's l2: 0.113167\tvalid_1's l1: 0.875495\tvalid_1's l2: 1.44868\n",
      "[863]\ttraining's l1: 0.153472\ttraining's l2: 0.113005\tvalid_1's l1: 0.875214\tvalid_1's l2: 1.44809\n",
      "[864]\ttraining's l1: 0.153401\ttraining's l2: 0.112844\tvalid_1's l1: 0.875196\tvalid_1's l2: 1.44815\n",
      "[865]\ttraining's l1: 0.153282\ttraining's l2: 0.11277\tvalid_1's l1: 0.875384\tvalid_1's l2: 1.44901\n",
      "[866]\ttraining's l1: 0.153148\ttraining's l2: 0.112638\tvalid_1's l1: 0.875776\tvalid_1's l2: 1.45044\n",
      "[867]\ttraining's l1: 0.153125\ttraining's l2: 0.112576\tvalid_1's l1: 0.875559\tvalid_1's l2: 1.4497\n",
      "[868]\ttraining's l1: 0.153166\ttraining's l2: 0.112408\tvalid_1's l1: 0.875348\tvalid_1's l2: 1.44928\n",
      "[869]\ttraining's l1: 0.153052\ttraining's l2: 0.112335\tvalid_1's l1: 0.875552\tvalid_1's l2: 1.45017\n",
      "[870]\ttraining's l1: 0.153042\ttraining's l2: 0.112153\tvalid_1's l1: 0.875746\tvalid_1's l2: 1.45069\n",
      "[871]\ttraining's l1: 0.152908\ttraining's l2: 0.112023\tvalid_1's l1: 0.876134\tvalid_1's l2: 1.45212\n",
      "[872]\ttraining's l1: 0.152926\ttraining's l2: 0.11193\tvalid_1's l1: 0.876035\tvalid_1's l2: 1.45162\n",
      "[873]\ttraining's l1: 0.152727\ttraining's l2: 0.111762\tvalid_1's l1: 0.876559\tvalid_1's l2: 1.45311\n",
      "[874]\ttraining's l1: 0.152637\ttraining's l2: 0.111608\tvalid_1's l1: 0.876432\tvalid_1's l2: 1.4527\n",
      "[875]\ttraining's l1: 0.152413\ttraining's l2: 0.111378\tvalid_1's l1: 0.876415\tvalid_1's l2: 1.45276\n",
      "[876]\ttraining's l1: 0.152428\ttraining's l2: 0.11128\tvalid_1's l1: 0.876211\tvalid_1's l2: 1.45191\n",
      "[877]\ttraining's l1: 0.152316\ttraining's l2: 0.111122\tvalid_1's l1: 0.876256\tvalid_1's l2: 1.45193\n",
      "[878]\ttraining's l1: 0.152332\ttraining's l2: 0.110943\tvalid_1's l1: 0.876451\tvalid_1's l2: 1.4528\n",
      "[879]\ttraining's l1: 0.152315\ttraining's l2: 0.110884\tvalid_1's l1: 0.876238\tvalid_1's l2: 1.45207\n",
      "[880]\ttraining's l1: 0.152325\ttraining's l2: 0.110738\tvalid_1's l1: 0.875951\tvalid_1's l2: 1.45102\n",
      "[881]\ttraining's l1: 0.152297\ttraining's l2: 0.110574\tvalid_1's l1: 0.876449\tvalid_1's l2: 1.45247\n",
      "[882]\ttraining's l1: 0.152174\ttraining's l2: 0.110439\tvalid_1's l1: 0.876463\tvalid_1's l2: 1.45266\n",
      "[883]\ttraining's l1: 0.1521\ttraining's l2: 0.110284\tvalid_1's l1: 0.876545\tvalid_1's l2: 1.45282\n",
      "[884]\ttraining's l1: 0.152094\ttraining's l2: 0.110181\tvalid_1's l1: 0.876433\tvalid_1's l2: 1.45282\n",
      "[885]\ttraining's l1: 0.152045\ttraining's l2: 0.110123\tvalid_1's l1: 0.876259\tvalid_1's l2: 1.45236\n",
      "[886]\ttraining's l1: 0.15194\ttraining's l2: 0.110053\tvalid_1's l1: 0.876477\tvalid_1's l2: 1.45327\n",
      "[887]\ttraining's l1: 0.151745\ttraining's l2: 0.109889\tvalid_1's l1: 0.876995\tvalid_1's l2: 1.45475\n",
      "[888]\ttraining's l1: 0.151606\ttraining's l2: 0.109753\tvalid_1's l1: 0.877\tvalid_1's l2: 1.45493\n",
      "[889]\ttraining's l1: 0.151588\ttraining's l2: 0.109622\tvalid_1's l1: 0.876875\tvalid_1's l2: 1.45508\n",
      "[890]\ttraining's l1: 0.151523\ttraining's l2: 0.109462\tvalid_1's l1: 0.876783\tvalid_1's l2: 1.45489\n",
      "[891]\ttraining's l1: 0.151435\ttraining's l2: 0.109296\tvalid_1's l1: 0.876674\tvalid_1's l2: 1.4549\n",
      "[892]\ttraining's l1: 0.151459\ttraining's l2: 0.109202\tvalid_1's l1: 0.876473\tvalid_1's l2: 1.45405\n",
      "[893]\ttraining's l1: 0.151484\ttraining's l2: 0.109041\tvalid_1's l1: 0.876265\tvalid_1's l2: 1.45364\n",
      "[894]\ttraining's l1: 0.151372\ttraining's l2: 0.10897\tvalid_1's l1: 0.876451\tvalid_1's l2: 1.45447\n",
      "[895]\ttraining's l1: 0.151323\ttraining's l2: 0.108829\tvalid_1's l1: 0.876745\tvalid_1's l2: 1.45545\n",
      "[896]\ttraining's l1: 0.151195\ttraining's l2: 0.108704\tvalid_1's l1: 0.877126\tvalid_1's l2: 1.45685\n",
      "[897]\ttraining's l1: 0.15121\ttraining's l2: 0.108533\tvalid_1's l1: 0.877053\tvalid_1's l2: 1.45721\n",
      "[898]\ttraining's l1: 0.151172\ttraining's l2: 0.108475\tvalid_1's l1: 0.876881\tvalid_1's l2: 1.45674\n",
      "[899]\ttraining's l1: 0.151103\ttraining's l2: 0.108325\tvalid_1's l1: 0.876962\tvalid_1's l2: 1.45689\n",
      "[900]\ttraining's l1: 0.150968\ttraining's l2: 0.108193\tvalid_1's l1: 0.876968\tvalid_1's l2: 1.45708\n",
      "[901]\ttraining's l1: 0.150892\ttraining's l2: 0.108058\tvalid_1's l1: 0.87687\tvalid_1's l2: 1.45673\n",
      "[902]\ttraining's l1: 0.150849\ttraining's l2: 0.107916\tvalid_1's l1: 0.87661\tvalid_1's l2: 1.45616\n",
      "[903]\ttraining's l1: 0.150836\ttraining's l2: 0.107859\tvalid_1's l1: 0.876412\tvalid_1's l2: 1.45546\n",
      "[904]\ttraining's l1: 0.150731\ttraining's l2: 0.107791\tvalid_1's l1: 0.87661\tvalid_1's l2: 1.45632\n",
      "[905]\ttraining's l1: 0.150632\ttraining's l2: 0.107723\tvalid_1's l1: 0.876823\tvalid_1's l2: 1.45722\n",
      "[906]\ttraining's l1: 0.15052\ttraining's l2: 0.107578\tvalid_1's l1: 0.876748\tvalid_1's l2: 1.45703\n",
      "[907]\ttraining's l1: 0.150539\ttraining's l2: 0.107409\tvalid_1's l1: 0.876925\tvalid_1's l2: 1.45751\n",
      "[908]\ttraining's l1: 0.150332\ttraining's l2: 0.10719\tvalid_1's l1: 0.876907\tvalid_1's l2: 1.45757\n",
      "[909]\ttraining's l1: 0.150355\ttraining's l2: 0.107097\tvalid_1's l1: 0.876707\tvalid_1's l2: 1.45673\n",
      "[910]\ttraining's l1: 0.150381\ttraining's l2: 0.106942\tvalid_1's l1: 0.876503\tvalid_1's l2: 1.45633\n",
      "[911]\ttraining's l1: 0.150201\ttraining's l2: 0.106867\tvalid_1's l1: 0.876737\tvalid_1's l2: 1.45725\n",
      "[912]\ttraining's l1: 0.150219\ttraining's l2: 0.106776\tvalid_1's l1: 0.87654\tvalid_1's l2: 1.45642\n",
      "[913]\ttraining's l1: 0.150037\ttraining's l2: 0.106702\tvalid_1's l1: 0.876754\tvalid_1's l2: 1.45729\n",
      "[914]\ttraining's l1: 0.149842\ttraining's l2: 0.106543\tvalid_1's l1: 0.877265\tvalid_1's l2: 1.45875\n",
      "[915]\ttraining's l1: 0.149867\ttraining's l2: 0.106379\tvalid_1's l1: 0.877189\tvalid_1's l2: 1.45877\n",
      "[916]\ttraining's l1: 0.14967\ttraining's l2: 0.106165\tvalid_1's l1: 0.877171\tvalid_1's l2: 1.45883\n",
      "[917]\ttraining's l1: 0.149688\ttraining's l2: 0.106074\tvalid_1's l1: 0.876975\tvalid_1's l2: 1.45801\n",
      "[918]\ttraining's l1: 0.149691\ttraining's l2: 0.105952\tvalid_1's l1: 0.876599\tvalid_1's l2: 1.45694\n",
      "[919]\ttraining's l1: 0.149592\ttraining's l2: 0.105886\tvalid_1's l1: 0.876812\tvalid_1's l2: 1.45783\n",
      "[920]\ttraining's l1: 0.149405\ttraining's l2: 0.10573\tvalid_1's l1: 0.877326\tvalid_1's l2: 1.45928\n",
      "[921]\ttraining's l1: 0.149331\ttraining's l2: 0.105599\tvalid_1's l1: 0.877156\tvalid_1's l2: 1.45886\n",
      "[922]\ttraining's l1: 0.149063\ttraining's l2: 0.105378\tvalid_1's l1: 0.877087\tvalid_1's l2: 1.45868\n",
      "[923]\ttraining's l1: 0.148892\ttraining's l2: 0.105159\tvalid_1's l1: 0.87722\tvalid_1's l2: 1.45915\n",
      "[924]\ttraining's l1: 0.148816\ttraining's l2: 0.105031\tvalid_1's l1: 0.877052\tvalid_1's l2: 1.45874\n",
      "[925]\ttraining's l1: 0.148837\ttraining's l2: 0.104942\tvalid_1's l1: 0.876856\tvalid_1's l2: 1.45792\n",
      "[926]\ttraining's l1: 0.148775\ttraining's l2: 0.104809\tvalid_1's l1: 0.877142\tvalid_1's l2: 1.45888\n",
      "[927]\ttraining's l1: 0.148651\ttraining's l2: 0.104687\tvalid_1's l1: 0.877516\tvalid_1's l2: 1.46025\n",
      "[928]\ttraining's l1: 0.14868\ttraining's l2: 0.104527\tvalid_1's l1: 0.877444\tvalid_1's l2: 1.4606\n",
      "[929]\ttraining's l1: 0.148652\ttraining's l2: 0.104473\tvalid_1's l1: 0.877255\tvalid_1's l2: 1.4599\n",
      "[930]\ttraining's l1: 0.148659\ttraining's l2: 0.10439\tvalid_1's l1: 0.877173\tvalid_1's l2: 1.45964\n",
      "[931]\ttraining's l1: 0.148474\ttraining's l2: 0.104183\tvalid_1's l1: 0.877154\tvalid_1's l2: 1.4597\n",
      "[932]\ttraining's l1: 0.148442\ttraining's l2: 0.104077\tvalid_1's l1: 0.877193\tvalid_1's l2: 1.4596\n",
      "[933]\ttraining's l1: 0.148393\ttraining's l2: 0.103931\tvalid_1's l1: 0.876941\tvalid_1's l2: 1.4591\n",
      "[934]\ttraining's l1: 0.148295\ttraining's l2: 0.103867\tvalid_1's l1: 0.877134\tvalid_1's l2: 1.45995\n",
      "[935]\ttraining's l1: 0.148321\ttraining's l2: 0.103717\tvalid_1's l1: 0.876933\tvalid_1's l2: 1.45955\n",
      "[936]\ttraining's l1: 0.148228\ttraining's l2: 0.103654\tvalid_1's l1: 0.877143\tvalid_1's l2: 1.46043\n",
      "[937]\ttraining's l1: 0.148244\ttraining's l2: 0.103567\tvalid_1's l1: 0.87695\tvalid_1's l2: 1.45962\n",
      "[938]\ttraining's l1: 0.148131\ttraining's l2: 0.103421\tvalid_1's l1: 0.877168\tvalid_1's l2: 1.46048\n",
      "[939]\ttraining's l1: 0.148095\ttraining's l2: 0.103358\tvalid_1's l1: 0.877105\tvalid_1's l2: 1.46061\n",
      "[940]\ttraining's l1: 0.148123\ttraining's l2: 0.103211\tvalid_1's l1: 0.876905\tvalid_1's l2: 1.46022\n",
      "[941]\ttraining's l1: 0.147995\ttraining's l2: 0.10309\tvalid_1's l1: 0.877279\tvalid_1's l2: 1.46159\n",
      "[942]\ttraining's l1: 0.147763\ttraining's l2: 0.102888\tvalid_1's l1: 0.877316\tvalid_1's l2: 1.46168\n",
      "[943]\ttraining's l1: 0.147775\ttraining's l2: 0.102803\tvalid_1's l1: 0.877123\tvalid_1's l2: 1.46088\n",
      "[944]\ttraining's l1: 0.147697\ttraining's l2: 0.102679\tvalid_1's l1: 0.876958\tvalid_1's l2: 1.46047\n",
      "[945]\ttraining's l1: 0.147726\ttraining's l2: 0.10252\tvalid_1's l1: 0.877131\tvalid_1's l2: 1.46094\n",
      "[946]\ttraining's l1: 0.147584\ttraining's l2: 0.102333\tvalid_1's l1: 0.877067\tvalid_1's l2: 1.46096\n",
      "[947]\ttraining's l1: 0.1476\ttraining's l2: 0.102248\tvalid_1's l1: 0.876877\tvalid_1's l2: 1.46017\n",
      "[948]\ttraining's l1: 0.147611\ttraining's l2: 0.102169\tvalid_1's l1: 0.876796\tvalid_1's l2: 1.45991\n",
      "[949]\ttraining's l1: 0.147512\ttraining's l2: 0.102105\tvalid_1's l1: 0.876988\tvalid_1's l2: 1.46075\n",
      "[950]\ttraining's l1: 0.147387\ttraining's l2: 0.101987\tvalid_1's l1: 0.877361\tvalid_1's l2: 1.46212\n",
      "[951]\ttraining's l1: 0.147416\ttraining's l2: 0.101831\tvalid_1's l1: 0.877533\tvalid_1's l2: 1.46258\n",
      "[952]\ttraining's l1: 0.147182\ttraining's l2: 0.101635\tvalid_1's l1: 0.877568\tvalid_1's l2: 1.46268\n",
      "[953]\ttraining's l1: 0.147002\ttraining's l2: 0.101487\tvalid_1's l1: 0.878062\tvalid_1's l2: 1.46408\n",
      "[954]\ttraining's l1: 0.146883\ttraining's l2: 0.101371\tvalid_1's l1: 0.878428\tvalid_1's l2: 1.46543\n",
      "[955]\ttraining's l1: 0.146894\ttraining's l2: 0.101287\tvalid_1's l1: 0.878237\tvalid_1's l2: 1.46463\n",
      "[956]\ttraining's l1: 0.146793\ttraining's l2: 0.101148\tvalid_1's l1: 0.878449\tvalid_1's l2: 1.46547\n",
      "[957]\ttraining's l1: 0.146713\ttraining's l2: 0.101027\tvalid_1's l1: 0.878286\tvalid_1's l2: 1.46506\n",
      "[958]\ttraining's l1: 0.146678\ttraining's l2: 0.100975\tvalid_1's l1: 0.878087\tvalid_1's l2: 1.46438\n",
      "[959]\ttraining's l1: 0.146712\ttraining's l2: 0.100832\tvalid_1's l1: 0.877887\tvalid_1's l2: 1.46399\n",
      "[960]\ttraining's l1: 0.146554\ttraining's l2: 0.10064\tvalid_1's l1: 0.877867\tvalid_1's l2: 1.46405\n",
      "[961]\ttraining's l1: 0.146554\ttraining's l2: 0.100558\tvalid_1's l1: 0.87768\tvalid_1's l2: 1.46326\n",
      "[962]\ttraining's l1: 0.146569\ttraining's l2: 0.10048\tvalid_1's l1: 0.877599\tvalid_1's l2: 1.463\n",
      "[963]\ttraining's l1: 0.146432\ttraining's l2: 0.100413\tvalid_1's l1: 0.877815\tvalid_1's l2: 1.46386\n",
      "[964]\ttraining's l1: 0.146362\ttraining's l2: 0.100294\tvalid_1's l1: 0.877653\tvalid_1's l2: 1.46346\n",
      "[965]\ttraining's l1: 0.146326\ttraining's l2: 0.100205\tvalid_1's l1: 0.877292\tvalid_1's l2: 1.46238\n",
      "[966]\ttraining's l1: 0.146229\ttraining's l2: 0.100143\tvalid_1's l1: 0.877481\tvalid_1's l2: 1.46321\n",
      "[967]\ttraining's l1: 0.146211\ttraining's l2: 0.100002\tvalid_1's l1: 0.877942\tvalid_1's l2: 1.46457\n",
      "[968]\ttraining's l1: 0.146252\ttraining's l2: 0.0998623\tvalid_1's l1: 0.877746\tvalid_1's l2: 1.46419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[969]\ttraining's l1: 0.146108\ttraining's l2: 0.0997136\tvalid_1's l1: 0.877554\tvalid_1's l2: 1.46376\n",
      "[970]\ttraining's l1: 0.145946\ttraining's l2: 0.099647\tvalid_1's l1: 0.877773\tvalid_1's l2: 1.46462\n",
      "[971]\ttraining's l1: 0.145948\ttraining's l2: 0.0995666\tvalid_1's l1: 0.877588\tvalid_1's l2: 1.46385\n",
      "[972]\ttraining's l1: 0.145902\ttraining's l2: 0.0994291\tvalid_1's l1: 0.877557\tvalid_1's l2: 1.4637\n",
      "[973]\ttraining's l1: 0.145924\ttraining's l2: 0.0992814\tvalid_1's l1: 0.877499\tvalid_1's l2: 1.46373\n",
      "[974]\ttraining's l1: 0.145784\ttraining's l2: 0.0992161\tvalid_1's l1: 0.877714\tvalid_1's l2: 1.46458\n",
      "[975]\ttraining's l1: 0.145645\ttraining's l2: 0.0991313\tvalid_1's l1: 0.877854\tvalid_1's l2: 1.46492\n",
      "[976]\ttraining's l1: 0.145519\ttraining's l2: 0.099017\tvalid_1's l1: 0.878217\tvalid_1's l2: 1.46626\n",
      "[977]\ttraining's l1: 0.145425\ttraining's l2: 0.0988837\tvalid_1's l1: 0.878704\tvalid_1's l2: 1.46757\n",
      "[978]\ttraining's l1: 0.145286\ttraining's l2: 0.0986981\tvalid_1's l1: 0.878686\tvalid_1's l2: 1.46763\n",
      "[979]\ttraining's l1: 0.145221\ttraining's l2: 0.0985836\tvalid_1's l1: 0.878528\tvalid_1's l2: 1.46724\n",
      "[980]\ttraining's l1: 0.145212\ttraining's l2: 0.0985033\tvalid_1's l1: 0.878342\tvalid_1's l2: 1.46646\n",
      "[981]\ttraining's l1: 0.145164\ttraining's l2: 0.0984048\tvalid_1's l1: 0.87838\tvalid_1's l2: 1.46637\n",
      "[982]\ttraining's l1: 0.145165\ttraining's l2: 0.0982692\tvalid_1's l1: 0.878831\tvalid_1's l2: 1.4677\n",
      "[983]\ttraining's l1: 0.145132\ttraining's l2: 0.0981332\tvalid_1's l1: 0.878584\tvalid_1's l2: 1.46721\n",
      "[984]\ttraining's l1: 0.145134\ttraining's l2: 0.098055\tvalid_1's l1: 0.878399\tvalid_1's l2: 1.46645\n",
      "[985]\ttraining's l1: 0.145164\ttraining's l2: 0.0979185\tvalid_1's l1: 0.878202\tvalid_1's l2: 1.46606\n",
      "[986]\ttraining's l1: 0.145125\ttraining's l2: 0.0978441\tvalid_1's l1: 0.878416\tvalid_1's l2: 1.46708\n",
      "[987]\ttraining's l1: 0.144999\ttraining's l2: 0.097732\tvalid_1's l1: 0.878775\tvalid_1's l2: 1.4684\n",
      "[988]\ttraining's l1: 0.144963\ttraining's l2: 0.097613\tvalid_1's l1: 0.878752\tvalid_1's l2: 1.46813\n",
      "[989]\ttraining's l1: 0.144894\ttraining's l2: 0.0974719\tvalid_1's l1: 0.878697\tvalid_1's l2: 1.46776\n",
      "[990]\ttraining's l1: 0.14479\ttraining's l2: 0.0973513\tvalid_1's l1: 0.878757\tvalid_1's l2: 1.46803\n",
      "[991]\ttraining's l1: 0.144671\ttraining's l2: 0.0972407\tvalid_1's l1: 0.879113\tvalid_1's l2: 1.46935\n",
      "[992]\ttraining's l1: 0.144533\ttraining's l2: 0.0970884\tvalid_1's l1: 0.879107\tvalid_1's l2: 1.46924\n",
      "[993]\ttraining's l1: 0.144502\ttraining's l2: 0.0969548\tvalid_1's l1: 0.878863\tvalid_1's l2: 1.46875\n",
      "[994]\ttraining's l1: 0.144467\ttraining's l2: 0.0969063\tvalid_1's l1: 0.878671\tvalid_1's l2: 1.4681\n",
      "[995]\ttraining's l1: 0.144338\ttraining's l2: 0.0968329\tvalid_1's l1: 0.878947\tvalid_1's l2: 1.46906\n",
      "[996]\ttraining's l1: 0.144259\ttraining's l2: 0.0967239\tvalid_1's l1: 0.879193\tvalid_1's l2: 1.46997\n",
      "[997]\ttraining's l1: 0.144195\ttraining's l2: 0.0966169\tvalid_1's l1: 0.878875\tvalid_1's l2: 1.46854\n",
      "[998]\ttraining's l1: 0.144103\ttraining's l2: 0.0964984\tvalid_1's l1: 0.879127\tvalid_1's l2: 1.46949\n",
      "[999]\ttraining's l1: 0.144075\ttraining's l2: 0.0963829\tvalid_1's l1: 0.879103\tvalid_1's l2: 1.46921\n",
      "[1000]\ttraining's l1: 0.143883\ttraining's l2: 0.0962033\tvalid_1's l1: 0.879139\tvalid_1's l2: 1.46931\n",
      "[1001]\ttraining's l1: 0.143825\ttraining's l2: 0.0960726\tvalid_1's l1: 0.879096\tvalid_1's l2: 1.46907\n",
      "[1002]\ttraining's l1: 0.143705\ttraining's l2: 0.0959365\tvalid_1's l1: 0.878878\tvalid_1's l2: 1.46849\n",
      "[1003]\ttraining's l1: 0.14359\ttraining's l2: 0.0958283\tvalid_1's l1: 0.87923\tvalid_1's l2: 1.4698\n",
      "[1004]\ttraining's l1: 0.143548\ttraining's l2: 0.0957797\tvalid_1's l1: 0.879039\tvalid_1's l2: 1.46914\n",
      "[1005]\ttraining's l1: 0.14356\ttraining's l2: 0.0956918\tvalid_1's l1: 0.878933\tvalid_1's l2: 1.46914\n",
      "[1006]\ttraining's l1: 0.143493\ttraining's l2: 0.095555\tvalid_1's l1: 0.879055\tvalid_1's l2: 1.46968\n",
      "[1007]\ttraining's l1: 0.143441\ttraining's l2: 0.0954608\tvalid_1's l1: 0.879092\tvalid_1's l2: 1.46959\n",
      "[1008]\ttraining's l1: 0.143364\ttraining's l2: 0.0953257\tvalid_1's l1: 0.879022\tvalid_1's l2: 1.46947\n",
      "[1009]\ttraining's l1: 0.143415\ttraining's l2: 0.0951835\tvalid_1's l1: 0.878964\tvalid_1's l2: 1.46979\n",
      "[1010]\ttraining's l1: 0.143362\ttraining's l2: 0.0950907\tvalid_1's l1: 0.879001\tvalid_1's l2: 1.4697\n",
      "[1011]\ttraining's l1: 0.143333\ttraining's l2: 0.0949591\tvalid_1's l1: 0.879042\tvalid_1's l2: 1.46983\n",
      "[1012]\ttraining's l1: 0.143215\ttraining's l2: 0.0948514\tvalid_1's l1: 0.879395\tvalid_1's l2: 1.47114\n",
      "[1013]\ttraining's l1: 0.14307\ttraining's l2: 0.094705\tvalid_1's l1: 0.879393\tvalid_1's l2: 1.47107\n",
      "[1014]\ttraining's l1: 0.14305\ttraining's l2: 0.0945763\tvalid_1's l1: 0.879154\tvalid_1's l2: 1.4706\n",
      "[1015]\ttraining's l1: 0.143052\ttraining's l2: 0.094503\tvalid_1's l1: 0.878975\tvalid_1's l2: 1.46986\n",
      "[1016]\ttraining's l1: 0.142984\ttraining's l2: 0.0943703\tvalid_1's l1: 0.879097\tvalid_1's l2: 1.4704\n",
      "[1017]\ttraining's l1: 0.142899\ttraining's l2: 0.0943116\tvalid_1's l1: 0.879243\tvalid_1's l2: 1.47116\n",
      "[1018]\ttraining's l1: 0.14278\ttraining's l2: 0.0942398\tvalid_1's l1: 0.879516\tvalid_1's l2: 1.47212\n",
      "[1019]\ttraining's l1: 0.142737\ttraining's l2: 0.0941683\tvalid_1's l1: 0.879725\tvalid_1's l2: 1.47311\n",
      "[1020]\ttraining's l1: 0.142641\ttraining's l2: 0.094056\tvalid_1's l1: 0.879783\tvalid_1's l2: 1.47338\n",
      "[1021]\ttraining's l1: 0.142546\ttraining's l2: 0.093961\tvalid_1's l1: 0.87982\tvalid_1's l2: 1.47328\n",
      "[1022]\ttraining's l1: 0.142487\ttraining's l2: 0.093893\tvalid_1's l1: 0.880167\tvalid_1's l2: 1.47431\n",
      "[1023]\ttraining's l1: 0.142294\ttraining's l2: 0.0936992\tvalid_1's l1: 0.88029\tvalid_1's l2: 1.47475\n",
      "[1024]\ttraining's l1: 0.142203\ttraining's l2: 0.0936302\tvalid_1's l1: 0.880637\tvalid_1's l2: 1.47575\n",
      "[1025]\ttraining's l1: 0.142175\ttraining's l2: 0.0935229\tvalid_1's l1: 0.880628\tvalid_1's l2: 1.47585\n",
      "[1026]\ttraining's l1: 0.142073\ttraining's l2: 0.0934196\tvalid_1's l1: 0.880972\tvalid_1's l2: 1.47712\n",
      "[1027]\ttraining's l1: 0.141938\ttraining's l2: 0.0932464\tvalid_1's l1: 0.880967\tvalid_1's l2: 1.47719\n",
      "[1028]\ttraining's l1: 0.141747\ttraining's l2: 0.0930567\tvalid_1's l1: 0.881091\tvalid_1's l2: 1.47763\n",
      "[1029]\ttraining's l1: 0.141617\ttraining's l2: 0.0930094\tvalid_1's l1: 0.88102\tvalid_1's l2: 1.47702\n",
      "[1030]\ttraining's l1: 0.141606\ttraining's l2: 0.0929363\tvalid_1's l1: 0.880829\tvalid_1's l2: 1.47626\n",
      "[1031]\ttraining's l1: 0.141584\ttraining's l2: 0.092827\tvalid_1's l1: 0.8808\tvalid_1's l2: 1.47598\n",
      "[1032]\ttraining's l1: 0.141393\ttraining's l2: 0.092657\tvalid_1's l1: 0.880835\tvalid_1's l2: 1.47608\n",
      "[1033]\ttraining's l1: 0.141332\ttraining's l2: 0.092531\tvalid_1's l1: 0.880792\tvalid_1's l2: 1.47584\n",
      "[1034]\ttraining's l1: 0.141187\ttraining's l2: 0.0923914\tvalid_1's l1: 0.880789\tvalid_1's l2: 1.47577\n",
      "[1035]\ttraining's l1: 0.141144\ttraining's l2: 0.0923452\tvalid_1's l1: 0.8806\tvalid_1's l2: 1.47512\n",
      "[1036]\ttraining's l1: 0.141116\ttraining's l2: 0.0922396\tvalid_1's l1: 0.880602\tvalid_1's l2: 1.47523\n",
      "[1037]\ttraining's l1: 0.141015\ttraining's l2: 0.0921373\tvalid_1's l1: 0.880941\tvalid_1's l2: 1.4765\n",
      "[1038]\ttraining's l1: 0.140997\ttraining's l2: 0.0920119\tvalid_1's l1: 0.880704\tvalid_1's l2: 1.47604\n",
      "[1039]\ttraining's l1: 0.140987\ttraining's l2: 0.091941\tvalid_1's l1: 0.880525\tvalid_1's l2: 1.4753\n",
      "[1040]\ttraining's l1: 0.140933\ttraining's l2: 0.0918139\tvalid_1's l1: 0.88064\tvalid_1's l2: 1.47582\n",
      "[1041]\ttraining's l1: 0.140766\ttraining's l2: 0.0917002\tvalid_1's l1: 0.88068\tvalid_1's l2: 1.476\n",
      "[1042]\ttraining's l1: 0.140691\ttraining's l2: 0.0916376\tvalid_1's l1: 0.880954\tvalid_1's l2: 1.47695\n",
      "[1043]\ttraining's l1: 0.140598\ttraining's l2: 0.0915458\tvalid_1's l1: 0.880991\tvalid_1's l2: 1.47686\n",
      "[1044]\ttraining's l1: 0.140568\ttraining's l2: 0.091432\tvalid_1's l1: 0.880747\tvalid_1's l2: 1.47634\n",
      "[1045]\ttraining's l1: 0.140385\ttraining's l2: 0.0912671\tvalid_1's l1: 0.880782\tvalid_1's l2: 1.47644\n",
      "[1046]\ttraining's l1: 0.140368\ttraining's l2: 0.0911448\tvalid_1's l1: 0.880549\tvalid_1's l2: 1.47599\n",
      "[1047]\ttraining's l1: 0.140314\ttraining's l2: 0.0910582\tvalid_1's l1: 0.880583\tvalid_1's l2: 1.47589\n",
      "[1048]\ttraining's l1: 0.140213\ttraining's l2: 0.0909577\tvalid_1's l1: 0.880919\tvalid_1's l2: 1.47715\n",
      "[1049]\ttraining's l1: 0.14013\ttraining's l2: 0.0908509\tvalid_1's l1: 0.880977\tvalid_1's l2: 1.47742\n",
      "[1050]\ttraining's l1: 0.14012\ttraining's l2: 0.0907814\tvalid_1's l1: 0.880797\tvalid_1's l2: 1.47669\n",
      "[1051]\ttraining's l1: 0.140065\ttraining's l2: 0.0907175\tvalid_1's l1: 0.881132\tvalid_1's l2: 1.47768\n",
      "[1052]\ttraining's l1: 0.140108\ttraining's l2: 0.090582\tvalid_1's l1: 0.881071\tvalid_1's l2: 1.47799\n",
      "[1053]\ttraining's l1: 0.139972\ttraining's l2: 0.0904295\tvalid_1's l1: 0.881011\tvalid_1's l2: 1.4779\n",
      "[1054]\ttraining's l1: 0.13992\ttraining's l2: 0.090385\tvalid_1's l1: 0.88084\tvalid_1's l2: 1.47727\n",
      "[1055]\ttraining's l1: 0.139856\ttraining's l2: 0.0902793\tvalid_1's l1: 0.881081\tvalid_1's l2: 1.47818\n",
      "[1056]\ttraining's l1: 0.139676\ttraining's l2: 0.0900977\tvalid_1's l1: 0.881199\tvalid_1's l2: 1.47861\n",
      "[1057]\ttraining's l1: 0.139667\ttraining's l2: 0.0899782\tvalid_1's l1: 0.880969\tvalid_1's l2: 1.47816\n",
      "[1058]\ttraining's l1: 0.139633\ttraining's l2: 0.0899313\tvalid_1's l1: 0.8808\tvalid_1's l2: 1.47771\n",
      "[1059]\ttraining's l1: 0.139657\ttraining's l2: 0.0898048\tvalid_1's l1: 0.88061\tvalid_1's l2: 1.47734\n",
      "[1060]\ttraining's l1: 0.139561\ttraining's l2: 0.0897062\tvalid_1's l1: 0.880935\tvalid_1's l2: 1.47859\n",
      "[1061]\ttraining's l1: 0.139414\ttraining's l2: 0.0895728\tvalid_1's l1: 0.880933\tvalid_1's l2: 1.47853\n",
      "[1062]\ttraining's l1: 0.139358\ttraining's l2: 0.0894574\tvalid_1's l1: 0.88098\tvalid_1's l2: 1.47869\n",
      "[1063]\ttraining's l1: 0.139281\ttraining's l2: 0.0893604\tvalid_1's l1: 0.880667\tvalid_1's l2: 1.47735\n",
      "[1064]\ttraining's l1: 0.139175\ttraining's l2: 0.0892534\tvalid_1's l1: 0.88093\tvalid_1's l2: 1.47832\n",
      "[1065]\ttraining's l1: 0.139094\ttraining's l2: 0.0891511\tvalid_1's l1: 0.880987\tvalid_1's l2: 1.47859\n",
      "[1066]\ttraining's l1: 0.139009\ttraining's l2: 0.0890637\tvalid_1's l1: 0.881023\tvalid_1's l2: 1.47851\n",
      "[1067]\ttraining's l1: 0.138911\ttraining's l2: 0.0889978\tvalid_1's l1: 0.881357\tvalid_1's l2: 1.47949\n",
      "[1068]\ttraining's l1: 0.138892\ttraining's l2: 0.0889207\tvalid_1's l1: 0.881295\tvalid_1's l2: 1.47937\n",
      "[1069]\ttraining's l1: 0.138827\ttraining's l2: 0.0888072\tvalid_1's l1: 0.881342\tvalid_1's l2: 1.47953\n",
      "[1070]\ttraining's l1: 0.138649\ttraining's l2: 0.0886303\tvalid_1's l1: 0.881458\tvalid_1's l2: 1.47996\n",
      "[1071]\ttraining's l1: 0.138539\ttraining's l2: 0.0885654\tvalid_1's l1: 0.881716\tvalid_1's l2: 1.48087\n",
      "[1072]\ttraining's l1: 0.138484\ttraining's l2: 0.0884694\tvalid_1's l1: 0.881938\tvalid_1's l2: 1.4817\n",
      "[1073]\ttraining's l1: 0.138304\ttraining's l2: 0.0883211\tvalid_1's l1: 0.881929\tvalid_1's l2: 1.48165\n",
      "[1074]\ttraining's l1: 0.138278\ttraining's l2: 0.0882134\tvalid_1's l1: 0.881698\tvalid_1's l2: 1.48115\n",
      "[1075]\ttraining's l1: 0.138201\ttraining's l2: 0.0881174\tvalid_1's l1: 0.881386\tvalid_1's l2: 1.47982\n",
      "[1076]\ttraining's l1: 0.138165\ttraining's l2: 0.0880499\tvalid_1's l1: 0.881589\tvalid_1's l2: 1.48079\n",
      "[1077]\ttraining's l1: 0.138202\ttraining's l2: 0.0879191\tvalid_1's l1: 0.881525\tvalid_1's l2: 1.4808\n",
      "[1078]\ttraining's l1: 0.138114\ttraining's l2: 0.0878246\tvalid_1's l1: 0.881839\tvalid_1's l2: 1.48202\n",
      "[1079]\ttraining's l1: 0.138033\ttraining's l2: 0.0876786\tvalid_1's l1: 0.881822\tvalid_1's l2: 1.48209\n",
      "[1080]\ttraining's l1: 0.138018\ttraining's l2: 0.0876116\tvalid_1's l1: 0.881681\tvalid_1's l2: 1.48147\n",
      "[1081]\ttraining's l1: 0.137873\ttraining's l2: 0.0874725\tvalid_1's l1: 0.881634\tvalid_1's l2: 1.48106\n",
      "[1082]\ttraining's l1: 0.137798\ttraining's l2: 0.0873721\tvalid_1's l1: 0.88187\tvalid_1's l2: 1.48195\n",
      "[1083]\ttraining's l1: 0.137682\ttraining's l2: 0.087309\tvalid_1's l1: 0.882126\tvalid_1's l2: 1.48285\n",
      "[1084]\ttraining's l1: 0.137557\ttraining's l2: 0.0872662\tvalid_1's l1: 0.882066\tvalid_1's l2: 1.48226\n",
      "[1085]\ttraining's l1: 0.13761\ttraining's l2: 0.0871368\tvalid_1's l1: 0.882005\tvalid_1's l2: 1.48257\n",
      "[1086]\ttraining's l1: 0.137567\ttraining's l2: 0.0870938\tvalid_1's l1: 0.881821\tvalid_1's l2: 1.48194\n",
      "[1087]\ttraining's l1: 0.137506\ttraining's l2: 0.0870329\tvalid_1's l1: 0.881974\tvalid_1's l2: 1.48265\n",
      "[1088]\ttraining's l1: 0.137465\ttraining's l2: 0.0869904\tvalid_1's l1: 0.88179\tvalid_1's l2: 1.48202\n",
      "[1089]\ttraining's l1: 0.137422\ttraining's l2: 0.0869301\tvalid_1's l1: 0.882116\tvalid_1's l2: 1.48299\n",
      "[1090]\ttraining's l1: 0.137261\ttraining's l2: 0.0867611\tvalid_1's l1: 0.882228\tvalid_1's l2: 1.4834\n",
      "[1091]\ttraining's l1: 0.137228\ttraining's l2: 0.0866611\tvalid_1's l1: 0.882198\tvalid_1's l2: 1.48313\n",
      "[1092]\ttraining's l1: 0.137199\ttraining's l2: 0.0865856\tvalid_1's l1: 0.882134\tvalid_1's l2: 1.48301\n",
      "[1093]\ttraining's l1: 0.13721\ttraining's l2: 0.0864636\tvalid_1's l1: 0.881946\tvalid_1's l2: 1.48264\n",
      "[1094]\ttraining's l1: 0.137141\ttraining's l2: 0.0863803\tvalid_1's l1: 0.881982\tvalid_1's l2: 1.48256\n",
      "[1095]\ttraining's l1: 0.137139\ttraining's l2: 0.0862673\tvalid_1's l1: 0.881758\tvalid_1's l2: 1.48212\n",
      "[1096]\ttraining's l1: 0.136985\ttraining's l2: 0.0861493\tvalid_1's l1: 0.881713\tvalid_1's l2: 1.48192\n",
      "[1097]\ttraining's l1: 0.136887\ttraining's l2: 0.0860564\tvalid_1's l1: 0.882018\tvalid_1's l2: 1.48313\n",
      "[1098]\ttraining's l1: 0.136877\ttraining's l2: 0.0859915\tvalid_1's l1: 0.881862\tvalid_1's l2: 1.48248\n",
      "[1099]\ttraining's l1: 0.136833\ttraining's l2: 0.0858945\tvalid_1's l1: 0.881864\tvalid_1's l2: 1.48258\n",
      "[1100]\ttraining's l1: 0.1368\ttraining's l2: 0.0858292\tvalid_1's l1: 0.882063\tvalid_1's l2: 1.48354\n",
      "[1101]\ttraining's l1: 0.136768\ttraining's l2: 0.0857718\tvalid_1's l1: 0.882392\tvalid_1's l2: 1.48451\n",
      "[1102]\ttraining's l1: 0.136663\ttraining's l2: 0.0856476\tvalid_1's l1: 0.882343\tvalid_1's l2: 1.48435\n",
      "[1103]\ttraining's l1: 0.136633\ttraining's l2: 0.085574\tvalid_1's l1: 0.882282\tvalid_1's l2: 1.48424\n",
      "[1104]\ttraining's l1: 0.136572\ttraining's l2: 0.0855146\tvalid_1's l1: 0.882432\tvalid_1's l2: 1.48494\n",
      "[1105]\ttraining's l1: 0.136515\ttraining's l2: 0.0854058\tvalid_1's l1: 0.882479\tvalid_1's l2: 1.48511\n",
      "[1106]\ttraining's l1: 0.136447\ttraining's l2: 0.085324\tvalid_1's l1: 0.882515\tvalid_1's l2: 1.48503\n",
      "[1107]\ttraining's l1: 0.136322\ttraining's l2: 0.0852817\tvalid_1's l1: 0.882458\tvalid_1's l2: 1.48445\n",
      "[1108]\ttraining's l1: 0.136154\ttraining's l2: 0.0851393\tvalid_1's l1: 0.882316\tvalid_1's l2: 1.48422\n",
      "[1109]\ttraining's l1: 0.136081\ttraining's l2: 0.085048\tvalid_1's l1: 0.882518\tvalid_1's l2: 1.48504\n",
      "[1110]\ttraining's l1: 0.13607\ttraining's l2: 0.0849841\tvalid_1's l1: 0.882364\tvalid_1's l2: 1.4844\n",
      "[1111]\ttraining's l1: 0.136049\ttraining's l2: 0.084889\tvalid_1's l1: 0.882541\tvalid_1's l2: 1.48512\n",
      "[1112]\ttraining's l1: 0.136102\ttraining's l2: 0.0847642\tvalid_1's l1: 0.882481\tvalid_1's l2: 1.48542\n",
      "[1113]\ttraining's l1: 0.135952\ttraining's l2: 0.0846496\tvalid_1's l1: 0.882436\tvalid_1's l2: 1.48522\n",
      "[1114]\ttraining's l1: 0.135802\ttraining's l2: 0.0844862\tvalid_1's l1: 0.882547\tvalid_1's l2: 1.48563\n",
      "[1115]\ttraining's l1: 0.13574\ttraining's l2: 0.0844277\tvalid_1's l1: 0.882696\tvalid_1's l2: 1.48634\n",
      "[1116]\ttraining's l1: 0.135687\ttraining's l2: 0.084348\tvalid_1's l1: 0.882732\tvalid_1's l2: 1.48626\n",
      "[1117]\ttraining's l1: 0.135569\ttraining's l2: 0.0843065\tvalid_1's l1: 0.882673\tvalid_1's l2: 1.48568\n",
      "[1118]\ttraining's l1: 0.135387\ttraining's l2: 0.0841696\tvalid_1's l1: 0.882664\tvalid_1's l2: 1.48564\n",
      "[1119]\ttraining's l1: 0.135376\ttraining's l2: 0.0841068\tvalid_1's l1: 0.88251\tvalid_1's l2: 1.485\n",
      "[1120]\ttraining's l1: 0.135411\ttraining's l2: 0.0839834\tvalid_1's l1: 0.882448\tvalid_1's l2: 1.48502\n",
      "[1121]\ttraining's l1: 0.135384\ttraining's l2: 0.0839115\tvalid_1's l1: 0.882389\tvalid_1's l2: 1.48491\n",
      "[1122]\ttraining's l1: 0.135322\ttraining's l2: 0.0838531\tvalid_1's l1: 0.882539\tvalid_1's l2: 1.48562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1123]\ttraining's l1: 0.135274\ttraining's l2: 0.0837451\tvalid_1's l1: 0.88248\tvalid_1's l2: 1.4856\n",
      "[1124]\ttraining's l1: 0.135183\ttraining's l2: 0.0836555\tvalid_1's l1: 0.882785\tvalid_1's l2: 1.48679\n",
      "[1125]\ttraining's l1: 0.135176\ttraining's l2: 0.0835933\tvalid_1's l1: 0.882613\tvalid_1's l2: 1.48609\n",
      "[1126]\ttraining's l1: 0.135224\ttraining's l2: 0.0834715\tvalid_1's l1: 0.882555\tvalid_1's l2: 1.48639\n",
      "[1127]\ttraining's l1: 0.135134\ttraining's l2: 0.0833833\tvalid_1's l1: 0.882859\tvalid_1's l2: 1.48757\n",
      "[1128]\ttraining's l1: 0.135123\ttraining's l2: 0.0833219\tvalid_1's l1: 0.882709\tvalid_1's l2: 1.48695\n",
      "[1129]\ttraining's l1: 0.135082\ttraining's l2: 0.0832587\tvalid_1's l1: 0.882941\tvalid_1's l2: 1.48793\n",
      "[1130]\ttraining's l1: 0.135036\ttraining's l2: 0.0831528\tvalid_1's l1: 0.882882\tvalid_1's l2: 1.48792\n",
      "[1131]\ttraining's l1: 0.13496\ttraining's l2: 0.0830656\tvalid_1's l1: 0.883077\tvalid_1's l2: 1.48872\n",
      "[1132]\ttraining's l1: 0.135007\ttraining's l2: 0.082946\tvalid_1's l1: 0.883019\tvalid_1's l2: 1.48902\n",
      "[1133]\ttraining's l1: 0.134872\ttraining's l2: 0.082835\tvalid_1's l1: 0.882975\tvalid_1's l2: 1.48882\n",
      "[1134]\ttraining's l1: 0.134801\ttraining's l2: 0.0827489\tvalid_1's l1: 0.882684\tvalid_1's l2: 1.48757\n",
      "[1135]\ttraining's l1: 0.134738\ttraining's l2: 0.0826919\tvalid_1's l1: 0.882832\tvalid_1's l2: 1.48826\n",
      "[1136]\ttraining's l1: 0.134774\ttraining's l2: 0.0825733\tvalid_1's l1: 0.882773\tvalid_1's l2: 1.48829\n",
      "[1137]\ttraining's l1: 0.134689\ttraining's l2: 0.082453\tvalid_1's l1: 0.88286\tvalid_1's l2: 1.48846\n",
      "[1138]\ttraining's l1: 0.134573\ttraining's l2: 0.0823174\tvalid_1's l1: 0.882672\tvalid_1's l2: 1.4882\n",
      "[1139]\ttraining's l1: 0.13452\ttraining's l2: 0.0822412\tvalid_1's l1: 0.882708\tvalid_1's l2: 1.48813\n",
      "[1140]\ttraining's l1: 0.134459\ttraining's l2: 0.0821849\tvalid_1's l1: 0.882855\tvalid_1's l2: 1.48882\n",
      "[1141]\ttraining's l1: 0.134421\ttraining's l2: 0.0821433\tvalid_1's l1: 0.882693\tvalid_1's l2: 1.48838\n",
      "[1142]\ttraining's l1: 0.134361\ttraining's l2: 0.0820877\tvalid_1's l1: 0.88284\tvalid_1's l2: 1.48907\n",
      "[1143]\ttraining's l1: 0.134274\ttraining's l2: 0.0820018\tvalid_1's l1: 0.883146\tvalid_1's l2: 1.49023\n",
      "[1144]\ttraining's l1: 0.134265\ttraining's l2: 0.0819415\tvalid_1's l1: 0.882969\tvalid_1's l2: 1.48954\n",
      "[1145]\ttraining's l1: 0.134174\ttraining's l2: 0.0818996\tvalid_1's l1: 0.882962\tvalid_1's l2: 1.48895\n",
      "[1146]\ttraining's l1: 0.134142\ttraining's l2: 0.0818452\tvalid_1's l1: 0.883281\tvalid_1's l2: 1.48989\n",
      "[1147]\ttraining's l1: 0.134121\ttraining's l2: 0.0817352\tvalid_1's l1: 0.883255\tvalid_1's l2: 1.48992\n",
      "[1148]\ttraining's l1: 0.134033\ttraining's l2: 0.0816135\tvalid_1's l1: 0.883308\tvalid_1's l2: 1.49007\n",
      "[1149]\ttraining's l1: 0.133895\ttraining's l2: 0.0815062\tvalid_1's l1: 0.883264\tvalid_1's l2: 1.48987\n",
      "[1150]\ttraining's l1: 0.133853\ttraining's l2: 0.0814679\tvalid_1's l1: 0.883089\tvalid_1's l2: 1.48927\n",
      "[1151]\ttraining's l1: 0.133827\ttraining's l2: 0.0813988\tvalid_1's l1: 0.88303\tvalid_1's l2: 1.48916\n",
      "[1152]\ttraining's l1: 0.133781\ttraining's l2: 0.0812962\tvalid_1's l1: 0.882973\tvalid_1's l2: 1.48916\n",
      "[1153]\ttraining's l1: 0.133693\ttraining's l2: 0.0812108\tvalid_1's l1: 0.883281\tvalid_1's l2: 1.49032\n",
      "[1154]\ttraining's l1: 0.133672\ttraining's l2: 0.0811272\tvalid_1's l1: 0.883133\tvalid_1's l2: 1.48997\n",
      "[1155]\ttraining's l1: 0.133706\ttraining's l2: 0.081012\tvalid_1's l1: 0.883076\tvalid_1's l2: 1.49\n",
      "[1156]\ttraining's l1: 0.133615\ttraining's l2: 0.0809282\tvalid_1's l1: 0.883364\tvalid_1's l2: 1.49116\n",
      "[1157]\ttraining's l1: 0.133601\ttraining's l2: 0.0808691\tvalid_1's l1: 0.883199\tvalid_1's l2: 1.49049\n",
      "[1158]\ttraining's l1: 0.133555\ttraining's l2: 0.0808083\tvalid_1's l1: 0.883424\tvalid_1's l2: 1.49144\n",
      "[1159]\ttraining's l1: 0.133478\ttraining's l2: 0.0807507\tvalid_1's l1: 0.883636\tvalid_1's l2: 1.4922\n",
      "[1160]\ttraining's l1: 0.133385\ttraining's l2: 0.0807093\tvalid_1's l1: 0.883622\tvalid_1's l2: 1.4916\n",
      "[1161]\ttraining's l1: 0.133368\ttraining's l2: 0.0806507\tvalid_1's l1: 0.883477\tvalid_1's l2: 1.49099\n",
      "[1162]\ttraining's l1: 0.133336\ttraining's l2: 0.0805435\tvalid_1's l1: 0.88342\tvalid_1's l2: 1.49105\n",
      "[1163]\ttraining's l1: 0.133265\ttraining's l2: 0.080425\tvalid_1's l1: 0.88349\tvalid_1's l2: 1.49123\n",
      "[1164]\ttraining's l1: 0.133151\ttraining's l2: 0.0803171\tvalid_1's l1: 0.883316\tvalid_1's l2: 1.49085\n",
      "[1165]\ttraining's l1: 0.133105\ttraining's l2: 0.0802341\tvalid_1's l1: 0.88352\tvalid_1's l2: 1.49162\n",
      "[1166]\ttraining's l1: 0.133051\ttraining's l2: 0.0801964\tvalid_1's l1: 0.883346\tvalid_1's l2: 1.49102\n",
      "[1167]\ttraining's l1: 0.13298\ttraining's l2: 0.0801393\tvalid_1's l1: 0.883556\tvalid_1's l2: 1.49178\n",
      "[1168]\ttraining's l1: 0.13293\ttraining's l2: 0.0801019\tvalid_1's l1: 0.883387\tvalid_1's l2: 1.49118\n",
      "[1169]\ttraining's l1: 0.13292\ttraining's l2: 0.08002\tvalid_1's l1: 0.883239\tvalid_1's l2: 1.49084\n",
      "[1170]\ttraining's l1: 0.13287\ttraining's l2: 0.0799668\tvalid_1's l1: 0.883487\tvalid_1's l2: 1.49171\n",
      "[1171]\ttraining's l1: 0.132843\ttraining's l2: 0.079909\tvalid_1's l1: 0.883323\tvalid_1's l2: 1.49104\n",
      "[1172]\ttraining's l1: 0.132859\ttraining's l2: 0.0797918\tvalid_1's l1: 0.883409\tvalid_1's l2: 1.49166\n",
      "[1173]\ttraining's l1: 0.132787\ttraining's l2: 0.0797354\tvalid_1's l1: 0.883628\tvalid_1's l2: 1.49242\n",
      "[1174]\ttraining's l1: 0.132765\ttraining's l2: 0.0796506\tvalid_1's l1: 0.883525\tvalid_1's l2: 1.492\n",
      "[1175]\ttraining's l1: 0.132735\ttraining's l2: 0.0795569\tvalid_1's l1: 0.883704\tvalid_1's l2: 1.49271\n",
      "[1176]\ttraining's l1: 0.132604\ttraining's l2: 0.0794282\tvalid_1's l1: 0.883734\tvalid_1's l2: 1.49281\n",
      "[1177]\ttraining's l1: 0.132543\ttraining's l2: 0.0793164\tvalid_1's l1: 0.883809\tvalid_1's l2: 1.49293\n",
      "[1178]\ttraining's l1: 0.132398\ttraining's l2: 0.079214\tvalid_1's l1: 0.883766\tvalid_1's l2: 1.49274\n",
      "[1179]\ttraining's l1: 0.132381\ttraining's l2: 0.0791255\tvalid_1's l1: 0.88376\tvalid_1's l2: 1.49257\n",
      "[1180]\ttraining's l1: 0.132307\ttraining's l2: 0.0790693\tvalid_1's l1: 0.883969\tvalid_1's l2: 1.49333\n",
      "[1181]\ttraining's l1: 0.13227\ttraining's l2: 0.0789968\tvalid_1's l1: 0.884004\tvalid_1's l2: 1.49326\n",
      "[1182]\ttraining's l1: 0.132195\ttraining's l2: 0.0789153\tvalid_1's l1: 0.8843\tvalid_1's l2: 1.49439\n",
      "[1183]\ttraining's l1: 0.132101\ttraining's l2: 0.0788751\tvalid_1's l1: 0.884285\tvalid_1's l2: 1.49381\n",
      "[1184]\ttraining's l1: 0.131975\ttraining's l2: 0.0787692\tvalid_1's l1: 0.884083\tvalid_1's l2: 1.49328\n",
      "[1185]\ttraining's l1: 0.131931\ttraining's l2: 0.0786888\tvalid_1's l1: 0.884283\tvalid_1's l2: 1.49404\n",
      "[1186]\ttraining's l1: 0.131882\ttraining's l2: 0.0786522\tvalid_1's l1: 0.884113\tvalid_1's l2: 1.49345\n",
      "[1187]\ttraining's l1: 0.131767\ttraining's l2: 0.0786018\tvalid_1's l1: 0.884034\tvalid_1's l2: 1.49279\n",
      "[1188]\ttraining's l1: 0.131719\ttraining's l2: 0.0785503\tvalid_1's l1: 0.884278\tvalid_1's l2: 1.49365\n",
      "[1189]\ttraining's l1: 0.131649\ttraining's l2: 0.0784702\tvalid_1's l1: 0.883989\tvalid_1's l2: 1.49242\n",
      "[1190]\ttraining's l1: 0.131619\ttraining's l2: 0.0784116\tvalid_1's l1: 0.884212\tvalid_1's l2: 1.49336\n",
      "[1191]\ttraining's l1: 0.131575\ttraining's l2: 0.0783608\tvalid_1's l1: 0.884454\tvalid_1's l2: 1.49421\n",
      "[1192]\ttraining's l1: 0.131504\ttraining's l2: 0.0782243\tvalid_1's l1: 0.884479\tvalid_1's l2: 1.49457\n",
      "[1193]\ttraining's l1: 0.131389\ttraining's l2: 0.0781747\tvalid_1's l1: 0.884397\tvalid_1's l2: 1.4939\n",
      "[1194]\ttraining's l1: 0.131352\ttraining's l2: 0.0781346\tvalid_1's l1: 0.884234\tvalid_1's l2: 1.49346\n",
      "[1195]\ttraining's l1: 0.1313\ttraining's l2: 0.0780369\tvalid_1's l1: 0.884207\tvalid_1's l2: 1.49351\n",
      "[1196]\ttraining's l1: 0.13128\ttraining's l2: 0.0779545\tvalid_1's l1: 0.8841\tvalid_1's l2: 1.4931\n",
      "[1197]\ttraining's l1: 0.131241\ttraining's l2: 0.0778636\tvalid_1's l1: 0.884274\tvalid_1's l2: 1.4938\n",
      "[1198]\ttraining's l1: 0.131289\ttraining's l2: 0.0777529\tvalid_1's l1: 0.884218\tvalid_1's l2: 1.49409\n",
      "[1199]\ttraining's l1: 0.131126\ttraining's l2: 0.0776292\tvalid_1's l1: 0.88421\tvalid_1's l2: 1.49405\n",
      "[1200]\ttraining's l1: 0.130987\ttraining's l2: 0.0774836\tvalid_1's l1: 0.884311\tvalid_1's l2: 1.49444\n",
      "[1201]\ttraining's l1: 0.130924\ttraining's l2: 0.0774278\tvalid_1's l1: 0.884539\tvalid_1's l2: 1.49518\n",
      "[1202]\ttraining's l1: 0.130884\ttraining's l2: 0.0773923\tvalid_1's l1: 0.884369\tvalid_1's l2: 1.4946\n",
      "[1203]\ttraining's l1: 0.130845\ttraining's l2: 0.0773423\tvalid_1's l1: 0.884677\tvalid_1's l2: 1.4955\n",
      "[1204]\ttraining's l1: 0.130812\ttraining's l2: 0.0772768\tvalid_1's l1: 0.884623\tvalid_1's l2: 1.49539\n",
      "[1205]\ttraining's l1: 0.130751\ttraining's l2: 0.0771449\tvalid_1's l1: 0.884647\tvalid_1's l2: 1.49574\n",
      "[1206]\ttraining's l1: 0.130732\ttraining's l2: 0.0770889\tvalid_1's l1: 0.884491\tvalid_1's l2: 1.49513\n",
      "[1207]\ttraining's l1: 0.130661\ttraining's l2: 0.0770355\tvalid_1's l1: 0.8847\tvalid_1's l2: 1.49586\n",
      "[1208]\ttraining's l1: 0.13055\ttraining's l2: 0.0769866\tvalid_1's l1: 0.884611\tvalid_1's l2: 1.4952\n",
      "[1209]\ttraining's l1: 0.130592\ttraining's l2: 0.0768771\tvalid_1's l1: 0.884552\tvalid_1's l2: 1.49522\n",
      "[1210]\ttraining's l1: 0.130563\ttraining's l2: 0.076771\tvalid_1's l1: 0.884461\tvalid_1's l2: 1.49492\n",
      "[1211]\ttraining's l1: 0.130521\ttraining's l2: 0.0766765\tvalid_1's l1: 0.884436\tvalid_1's l2: 1.49497\n",
      "[1212]\ttraining's l1: 0.130464\ttraining's l2: 0.0765868\tvalid_1's l1: 0.884458\tvalid_1's l2: 1.495\n",
      "[1213]\ttraining's l1: 0.130375\ttraining's l2: 0.0765087\tvalid_1's l1: 0.884734\tvalid_1's l2: 1.49611\n",
      "[1214]\ttraining's l1: 0.130414\ttraining's l2: 0.0764016\tvalid_1's l1: 0.884624\tvalid_1's l2: 1.49606\n",
      "[1215]\ttraining's l1: 0.130259\ttraining's l2: 0.0762815\tvalid_1's l1: 0.88461\tvalid_1's l2: 1.49602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1216]\ttraining's l1: 0.130256\ttraining's l2: 0.0761903\tvalid_1's l1: 0.884612\tvalid_1's l2: 1.4958\n",
      "[1217]\ttraining's l1: 0.130209\ttraining's l2: 0.076101\tvalid_1's l1: 0.884785\tvalid_1's l2: 1.49649\n",
      "[1218]\ttraining's l1: 0.130122\ttraining's l2: 0.0759819\tvalid_1's l1: 0.884704\tvalid_1's l2: 1.49653\n",
      "[1219]\ttraining's l1: 0.1301\ttraining's l2: 0.0758829\tvalid_1's l1: 0.88458\tvalid_1's l2: 1.49635\n",
      "[1220]\ttraining's l1: 0.130067\ttraining's l2: 0.0758196\tvalid_1's l1: 0.884523\tvalid_1's l2: 1.49624\n",
      "[1221]\ttraining's l1: 0.129936\ttraining's l2: 0.0756802\tvalid_1's l1: 0.884622\tvalid_1's l2: 1.49663\n",
      "[1222]\ttraining's l1: 0.129862\ttraining's l2: 0.075558\tvalid_1's l1: 0.884597\tvalid_1's l2: 1.49656\n",
      "[1223]\ttraining's l1: 0.129827\ttraining's l2: 0.0755018\tvalid_1's l1: 0.884813\tvalid_1's l2: 1.49748\n",
      "[1224]\ttraining's l1: 0.129755\ttraining's l2: 0.0754489\tvalid_1's l1: 0.885012\tvalid_1's l2: 1.4982\n",
      "[1225]\ttraining's l1: 0.129653\ttraining's l2: 0.0753893\tvalid_1's l1: 0.884948\tvalid_1's l2: 1.49783\n",
      "[1226]\ttraining's l1: 0.129551\ttraining's l2: 0.0752696\tvalid_1's l1: 0.884894\tvalid_1's l2: 1.49764\n",
      "[1227]\ttraining's l1: 0.12947\ttraining's l2: 0.075163\tvalid_1's l1: 0.88484\tvalid_1's l2: 1.4975\n",
      "[1228]\ttraining's l1: 0.1294\ttraining's l2: 0.0751108\tvalid_1's l1: 0.885042\tvalid_1's l2: 1.49822\n",
      "[1229]\ttraining's l1: 0.129298\ttraining's l2: 0.0750523\tvalid_1's l1: 0.884987\tvalid_1's l2: 1.49785\n",
      "[1230]\ttraining's l1: 0.129232\ttraining's l2: 0.0749352\tvalid_1's l1: 0.884967\tvalid_1's l2: 1.49779\n",
      "[1231]\ttraining's l1: 0.129166\ttraining's l2: 0.0748823\tvalid_1's l1: 0.885197\tvalid_1's l2: 1.49851\n",
      "[1232]\ttraining's l1: 0.129064\ttraining's l2: 0.0748245\tvalid_1's l1: 0.885142\tvalid_1's l2: 1.49814\n",
      "[1233]\ttraining's l1: 0.128968\ttraining's l2: 0.0747889\tvalid_1's l1: 0.885072\tvalid_1's l2: 1.49757\n",
      "[1234]\ttraining's l1: 0.128863\ttraining's l2: 0.0747418\tvalid_1's l1: 0.884983\tvalid_1's l2: 1.49692\n",
      "[1235]\ttraining's l1: 0.128827\ttraining's l2: 0.0746724\tvalid_1's l1: 0.884736\tvalid_1's l2: 1.49606\n",
      "[1236]\ttraining's l1: 0.128758\ttraining's l2: 0.0746206\tvalid_1's l1: 0.884943\tvalid_1's l2: 1.49679\n",
      "[1237]\ttraining's l1: 0.128661\ttraining's l2: 0.0745642\tvalid_1's l1: 0.88489\tvalid_1's l2: 1.49643\n",
      "[1238]\ttraining's l1: 0.128584\ttraining's l2: 0.0744497\tvalid_1's l1: 0.884836\tvalid_1's l2: 1.49625\n",
      "[1239]\ttraining's l1: 0.128564\ttraining's l2: 0.0744039\tvalid_1's l1: 0.884983\tvalid_1's l2: 1.4969\n",
      "[1240]\ttraining's l1: 0.128461\ttraining's l2: 0.0743691\tvalid_1's l1: 0.884917\tvalid_1's l2: 1.49634\n",
      "[1241]\ttraining's l1: 0.128432\ttraining's l2: 0.0743008\tvalid_1's l1: 0.884671\tvalid_1's l2: 1.49549\n",
      "[1242]\ttraining's l1: 0.128405\ttraining's l2: 0.0742095\tvalid_1's l1: 0.884669\tvalid_1's l2: 1.49556\n",
      "[1243]\ttraining's l1: 0.128439\ttraining's l2: 0.074105\tvalid_1's l1: 0.884613\tvalid_1's l2: 1.49559\n",
      "[1244]\ttraining's l1: 0.128347\ttraining's l2: 0.0740262\tvalid_1's l1: 0.884927\tvalid_1's l2: 1.49672\n",
      "[1245]\ttraining's l1: 0.128323\ttraining's l2: 0.0739806\tvalid_1's l1: 0.885073\tvalid_1's l2: 1.49737\n",
      "[1246]\ttraining's l1: 0.128224\ttraining's l2: 0.0739464\tvalid_1's l1: 0.885006\tvalid_1's l2: 1.49681\n",
      "[1247]\ttraining's l1: 0.128185\ttraining's l2: 0.0738922\tvalid_1's l1: 0.88522\tvalid_1's l2: 1.49772\n",
      "[1248]\ttraining's l1: 0.128098\ttraining's l2: 0.0738365\tvalid_1's l1: 0.885181\tvalid_1's l2: 1.49737\n",
      "[1249]\ttraining's l1: 0.128031\ttraining's l2: 0.0737245\tvalid_1's l1: 0.885128\tvalid_1's l2: 1.49719\n",
      "[1250]\ttraining's l1: 0.12792\ttraining's l2: 0.0735923\tvalid_1's l1: 0.885227\tvalid_1's l2: 1.49757\n",
      "[1251]\ttraining's l1: 0.127907\ttraining's l2: 0.0735031\tvalid_1's l1: 0.885219\tvalid_1's l2: 1.49764\n",
      "[1252]\ttraining's l1: 0.127798\ttraining's l2: 0.073469\tvalid_1's l1: 0.88515\tvalid_1's l2: 1.49708\n",
      "[1253]\ttraining's l1: 0.127741\ttraining's l2: 0.0733841\tvalid_1's l1: 0.885169\tvalid_1's l2: 1.49711\n",
      "[1254]\ttraining's l1: 0.127685\ttraining's l2: 0.0732745\tvalid_1's l1: 0.885116\tvalid_1's l2: 1.49693\n",
      "[1255]\ttraining's l1: 0.12772\ttraining's l2: 0.0731715\tvalid_1's l1: 0.885062\tvalid_1's l2: 1.49722\n",
      "[1256]\ttraining's l1: 0.127661\ttraining's l2: 0.0731217\tvalid_1's l1: 0.885268\tvalid_1's l2: 1.49794\n",
      "[1257]\ttraining's l1: 0.127584\ttraining's l2: 0.0730665\tvalid_1's l1: 0.88523\tvalid_1's l2: 1.4976\n",
      "[1258]\ttraining's l1: 0.127574\ttraining's l2: 0.0730221\tvalid_1's l1: 0.885374\tvalid_1's l2: 1.49824\n",
      "[1259]\ttraining's l1: 0.127569\ttraining's l2: 0.0729349\tvalid_1's l1: 0.885367\tvalid_1's l2: 1.49831\n",
      "[1260]\ttraining's l1: 0.127501\ttraining's l2: 0.0728576\tvalid_1's l1: 0.885586\tvalid_1's l2: 1.49907\n",
      "[1261]\ttraining's l1: 0.127446\ttraining's l2: 0.0727746\tvalid_1's l1: 0.885606\tvalid_1's l2: 1.49911\n",
      "[1262]\ttraining's l1: 0.127394\ttraining's l2: 0.0726899\tvalid_1's l1: 0.885765\tvalid_1's l2: 1.49979\n",
      "[1263]\ttraining's l1: 0.127343\ttraining's l2: 0.0725828\tvalid_1's l1: 0.885713\tvalid_1's l2: 1.49961\n",
      "[1264]\ttraining's l1: 0.127215\ttraining's l2: 0.0724685\tvalid_1's l1: 0.885654\tvalid_1's l2: 1.49955\n",
      "[1265]\ttraining's l1: 0.127219\ttraining's l2: 0.0723671\tvalid_1's l1: 0.885596\tvalid_1's l2: 1.49957\n",
      "[1266]\ttraining's l1: 0.127146\ttraining's l2: 0.0723126\tvalid_1's l1: 0.885558\tvalid_1's l2: 1.49923\n",
      "[1267]\ttraining's l1: 0.127098\ttraining's l2: 0.0722638\tvalid_1's l1: 0.885759\tvalid_1's l2: 1.49994\n",
      "[1268]\ttraining's l1: 0.127026\ttraining's l2: 0.0722101\tvalid_1's l1: 0.88572\tvalid_1's l2: 1.49959\n",
      "[1269]\ttraining's l1: 0.126975\ttraining's l2: 0.0721051\tvalid_1's l1: 0.885668\tvalid_1's l2: 1.49942\n",
      "[1270]\ttraining's l1: 0.126847\ttraining's l2: 0.0719772\tvalid_1's l1: 0.885636\tvalid_1's l2: 1.49942\n",
      "[1271]\ttraining's l1: 0.126826\ttraining's l2: 0.0718743\tvalid_1's l1: 0.885617\tvalid_1's l2: 1.49937\n",
      "[1272]\ttraining's l1: 0.126754\ttraining's l2: 0.0717757\tvalid_1's l1: 0.885561\tvalid_1's l2: 1.49924\n",
      "[1273]\ttraining's l1: 0.126731\ttraining's l2: 0.0717323\tvalid_1's l1: 0.885663\tvalid_1's l2: 1.49988\n",
      "[1274]\ttraining's l1: 0.126619\ttraining's l2: 0.0716984\tvalid_1's l1: 0.8856\tvalid_1's l2: 1.49932\n",
      "[1275]\ttraining's l1: 0.126615\ttraining's l2: 0.0715955\tvalid_1's l1: 0.885743\tvalid_1's l2: 1.49998\n",
      "[1276]\ttraining's l1: 0.126542\ttraining's l2: 0.0715427\tvalid_1's l1: 0.885706\tvalid_1's l2: 1.49964\n",
      "[1277]\ttraining's l1: 0.126469\ttraining's l2: 0.0714408\tvalid_1's l1: 0.885589\tvalid_1's l2: 1.49931\n",
      "[1278]\ttraining's l1: 0.126464\ttraining's l2: 0.0713562\tvalid_1's l1: 0.885582\tvalid_1's l2: 1.49938\n",
      "[1279]\ttraining's l1: 0.126396\ttraining's l2: 0.0713106\tvalid_1's l1: 0.885706\tvalid_1's l2: 1.5001\n",
      "[1280]\ttraining's l1: 0.126351\ttraining's l2: 0.0712372\tvalid_1's l1: 0.885901\tvalid_1's l2: 1.50083\n",
      "[1281]\ttraining's l1: 0.126242\ttraining's l2: 0.0712038\tvalid_1's l1: 0.885838\tvalid_1's l2: 1.50028\n",
      "[1282]\ttraining's l1: 0.126136\ttraining's l2: 0.0711289\tvalid_1's l1: 0.886143\tvalid_1's l2: 1.50137\n",
      "[1283]\ttraining's l1: 0.126027\ttraining's l2: 0.0710961\tvalid_1's l1: 0.886078\tvalid_1's l2: 1.50082\n",
      "[1284]\ttraining's l1: 0.12591\ttraining's l2: 0.0709845\tvalid_1's l1: 0.886019\tvalid_1's l2: 1.50075\n",
      "[1285]\ttraining's l1: 0.125843\ttraining's l2: 0.0709322\tvalid_1's l1: 0.88598\tvalid_1's l2: 1.50041\n",
      "[1286]\ttraining's l1: 0.125751\ttraining's l2: 0.0708881\tvalid_1's l1: 0.88589\tvalid_1's l2: 1.4998\n",
      "[1287]\ttraining's l1: 0.125734\ttraining's l2: 0.0708091\tvalid_1's l1: 0.885836\tvalid_1's l2: 1.49967\n",
      "[1288]\ttraining's l1: 0.125716\ttraining's l2: 0.0707577\tvalid_1's l1: 0.886047\tvalid_1's l2: 1.50056\n",
      "[1289]\ttraining's l1: 0.125711\ttraining's l2: 0.0706747\tvalid_1's l1: 0.88604\tvalid_1's l2: 1.50064\n",
      "[1290]\ttraining's l1: 0.12564\ttraining's l2: 0.0706001\tvalid_1's l1: 0.886257\tvalid_1's l2: 1.50139\n",
      "[1291]\ttraining's l1: 0.125644\ttraining's l2: 0.070502\tvalid_1's l1: 0.886202\tvalid_1's l2: 1.50142\n",
      "[1292]\ttraining's l1: 0.125537\ttraining's l2: 0.0704286\tvalid_1's l1: 0.886503\tvalid_1's l2: 1.5025\n",
      "[1293]\ttraining's l1: 0.125536\ttraining's l2: 0.0703336\tvalid_1's l1: 0.88642\tvalid_1's l2: 1.50222\n",
      "[1294]\ttraining's l1: 0.125491\ttraining's l2: 0.0702327\tvalid_1's l1: 0.886455\tvalid_1's l2: 1.50236\n",
      "[1295]\ttraining's l1: 0.125377\ttraining's l2: 0.070143\tvalid_1's l1: 0.886407\tvalid_1's l2: 1.50218\n",
      "[1296]\ttraining's l1: 0.125369\ttraining's l2: 0.0700617\tvalid_1's l1: 0.886401\tvalid_1's l2: 1.50225\n",
      "[1297]\ttraining's l1: 0.12532\ttraining's l2: 0.0699824\tvalid_1's l1: 0.88642\tvalid_1's l2: 1.50229\n",
      "[1298]\ttraining's l1: 0.125262\ttraining's l2: 0.0698984\tvalid_1's l1: 0.886582\tvalid_1's l2: 1.50297\n",
      "[1299]\ttraining's l1: 0.12517\ttraining's l2: 0.0697901\tvalid_1's l1: 0.886525\tvalid_1's l2: 1.5029\n",
      "[1300]\ttraining's l1: 0.125154\ttraining's l2: 0.0697401\tvalid_1's l1: 0.886732\tvalid_1's l2: 1.50378\n",
      "[1301]\ttraining's l1: 0.125053\ttraining's l2: 0.0696536\tvalid_1's l1: 0.886575\tvalid_1's l2: 1.50354\n",
      "[1302]\ttraining's l1: 0.125069\ttraining's l2: 0.0695573\tvalid_1's l1: 0.886522\tvalid_1's l2: 1.50382\n",
      "[1303]\ttraining's l1: 0.125021\ttraining's l2: 0.0695111\tvalid_1's l1: 0.886721\tvalid_1's l2: 1.50451\n",
      "[1304]\ttraining's l1: 0.124955\ttraining's l2: 0.0694601\tvalid_1's l1: 0.886681\tvalid_1's l2: 1.50417\n",
      "[1305]\ttraining's l1: 0.124928\ttraining's l2: 0.0693836\tvalid_1's l1: 0.886626\tvalid_1's l2: 1.50404\n",
      "[1306]\ttraining's l1: 0.124917\ttraining's l2: 0.0693345\tvalid_1's l1: 0.886832\tvalid_1's l2: 1.50491\n",
      "[1307]\ttraining's l1: 0.124881\ttraining's l2: 0.0692421\tvalid_1's l1: 0.886788\tvalid_1's l2: 1.50499\n",
      "[1308]\ttraining's l1: 0.124832\ttraining's l2: 0.0691721\tvalid_1's l1: 0.886974\tvalid_1's l2: 1.50569\n",
      "[1309]\ttraining's l1: 0.124747\ttraining's l2: 0.0691284\tvalid_1's l1: 0.886884\tvalid_1's l2: 1.50507\n",
      "[1310]\ttraining's l1: 0.124677\ttraining's l2: 0.0690779\tvalid_1's l1: 0.886844\tvalid_1's l2: 1.50473\n",
      "[1311]\ttraining's l1: 0.124593\ttraining's l2: 0.069035\tvalid_1's l1: 0.886755\tvalid_1's l2: 1.50412\n",
      "[1312]\ttraining's l1: 0.124524\ttraining's l2: 0.0689855\tvalid_1's l1: 0.886716\tvalid_1's l2: 1.50379\n",
      "[1313]\ttraining's l1: 0.124507\ttraining's l2: 0.0689108\tvalid_1's l1: 0.886663\tvalid_1's l2: 1.50366\n",
      "[1314]\ttraining's l1: 0.124414\ttraining's l2: 0.0688184\tvalid_1's l1: 0.886473\tvalid_1's l2: 1.50311\n",
      "[1315]\ttraining's l1: 0.12439\ttraining's l2: 0.0687187\tvalid_1's l1: 0.886388\tvalid_1's l2: 1.50311\n",
      "[1316]\ttraining's l1: 0.124381\ttraining's l2: 0.0686697\tvalid_1's l1: 0.886596\tvalid_1's l2: 1.504\n",
      "[1317]\ttraining's l1: 0.124314\ttraining's l2: 0.0686258\tvalid_1's l1: 0.886703\tvalid_1's l2: 1.50468\n",
      "[1318]\ttraining's l1: 0.124221\ttraining's l2: 0.06859\tvalid_1's l1: 0.886678\tvalid_1's l2: 1.50413\n",
      "[1319]\ttraining's l1: 0.124147\ttraining's l2: 0.0684831\tvalid_1's l1: 0.886772\tvalid_1's l2: 1.5045\n",
      "[1320]\ttraining's l1: 0.124099\ttraining's l2: 0.0684135\tvalid_1's l1: 0.88696\tvalid_1's l2: 1.50521\n",
      "[1321]\ttraining's l1: 0.124084\ttraining's l2: 0.0683153\tvalid_1's l1: 0.887097\tvalid_1's l2: 1.5056\n",
      "[1322]\ttraining's l1: 0.123975\ttraining's l2: 0.0682435\tvalid_1's l1: 0.887393\tvalid_1's l2: 1.50667\n",
      "[1323]\ttraining's l1: 0.123932\ttraining's l2: 0.0681461\tvalid_1's l1: 0.887428\tvalid_1's l2: 1.50681\n",
      "[1324]\ttraining's l1: 0.123863\ttraining's l2: 0.0680972\tvalid_1's l1: 0.887388\tvalid_1's l2: 1.50648\n",
      "[1325]\ttraining's l1: 0.123815\ttraining's l2: 0.0680526\tvalid_1's l1: 0.887573\tvalid_1's l2: 1.50717\n",
      "[1326]\ttraining's l1: 0.123731\ttraining's l2: 0.0680104\tvalid_1's l1: 0.887485\tvalid_1's l2: 1.50656\n",
      "[1327]\ttraining's l1: 0.123725\ttraining's l2: 0.0679748\tvalid_1's l1: 0.887336\tvalid_1's l2: 1.50608\n",
      "[1328]\ttraining's l1: 0.123677\ttraining's l2: 0.067907\tvalid_1's l1: 0.887521\tvalid_1's l2: 1.50678\n",
      "[1329]\ttraining's l1: 0.123668\ttraining's l2: 0.0678585\tvalid_1's l1: 0.887726\tvalid_1's l2: 1.50766\n",
      "[1330]\ttraining's l1: 0.123625\ttraining's l2: 0.0677766\tvalid_1's l1: 0.887675\tvalid_1's l2: 1.50761\n",
      "[1331]\ttraining's l1: 0.123574\ttraining's l2: 0.0677012\tvalid_1's l1: 0.887731\tvalid_1's l2: 1.50774\n",
      "[1332]\ttraining's l1: 0.123549\ttraining's l2: 0.0676139\tvalid_1's l1: 0.887678\tvalid_1's l2: 1.50779\n",
      "[1333]\ttraining's l1: 0.123522\ttraining's l2: 0.0675337\tvalid_1's l1: 0.887671\tvalid_1's l2: 1.50758\n",
      "[1334]\ttraining's l1: 0.123485\ttraining's l2: 0.0674391\tvalid_1's l1: 0.887707\tvalid_1's l2: 1.50772\n",
      "[1335]\ttraining's l1: 0.123512\ttraining's l2: 0.0673423\tvalid_1's l1: 0.887575\tvalid_1's l2: 1.50761\n",
      "[1336]\ttraining's l1: 0.123441\ttraining's l2: 0.067275\tvalid_1's l1: 0.887843\tvalid_1's l2: 1.50865\n",
      "[1337]\ttraining's l1: 0.123447\ttraining's l2: 0.0671795\tvalid_1's l1: 0.887981\tvalid_1's l2: 1.50929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338]\ttraining's l1: 0.123349\ttraining's l2: 0.0670952\tvalid_1's l1: 0.887934\tvalid_1's l2: 1.50912\n",
      "[1339]\ttraining's l1: 0.123307\ttraining's l2: 0.0670025\tvalid_1's l1: 0.887986\tvalid_1's l2: 1.50929\n",
      "[1340]\ttraining's l1: 0.123212\ttraining's l2: 0.0669\tvalid_1's l1: 0.887931\tvalid_1's l2: 1.50922\n",
      "[1341]\ttraining's l1: 0.123203\ttraining's l2: 0.0668527\tvalid_1's l1: 0.888133\tvalid_1's l2: 1.51009\n",
      "[1342]\ttraining's l1: 0.123162\ttraining's l2: 0.0668092\tvalid_1's l1: 0.888323\tvalid_1's l2: 1.51076\n",
      "[1343]\ttraining's l1: 0.123085\ttraining's l2: 0.0667601\tvalid_1's l1: 0.888283\tvalid_1's l2: 1.51043\n",
      "[1344]\ttraining's l1: 0.122988\ttraining's l2: 0.0666699\tvalid_1's l1: 0.888092\tvalid_1's l2: 1.50987\n",
      "[1345]\ttraining's l1: 0.122913\ttraining's l2: 0.0666245\tvalid_1's l1: 0.888301\tvalid_1's l2: 1.51066\n",
      "[1346]\ttraining's l1: 0.122869\ttraining's l2: 0.0665455\tvalid_1's l1: 0.888251\tvalid_1's l2: 1.51061\n",
      "[1347]\ttraining's l1: 0.122839\ttraining's l2: 0.066467\tvalid_1's l1: 0.888245\tvalid_1's l2: 1.5104\n",
      "[1348]\ttraining's l1: 0.122754\ttraining's l2: 0.0664202\tvalid_1's l1: 0.888429\tvalid_1's l2: 1.51113\n",
      "[1349]\ttraining's l1: 0.12272\ttraining's l2: 0.0662912\tvalid_1's l1: 0.888494\tvalid_1's l2: 1.5115\n",
      "[1350]\ttraining's l1: 0.122667\ttraining's l2: 0.0662096\tvalid_1's l1: 0.888656\tvalid_1's l2: 1.51218\n",
      "[1351]\ttraining's l1: 0.122597\ttraining's l2: 0.0661616\tvalid_1's l1: 0.888616\tvalid_1's l2: 1.51185\n",
      "[1352]\ttraining's l1: 0.122554\ttraining's l2: 0.0661186\tvalid_1's l1: 0.888806\tvalid_1's l2: 1.51251\n",
      "[1353]\ttraining's l1: 0.122476\ttraining's l2: 0.0660707\tvalid_1's l1: 0.888767\tvalid_1's l2: 1.51218\n",
      "[1354]\ttraining's l1: 0.122379\ttraining's l2: 0.0659826\tvalid_1's l1: 0.888578\tvalid_1's l2: 1.51163\n",
      "[1355]\ttraining's l1: 0.122293\ttraining's l2: 0.0659362\tvalid_1's l1: 0.888761\tvalid_1's l2: 1.51237\n",
      "[1356]\ttraining's l1: 0.12227\ttraining's l2: 0.0658419\tvalid_1's l1: 0.888676\tvalid_1's l2: 1.51237\n",
      "[1357]\ttraining's l1: 0.122184\ttraining's l2: 0.0658007\tvalid_1's l1: 0.888588\tvalid_1's l2: 1.51175\n",
      "[1358]\ttraining's l1: 0.122116\ttraining's l2: 0.0657541\tvalid_1's l1: 0.888548\tvalid_1's l2: 1.51143\n",
      "[1359]\ttraining's l1: 0.12208\ttraining's l2: 0.0656693\tvalid_1's l1: 0.888503\tvalid_1's l2: 1.51149\n",
      "[1360]\ttraining's l1: 0.122033\ttraining's l2: 0.0655973\tvalid_1's l1: 0.888557\tvalid_1's l2: 1.51163\n",
      "[1361]\ttraining's l1: 0.12197\ttraining's l2: 0.0655056\tvalid_1's l1: 0.888431\tvalid_1's l2: 1.51143\n",
      "[1362]\ttraining's l1: 0.121901\ttraining's l2: 0.0654595\tvalid_1's l1: 0.888393\tvalid_1's l2: 1.51111\n",
      "[1363]\ttraining's l1: 0.121888\ttraining's l2: 0.065389\tvalid_1's l1: 0.888342\tvalid_1's l2: 1.51099\n",
      "[1364]\ttraining's l1: 0.121832\ttraining's l2: 0.0652996\tvalid_1's l1: 0.888375\tvalid_1's l2: 1.5111\n",
      "[1365]\ttraining's l1: 0.121784\ttraining's l2: 0.0652482\tvalid_1's l1: 0.888647\tvalid_1's l2: 1.512\n",
      "[1366]\ttraining's l1: 0.121766\ttraining's l2: 0.0651584\tvalid_1's l1: 0.888563\tvalid_1's l2: 1.51201\n",
      "[1367]\ttraining's l1: 0.121722\ttraining's l2: 0.0650926\tvalid_1's l1: 0.88874\tvalid_1's l2: 1.5127\n",
      "[1368]\ttraining's l1: 0.121729\ttraining's l2: 0.0650006\tvalid_1's l1: 0.888874\tvalid_1's l2: 1.51332\n",
      "[1369]\ttraining's l1: 0.12166\ttraining's l2: 0.0649551\tvalid_1's l1: 0.888834\tvalid_1's l2: 1.513\n",
      "[1370]\ttraining's l1: 0.121614\ttraining's l2: 0.0649131\tvalid_1's l1: 0.889012\tvalid_1's l2: 1.51368\n",
      "[1371]\ttraining's l1: 0.121546\ttraining's l2: 0.0648681\tvalid_1's l1: 0.888969\tvalid_1's l2: 1.51336\n",
      "[1372]\ttraining's l1: 0.121499\ttraining's l2: 0.0648278\tvalid_1's l1: 0.889149\tvalid_1's l2: 1.51402\n",
      "[1373]\ttraining's l1: 0.121415\ttraining's l2: 0.0647876\tvalid_1's l1: 0.889065\tvalid_1's l2: 1.51342\n",
      "[1374]\ttraining's l1: 0.121408\ttraining's l2: 0.0647538\tvalid_1's l1: 0.88892\tvalid_1's l2: 1.51295\n",
      "[1375]\ttraining's l1: 0.12136\ttraining's l2: 0.064683\tvalid_1's l1: 0.888936\tvalid_1's l2: 1.51301\n",
      "[1376]\ttraining's l1: 0.121312\ttraining's l2: 0.064606\tvalid_1's l1: 0.888762\tvalid_1's l2: 1.51272\n",
      "[1377]\ttraining's l1: 0.121269\ttraining's l2: 0.0645408\tvalid_1's l1: 0.88894\tvalid_1's l2: 1.51341\n",
      "[1378]\ttraining's l1: 0.121222\ttraining's l2: 0.0644904\tvalid_1's l1: 0.889209\tvalid_1's l2: 1.5143\n",
      "[1379]\ttraining's l1: 0.121156\ttraining's l2: 0.0644469\tvalid_1's l1: 0.889414\tvalid_1's l2: 1.51509\n",
      "[1380]\ttraining's l1: 0.121074\ttraining's l2: 0.0643824\tvalid_1's l1: 0.889709\tvalid_1's l2: 1.51613\n",
      "[1381]\ttraining's l1: 0.121006\ttraining's l2: 0.0643374\tvalid_1's l1: 0.889667\tvalid_1's l2: 1.51581\n",
      "[1382]\ttraining's l1: 0.120931\ttraining's l2: 0.0642398\tvalid_1's l1: 0.889757\tvalid_1's l2: 1.51616\n",
      "[1383]\ttraining's l1: 0.120848\ttraining's l2: 0.0642003\tvalid_1's l1: 0.889672\tvalid_1's l2: 1.51556\n",
      "[1384]\ttraining's l1: 0.120835\ttraining's l2: 0.0641323\tvalid_1's l1: 0.889625\tvalid_1's l2: 1.51544\n",
      "[1385]\ttraining's l1: 0.1208\ttraining's l2: 0.0640088\tvalid_1's l1: 0.88969\tvalid_1's l2: 1.51581\n",
      "[1386]\ttraining's l1: 0.120744\ttraining's l2: 0.063934\tvalid_1's l1: 0.889514\tvalid_1's l2: 1.51552\n",
      "[1387]\ttraining's l1: 0.120697\ttraining's l2: 0.0638846\tvalid_1's l1: 0.889779\tvalid_1's l2: 1.5164\n",
      "[1388]\ttraining's l1: 0.120651\ttraining's l2: 0.0638438\tvalid_1's l1: 0.889944\tvalid_1's l2: 1.51706\n",
      "[1389]\ttraining's l1: 0.120583\ttraining's l2: 0.0637996\tvalid_1's l1: 0.889901\tvalid_1's l2: 1.51674\n",
      "[1390]\ttraining's l1: 0.120565\ttraining's l2: 0.0637114\tvalid_1's l1: 0.889818\tvalid_1's l2: 1.51675\n",
      "[1391]\ttraining's l1: 0.120522\ttraining's l2: 0.063648\tvalid_1's l1: 0.889994\tvalid_1's l2: 1.51742\n",
      "[1392]\ttraining's l1: 0.120447\ttraining's l2: 0.0636037\tvalid_1's l1: 0.889957\tvalid_1's l2: 1.51711\n",
      "[1393]\ttraining's l1: 0.120402\ttraining's l2: 0.0635634\tvalid_1's l1: 0.89013\tvalid_1's l2: 1.51777\n",
      "[1394]\ttraining's l1: 0.120317\ttraining's l2: 0.0635243\tvalid_1's l1: 0.89005\tvalid_1's l2: 1.51716\n",
      "[1395]\ttraining's l1: 0.12025\ttraining's l2: 0.0634811\tvalid_1's l1: 0.890006\tvalid_1's l2: 1.51686\n",
      "[1396]\ttraining's l1: 0.120169\ttraining's l2: 0.0634427\tvalid_1's l1: 0.889924\tvalid_1's l2: 1.51626\n",
      "[1397]\ttraining's l1: 0.120113\ttraining's l2: 0.0633689\tvalid_1's l1: 0.889742\tvalid_1's l2: 1.51598\n",
      "[1398]\ttraining's l1: 0.120106\ttraining's l2: 0.0633366\tvalid_1's l1: 0.889606\tvalid_1's l2: 1.51552\n",
      "[1399]\ttraining's l1: 0.120075\ttraining's l2: 0.0632562\tvalid_1's l1: 0.889568\tvalid_1's l2: 1.51559\n",
      "[1400]\ttraining's l1: 0.12002\ttraining's l2: 0.063192\tvalid_1's l1: 0.889783\tvalid_1's l2: 1.51631\n",
      "[1401]\ttraining's l1: 0.119953\ttraining's l2: 0.0631494\tvalid_1's l1: 0.889733\tvalid_1's l2: 1.51601\n",
      "[1402]\ttraining's l1: 0.11988\ttraining's l2: 0.0630985\tvalid_1's l1: 0.889788\tvalid_1's l2: 1.51655\n",
      "[1403]\ttraining's l1: 0.119825\ttraining's l2: 0.063026\tvalid_1's l1: 0.889608\tvalid_1's l2: 1.51627\n",
      "[1404]\ttraining's l1: 0.119779\ttraining's l2: 0.0629772\tvalid_1's l1: 0.889873\tvalid_1's l2: 1.51715\n",
      "[1405]\ttraining's l1: 0.119734\ttraining's l2: 0.0629371\tvalid_1's l1: 0.890046\tvalid_1's l2: 1.51781\n",
      "[1406]\ttraining's l1: 0.119728\ttraining's l2: 0.0629048\tvalid_1's l1: 0.889905\tvalid_1's l2: 1.51735\n",
      "[1407]\ttraining's l1: 0.119673\ttraining's l2: 0.0628419\tvalid_1's l1: 0.890118\tvalid_1's l2: 1.51806\n",
      "[1408]\ttraining's l1: 0.119646\ttraining's l2: 0.0627225\tvalid_1's l1: 0.89014\tvalid_1's l2: 1.5184\n",
      "[1409]\ttraining's l1: 0.119582\ttraining's l2: 0.0626802\tvalid_1's l1: 0.890103\tvalid_1's l2: 1.51809\n",
      "[1410]\ttraining's l1: 0.119535\ttraining's l2: 0.0626418\tvalid_1's l1: 0.890277\tvalid_1's l2: 1.51874\n",
      "[1411]\ttraining's l1: 0.119489\ttraining's l2: 0.0625796\tvalid_1's l1: 0.890098\tvalid_1's l2: 1.51826\n",
      "[1412]\ttraining's l1: 0.119443\ttraining's l2: 0.06254\tvalid_1's l1: 0.89027\tvalid_1's l2: 1.51891\n",
      "[1413]\ttraining's l1: 0.119369\ttraining's l2: 0.0624978\tvalid_1's l1: 0.890235\tvalid_1's l2: 1.51861\n",
      "[1414]\ttraining's l1: 0.119269\ttraining's l2: 0.062465\tvalid_1's l1: 0.890184\tvalid_1's l2: 1.51809\n",
      "[1415]\ttraining's l1: 0.11923\ttraining's l2: 0.0623856\tvalid_1's l1: 0.890141\tvalid_1's l2: 1.51816\n",
      "[1416]\ttraining's l1: 0.119176\ttraining's l2: 0.0623146\tvalid_1's l1: 0.889964\tvalid_1's l2: 1.51788\n",
      "[1417]\ttraining's l1: 0.119126\ttraining's l2: 0.0622466\tvalid_1's l1: 0.890074\tvalid_1's l2: 1.51806\n",
      "[1418]\ttraining's l1: 0.119082\ttraining's l2: 0.062207\tvalid_1's l1: 0.890247\tvalid_1's l2: 1.51872\n",
      "[1419]\ttraining's l1: 0.118988\ttraining's l2: 0.0621748\tvalid_1's l1: 0.890197\tvalid_1's l2: 1.51821\n",
      "[1420]\ttraining's l1: 0.11892\ttraining's l2: 0.0621339\tvalid_1's l1: 0.890162\tvalid_1's l2: 1.51791\n",
      "[1421]\ttraining's l1: 0.11891\ttraining's l2: 0.0620489\tvalid_1's l1: 0.890082\tvalid_1's l2: 1.51792\n",
      "[1422]\ttraining's l1: 0.118871\ttraining's l2: 0.061986\tvalid_1's l1: 0.890312\tvalid_1's l2: 1.51865\n",
      "[1423]\ttraining's l1: 0.11886\ttraining's l2: 0.0619537\tvalid_1's l1: 0.890179\tvalid_1's l2: 1.5182\n",
      "[1424]\ttraining's l1: 0.118863\ttraining's l2: 0.0618823\tvalid_1's l1: 0.890162\tvalid_1's l2: 1.5182\n",
      "[1425]\ttraining's l1: 0.118815\ttraining's l2: 0.0618132\tvalid_1's l1: 0.889995\tvalid_1's l2: 1.51793\n",
      "[1426]\ttraining's l1: 0.118766\ttraining's l2: 0.0617649\tvalid_1's l1: 0.890258\tvalid_1's l2: 1.51881\n",
      "[1427]\ttraining's l1: 0.118719\ttraining's l2: 0.0617027\tvalid_1's l1: 0.890484\tvalid_1's l2: 1.51952\n",
      "[1428]\ttraining's l1: 0.118652\ttraining's l2: 0.0616621\tvalid_1's l1: 0.890441\tvalid_1's l2: 1.51922\n",
      "[1429]\ttraining's l1: 0.118612\ttraining's l2: 0.0616227\tvalid_1's l1: 0.890608\tvalid_1's l2: 1.51988\n",
      "[1430]\ttraining's l1: 0.118568\ttraining's l2: 0.0615568\tvalid_1's l1: 0.890629\tvalid_1's l2: 1.51994\n",
      "[1431]\ttraining's l1: 0.118547\ttraining's l2: 0.0614678\tvalid_1's l1: 0.890674\tvalid_1's l2: 1.51993\n",
      "[1432]\ttraining's l1: 0.118497\ttraining's l2: 0.0614255\tvalid_1's l1: 0.890933\tvalid_1's l2: 1.52076\n",
      "[1433]\ttraining's l1: 0.11846\ttraining's l2: 0.0613645\tvalid_1's l1: 0.891158\tvalid_1's l2: 1.52148\n",
      "[1434]\ttraining's l1: 0.118392\ttraining's l2: 0.0613239\tvalid_1's l1: 0.891116\tvalid_1's l2: 1.52117\n",
      "[1435]\ttraining's l1: 0.118345\ttraining's l2: 0.0612499\tvalid_1's l1: 0.891279\tvalid_1's l2: 1.52184\n",
      "[1436]\ttraining's l1: 0.118305\ttraining's l2: 0.0612126\tvalid_1's l1: 0.891446\tvalid_1's l2: 1.52248\n",
      "[1437]\ttraining's l1: 0.118299\ttraining's l2: 0.0611806\tvalid_1's l1: 0.891317\tvalid_1's l2: 1.52203\n",
      "[1438]\ttraining's l1: 0.118254\ttraining's l2: 0.0611082\tvalid_1's l1: 0.891481\tvalid_1's l2: 1.52269\n",
      "[1439]\ttraining's l1: 0.118188\ttraining's l2: 0.0610682\tvalid_1's l1: 0.891437\tvalid_1's l2: 1.52239\n",
      "[1440]\ttraining's l1: 0.118091\ttraining's l2: 0.0609883\tvalid_1's l1: 0.891264\tvalid_1's l2: 1.52186\n",
      "[1441]\ttraining's l1: 0.118035\ttraining's l2: 0.0609498\tvalid_1's l1: 0.891356\tvalid_1's l2: 1.5225\n",
      "[1442]\ttraining's l1: 0.118021\ttraining's l2: 0.0608651\tvalid_1's l1: 0.891273\tvalid_1's l2: 1.52251\n",
      "[1443]\ttraining's l1: 0.11792\ttraining's l2: 0.0608334\tvalid_1's l1: 0.891234\tvalid_1's l2: 1.52199\n",
      "[1444]\ttraining's l1: 0.117889\ttraining's l2: 0.0607689\tvalid_1's l1: 0.891333\tvalid_1's l2: 1.52211\n",
      "[1445]\ttraining's l1: 0.117842\ttraining's l2: 0.0606883\tvalid_1's l1: 0.891383\tvalid_1's l2: 1.52223\n",
      "[1446]\ttraining's l1: 0.117822\ttraining's l2: 0.0606042\tvalid_1's l1: 0.891205\tvalid_1's l2: 1.52194\n",
      "[1447]\ttraining's l1: 0.117767\ttraining's l2: 0.0605378\tvalid_1's l1: 0.891191\tvalid_1's l2: 1.52172\n",
      "[1448]\ttraining's l1: 0.117719\ttraining's l2: 0.0604913\tvalid_1's l1: 0.891448\tvalid_1's l2: 1.52258\n",
      "[1449]\ttraining's l1: 0.117678\ttraining's l2: 0.0604543\tvalid_1's l1: 0.891608\tvalid_1's l2: 1.52321\n",
      "[1450]\ttraining's l1: 0.11765\ttraining's l2: 0.0603911\tvalid_1's l1: 0.891706\tvalid_1's l2: 1.52333\n",
      "[1451]\ttraining's l1: 0.117596\ttraining's l2: 0.0603002\tvalid_1's l1: 0.891778\tvalid_1's l2: 1.52367\n",
      "[1452]\ttraining's l1: 0.117549\ttraining's l2: 0.0602403\tvalid_1's l1: 0.891984\tvalid_1's l2: 1.52436\n",
      "[1453]\ttraining's l1: 0.117495\ttraining's l2: 0.0601812\tvalid_1's l1: 0.891817\tvalid_1's l2: 1.5239\n",
      "[1454]\ttraining's l1: 0.117462\ttraining's l2: 0.0601166\tvalid_1's l1: 0.89184\tvalid_1's l2: 1.52395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1455]\ttraining's l1: 0.11742\ttraining's l2: 0.0600376\tvalid_1's l1: 0.89189\tvalid_1's l2: 1.52407\n",
      "[1456]\ttraining's l1: 0.117408\ttraining's l2: 0.0599622\tvalid_1's l1: 0.89184\tvalid_1's l2: 1.52412\n",
      "[1457]\ttraining's l1: 0.117343\ttraining's l2: 0.0599036\tvalid_1's l1: 0.892089\tvalid_1's l2: 1.52509\n",
      "[1458]\ttraining's l1: 0.117266\ttraining's l2: 0.0598637\tvalid_1's l1: 0.892046\tvalid_1's l2: 1.5248\n",
      "[1459]\ttraining's l1: 0.11727\ttraining's l2: 0.0597961\tvalid_1's l1: 0.892034\tvalid_1's l2: 1.52479\n",
      "[1460]\ttraining's l1: 0.117252\ttraining's l2: 0.059712\tvalid_1's l1: 0.892091\tvalid_1's l2: 1.52485\n",
      "[1461]\ttraining's l1: 0.117206\ttraining's l2: 0.0596345\tvalid_1's l1: 0.89214\tvalid_1's l2: 1.52497\n",
      "[1462]\ttraining's l1: 0.117159\ttraining's l2: 0.0595896\tvalid_1's l1: 0.892393\tvalid_1's l2: 1.52582\n",
      "[1463]\ttraining's l1: 0.117117\ttraining's l2: 0.0595533\tvalid_1's l1: 0.892551\tvalid_1's l2: 1.52644\n",
      "[1464]\ttraining's l1: 0.117052\ttraining's l2: 0.0595143\tvalid_1's l1: 0.892506\tvalid_1's l2: 1.52614\n",
      "[1465]\ttraining's l1: 0.117019\ttraining's l2: 0.0594784\tvalid_1's l1: 0.892664\tvalid_1's l2: 1.52676\n",
      "[1466]\ttraining's l1: 0.116944\ttraining's l2: 0.0594392\tvalid_1's l1: 0.892621\tvalid_1's l2: 1.52647\n",
      "[1467]\ttraining's l1: 0.116917\ttraining's l2: 0.0594026\tvalid_1's l1: 0.892776\tvalid_1's l2: 1.52709\n",
      "[1468]\ttraining's l1: 0.116904\ttraining's l2: 0.0593712\tvalid_1's l1: 0.892651\tvalid_1's l2: 1.52664\n",
      "[1469]\ttraining's l1: 0.116872\ttraining's l2: 0.059336\tvalid_1's l1: 0.892807\tvalid_1's l2: 1.52725\n",
      "[1470]\ttraining's l1: 0.116825\ttraining's l2: 0.0592952\tvalid_1's l1: 0.892713\tvalid_1's l2: 1.52682\n",
      "[1471]\ttraining's l1: 0.116794\ttraining's l2: 0.0592602\tvalid_1's l1: 0.892868\tvalid_1's l2: 1.52743\n",
      "[1472]\ttraining's l1: 0.116781\ttraining's l2: 0.0592292\tvalid_1's l1: 0.892743\tvalid_1's l2: 1.52698\n",
      "[1473]\ttraining's l1: 0.116779\ttraining's l2: 0.0591426\tvalid_1's l1: 0.892906\tvalid_1's l2: 1.52746\n",
      "[1474]\ttraining's l1: 0.116745\ttraining's l2: 0.0590816\tvalid_1's l1: 0.893002\tvalid_1's l2: 1.52757\n",
      "[1475]\ttraining's l1: 0.116747\ttraining's l2: 0.0590153\tvalid_1's l1: 0.892988\tvalid_1's l2: 1.52756\n",
      "[1476]\ttraining's l1: 0.116699\ttraining's l2: 0.0589506\tvalid_1's l1: 0.893086\tvalid_1's l2: 1.52773\n",
      "[1477]\ttraining's l1: 0.116666\ttraining's l2: 0.0589154\tvalid_1's l1: 0.893242\tvalid_1's l2: 1.52834\n",
      "[1478]\ttraining's l1: 0.116618\ttraining's l2: 0.0588583\tvalid_1's l1: 0.893078\tvalid_1's l2: 1.52789\n",
      "[1479]\ttraining's l1: 0.116624\ttraining's l2: 0.0587934\tvalid_1's l1: 0.893064\tvalid_1's l2: 1.52788\n",
      "[1480]\ttraining's l1: 0.116585\ttraining's l2: 0.0587333\tvalid_1's l1: 0.893159\tvalid_1's l2: 1.52799\n",
      "[1481]\ttraining's l1: 0.116535\ttraining's l2: 0.0586749\tvalid_1's l1: 0.893364\tvalid_1's l2: 1.52868\n",
      "[1482]\ttraining's l1: 0.116536\ttraining's l2: 0.0586022\tvalid_1's l1: 0.893314\tvalid_1's l2: 1.52872\n",
      "[1483]\ttraining's l1: 0.116489\ttraining's l2: 0.0585386\tvalid_1's l1: 0.893412\tvalid_1's l2: 1.52889\n",
      "[1484]\ttraining's l1: 0.116472\ttraining's l2: 0.0584769\tvalid_1's l1: 0.893431\tvalid_1's l2: 1.52894\n",
      "[1485]\ttraining's l1: 0.1164\ttraining's l2: 0.05842\tvalid_1's l1: 0.893678\tvalid_1's l2: 1.52991\n",
      "[1486]\ttraining's l1: 0.11632\ttraining's l2: 0.0583821\tvalid_1's l1: 0.893636\tvalid_1's l2: 1.52962\n",
      "[1487]\ttraining's l1: 0.116234\ttraining's l2: 0.0583119\tvalid_1's l1: 0.893482\tvalid_1's l2: 1.5294\n",
      "[1488]\ttraining's l1: 0.116244\ttraining's l2: 0.0582485\tvalid_1's l1: 0.893468\tvalid_1's l2: 1.5294\n",
      "[1489]\ttraining's l1: 0.116201\ttraining's l2: 0.0582054\tvalid_1's l1: 0.893716\tvalid_1's l2: 1.53022\n",
      "[1490]\ttraining's l1: 0.116199\ttraining's l2: 0.0581274\tvalid_1's l1: 0.89357\tvalid_1's l2: 1.52995\n",
      "[1491]\ttraining's l1: 0.116163\ttraining's l2: 0.0580924\tvalid_1's l1: 0.893726\tvalid_1's l2: 1.53055\n",
      "[1492]\ttraining's l1: 0.116118\ttraining's l2: 0.0580406\tvalid_1's l1: 0.893645\tvalid_1's l2: 1.5302\n",
      "[1493]\ttraining's l1: 0.116124\ttraining's l2: 0.0579601\tvalid_1's l1: 0.8937\tvalid_1's l2: 1.53026\n",
      "[1494]\ttraining's l1: 0.116085\ttraining's l2: 0.0579254\tvalid_1's l1: 0.893856\tvalid_1's l2: 1.53086\n",
      "[1495]\ttraining's l1: 0.116044\ttraining's l2: 0.0578863\tvalid_1's l1: 0.893764\tvalid_1's l2: 1.53044\n",
      "[1496]\ttraining's l1: 0.115999\ttraining's l2: 0.0578511\tvalid_1's l1: 0.893921\tvalid_1's l2: 1.53103\n",
      "[1497]\ttraining's l1: 0.115953\ttraining's l2: 0.0577956\tvalid_1's l1: 0.893759\tvalid_1's l2: 1.53058\n",
      "[1498]\ttraining's l1: 0.115956\ttraining's l2: 0.0577336\tvalid_1's l1: 0.893744\tvalid_1's l2: 1.53057\n",
      "[1499]\ttraining's l1: 0.115921\ttraining's l2: 0.0576702\tvalid_1's l1: 0.893582\tvalid_1's l2: 1.5303\n",
      "[1500]\ttraining's l1: 0.115849\ttraining's l2: 0.0576002\tvalid_1's l1: 0.893617\tvalid_1's l2: 1.53047\n",
      "[1501]\ttraining's l1: 0.115804\ttraining's l2: 0.0575494\tvalid_1's l1: 0.893539\tvalid_1's l2: 1.53013\n",
      "[1502]\ttraining's l1: 0.115804\ttraining's l2: 0.0574684\tvalid_1's l1: 0.893581\tvalid_1's l2: 1.53012\n",
      "[1503]\ttraining's l1: 0.115786\ttraining's l2: 0.0574096\tvalid_1's l1: 0.893601\tvalid_1's l2: 1.53017\n",
      "[1504]\ttraining's l1: 0.115766\ttraining's l2: 0.0573699\tvalid_1's l1: 0.89385\tvalid_1's l2: 1.531\n",
      "[1505]\ttraining's l1: 0.115721\ttraining's l2: 0.0573344\tvalid_1's l1: 0.894009\tvalid_1's l2: 1.5316\n",
      "[1506]\ttraining's l1: 0.115669\ttraining's l2: 0.0572775\tvalid_1's l1: 0.894213\tvalid_1's l2: 1.53228\n",
      "[1507]\ttraining's l1: 0.115632\ttraining's l2: 0.0572147\tvalid_1's l1: 0.894051\tvalid_1's l2: 1.53202\n",
      "[1508]\ttraining's l1: 0.115608\ttraining's l2: 0.0571571\tvalid_1's l1: 0.894144\tvalid_1's l2: 1.53213\n",
      "[1509]\ttraining's l1: 0.115559\ttraining's l2: 0.0570834\tvalid_1's l1: 0.89419\tvalid_1's l2: 1.53224\n",
      "[1510]\ttraining's l1: 0.115514\ttraining's l2: 0.0569948\tvalid_1's l1: 0.894163\tvalid_1's l2: 1.53234\n",
      "[1511]\ttraining's l1: 0.11547\ttraining's l2: 0.056945\tvalid_1's l1: 0.894084\tvalid_1's l2: 1.532\n",
      "[1512]\ttraining's l1: 0.115472\ttraining's l2: 0.0568851\tvalid_1's l1: 0.894069\tvalid_1's l2: 1.53199\n",
      "[1513]\ttraining's l1: 0.115482\ttraining's l2: 0.0568158\tvalid_1's l1: 0.894021\tvalid_1's l2: 1.53204\n",
      "[1514]\ttraining's l1: 0.115408\ttraining's l2: 0.0567598\tvalid_1's l1: 0.893795\tvalid_1's l2: 1.53141\n",
      "[1515]\ttraining's l1: 0.115374\ttraining's l2: 0.056718\tvalid_1's l1: 0.894058\tvalid_1's l2: 1.53225\n",
      "[1516]\ttraining's l1: 0.115329\ttraining's l2: 0.0566828\tvalid_1's l1: 0.894215\tvalid_1's l2: 1.53284\n",
      "[1517]\ttraining's l1: 0.115337\ttraining's l2: 0.0566082\tvalid_1's l1: 0.894072\tvalid_1's l2: 1.53257\n",
      "[1518]\ttraining's l1: 0.115293\ttraining's l2: 0.0565594\tvalid_1's l1: 0.893995\tvalid_1's l2: 1.53223\n",
      "[1519]\ttraining's l1: 0.115275\ttraining's l2: 0.0565026\tvalid_1's l1: 0.894023\tvalid_1's l2: 1.5323\n",
      "[1520]\ttraining's l1: 0.115248\ttraining's l2: 0.0564462\tvalid_1's l1: 0.894115\tvalid_1's l2: 1.53241\n",
      "[1521]\ttraining's l1: 0.115139\ttraining's l2: 0.0563868\tvalid_1's l1: 0.894376\tvalid_1's l2: 1.53338\n",
      "[1522]\ttraining's l1: 0.115093\ttraining's l2: 0.0563147\tvalid_1's l1: 0.894422\tvalid_1's l2: 1.5335\n",
      "[1523]\ttraining's l1: 0.115101\ttraining's l2: 0.0562465\tvalid_1's l1: 0.894375\tvalid_1's l2: 1.53355\n",
      "[1524]\ttraining's l1: 0.115035\ttraining's l2: 0.0561861\tvalid_1's l1: 0.894362\tvalid_1's l2: 1.53334\n",
      "[1525]\ttraining's l1: 0.115029\ttraining's l2: 0.0561321\tvalid_1's l1: 0.89441\tvalid_1's l2: 1.53351\n",
      "[1526]\ttraining's l1: 0.114978\ttraining's l2: 0.056061\tvalid_1's l1: 0.894456\tvalid_1's l2: 1.53362\n",
      "[1527]\ttraining's l1: 0.114896\ttraining's l2: 0.0560024\tvalid_1's l1: 0.894637\tvalid_1's l2: 1.53429\n",
      "[1528]\ttraining's l1: 0.114852\ttraining's l2: 0.0559677\tvalid_1's l1: 0.894791\tvalid_1's l2: 1.53487\n",
      "[1529]\ttraining's l1: 0.114789\ttraining's l2: 0.0559009\tvalid_1's l1: 0.894835\tvalid_1's l2: 1.53502\n",
      "[1530]\ttraining's l1: 0.11478\ttraining's l2: 0.0558362\tvalid_1's l1: 0.894804\tvalid_1's l2: 1.53525\n",
      "[1531]\ttraining's l1: 0.114734\ttraining's l2: 0.0557665\tvalid_1's l1: 0.894849\tvalid_1's l2: 1.53536\n",
      "[1532]\ttraining's l1: 0.114689\ttraining's l2: 0.0556816\tvalid_1's l1: 0.894823\tvalid_1's l2: 1.53547\n",
      "[1533]\ttraining's l1: 0.114669\ttraining's l2: 0.0556262\tvalid_1's l1: 0.894838\tvalid_1's l2: 1.53551\n",
      "[1534]\ttraining's l1: 0.114684\ttraining's l2: 0.0555601\tvalid_1's l1: 0.894793\tvalid_1's l2: 1.53557\n",
      "[1535]\ttraining's l1: 0.114555\ttraining's l2: 0.055506\tvalid_1's l1: 0.894768\tvalid_1's l2: 1.53541\n",
      "[1536]\ttraining's l1: 0.114453\ttraining's l2: 0.0554482\tvalid_1's l1: 0.895025\tvalid_1's l2: 1.53637\n",
      "[1537]\ttraining's l1: 0.114458\ttraining's l2: 0.0553909\tvalid_1's l1: 0.895007\tvalid_1's l2: 1.53636\n",
      "[1538]\ttraining's l1: 0.114391\ttraining's l2: 0.0553366\tvalid_1's l1: 0.894784\tvalid_1's l2: 1.53574\n",
      "[1539]\ttraining's l1: 0.114381\ttraining's l2: 0.0552822\tvalid_1's l1: 0.894875\tvalid_1's l2: 1.53585\n",
      "[1540]\ttraining's l1: 0.11434\ttraining's l2: 0.0552138\tvalid_1's l1: 0.89492\tvalid_1's l2: 1.53596\n",
      "[1541]\ttraining's l1: 0.1143\ttraining's l2: 0.0551802\tvalid_1's l1: 0.895072\tvalid_1's l2: 1.53655\n",
      "[1542]\ttraining's l1: 0.114243\ttraining's l2: 0.0551275\tvalid_1's l1: 0.895045\tvalid_1's l2: 1.53633\n",
      "[1543]\ttraining's l1: 0.114253\ttraining's l2: 0.055077\tvalid_1's l1: 0.895053\tvalid_1's l2: 1.53644\n",
      "[1544]\ttraining's l1: 0.114206\ttraining's l2: 0.055043\tvalid_1's l1: 0.895205\tvalid_1's l2: 1.53701\n",
      "[1545]\ttraining's l1: 0.114105\ttraining's l2: 0.0549865\tvalid_1's l1: 0.895458\tvalid_1's l2: 1.53796\n",
      "[1546]\ttraining's l1: 0.113977\ttraining's l2: 0.0549334\tvalid_1's l1: 0.895432\tvalid_1's l2: 1.5378\n",
      "[1547]\ttraining's l1: 0.113983\ttraining's l2: 0.0548614\tvalid_1's l1: 0.895291\tvalid_1's l2: 1.53753\n",
      "[1548]\ttraining's l1: 0.11391\ttraining's l2: 0.0548054\tvalid_1's l1: 0.895468\tvalid_1's l2: 1.53819\n",
      "[1549]\ttraining's l1: 0.113876\ttraining's l2: 0.0547382\tvalid_1's l1: 0.895512\tvalid_1's l2: 1.5383\n",
      "[1550]\ttraining's l1: 0.113831\ttraining's l2: 0.0546558\tvalid_1's l1: 0.895448\tvalid_1's l2: 1.53834\n",
      "[1551]\ttraining's l1: 0.113825\ttraining's l2: 0.0545928\tvalid_1's l1: 0.895472\tvalid_1's l2: 1.53862\n",
      "[1552]\ttraining's l1: 0.113772\ttraining's l2: 0.0545413\tvalid_1's l1: 0.895445\tvalid_1's l2: 1.5384\n",
      "[1553]\ttraining's l1: 0.11373\ttraining's l2: 0.0545081\tvalid_1's l1: 0.895594\tvalid_1's l2: 1.53896\n",
      "[1554]\ttraining's l1: 0.113704\ttraining's l2: 0.0544836\tvalid_1's l1: 0.895473\tvalid_1's l2: 1.53863\n",
      "[1555]\ttraining's l1: 0.113669\ttraining's l2: 0.0544515\tvalid_1's l1: 0.89562\tvalid_1's l2: 1.53921\n",
      "[1556]\ttraining's l1: 0.113596\ttraining's l2: 0.0543968\tvalid_1's l1: 0.895792\tvalid_1's l2: 1.53985\n",
      "[1557]\ttraining's l1: 0.113506\ttraining's l2: 0.0543725\tvalid_1's l1: 0.895786\tvalid_1's l2: 1.53942\n",
      "[1558]\ttraining's l1: 0.113428\ttraining's l2: 0.0543337\tvalid_1's l1: 0.895995\tvalid_1's l2: 1.54013\n",
      "[1559]\ttraining's l1: 0.113395\ttraining's l2: 0.0542678\tvalid_1's l1: 0.896039\tvalid_1's l2: 1.54024\n",
      "[1560]\ttraining's l1: 0.113368\ttraining's l2: 0.0542147\tvalid_1's l1: 0.896063\tvalid_1's l2: 1.54026\n",
      "[1561]\ttraining's l1: 0.113315\ttraining's l2: 0.0541512\tvalid_1's l1: 0.896105\tvalid_1's l2: 1.54041\n",
      "[1562]\ttraining's l1: 0.113289\ttraining's l2: 0.0540972\tvalid_1's l1: 0.896117\tvalid_1's l2: 1.54045\n",
      "[1563]\ttraining's l1: 0.113306\ttraining's l2: 0.0540334\tvalid_1's l1: 0.896074\tvalid_1's l2: 1.54051\n",
      "[1564]\ttraining's l1: 0.113238\ttraining's l2: 0.0539829\tvalid_1's l1: 0.896303\tvalid_1's l2: 1.54142\n",
      "[1565]\ttraining's l1: 0.113171\ttraining's l2: 0.0539015\tvalid_1's l1: 0.896202\tvalid_1's l2: 1.54115\n",
      "[1566]\ttraining's l1: 0.11308\ttraining's l2: 0.0538774\tvalid_1's l1: 0.896196\tvalid_1's l2: 1.54073\n",
      "[1567]\ttraining's l1: 0.112963\ttraining's l2: 0.0538257\tvalid_1's l1: 0.896171\tvalid_1's l2: 1.54057\n",
      "[1568]\ttraining's l1: 0.112893\ttraining's l2: 0.0537581\tvalid_1's l1: 0.896477\tvalid_1's l2: 1.54141\n",
      "[1569]\ttraining's l1: 0.112825\ttraining's l2: 0.0536918\tvalid_1's l1: 0.896781\tvalid_1's l2: 1.54225\n",
      "[1570]\ttraining's l1: 0.112813\ttraining's l2: 0.0536305\tvalid_1's l1: 0.896752\tvalid_1's l2: 1.54248\n",
      "[1571]\ttraining's l1: 0.112763\ttraining's l2: 0.0535947\tvalid_1's l1: 0.896974\tvalid_1's l2: 1.5432\n",
      "[1572]\ttraining's l1: 0.112763\ttraining's l2: 0.0535188\tvalid_1's l1: 0.897127\tvalid_1's l2: 1.54366\n",
      "[1573]\ttraining's l1: 0.112697\ttraining's l2: 0.0534398\tvalid_1's l1: 0.897098\tvalid_1's l2: 1.54373\n",
      "[1574]\ttraining's l1: 0.112671\ttraining's l2: 0.0533867\tvalid_1's l1: 0.89711\tvalid_1's l2: 1.54377\n",
      "[1575]\ttraining's l1: 0.112671\ttraining's l2: 0.0533263\tvalid_1's l1: 0.897135\tvalid_1's l2: 1.54405\n",
      "[1576]\ttraining's l1: 0.112602\ttraining's l2: 0.05325\tvalid_1's l1: 0.897093\tvalid_1's l2: 1.544\n",
      "[1577]\ttraining's l1: 0.112571\ttraining's l2: 0.0531907\tvalid_1's l1: 0.896934\tvalid_1's l2: 1.54373\n",
      "[1578]\ttraining's l1: 0.112503\ttraining's l2: 0.0531416\tvalid_1's l1: 0.89716\tvalid_1's l2: 1.54462\n",
      "[1579]\ttraining's l1: 0.112505\ttraining's l2: 0.053082\tvalid_1's l1: 0.897185\tvalid_1's l2: 1.5449\n",
      "[1580]\ttraining's l1: 0.112403\ttraining's l2: 0.05302\tvalid_1's l1: 0.897147\tvalid_1's l2: 1.54475\n",
      "[1581]\ttraining's l1: 0.112286\ttraining's l2: 0.0529694\tvalid_1's l1: 0.897123\tvalid_1's l2: 1.54459\n",
      "[1582]\ttraining's l1: 0.112265\ttraining's l2: 0.0529177\tvalid_1's l1: 0.897135\tvalid_1's l2: 1.54463\n",
      "[1583]\ttraining's l1: 0.112213\ttraining's l2: 0.0528397\tvalid_1's l1: 0.897025\tvalid_1's l2: 1.54436\n",
      "[1584]\ttraining's l1: 0.112186\ttraining's l2: 0.0527822\tvalid_1's l1: 0.896869\tvalid_1's l2: 1.54409\n",
      "[1585]\ttraining's l1: 0.112116\ttraining's l2: 0.0527447\tvalid_1's l1: 0.897081\tvalid_1's l2: 1.54478\n",
      "[1586]\ttraining's l1: 0.112121\ttraining's l2: 0.0526719\tvalid_1's l1: 0.897121\tvalid_1's l2: 1.54477\n",
      "[1587]\ttraining's l1: 0.112027\ttraining's l2: 0.0525688\tvalid_1's l1: 0.897363\tvalid_1's l2: 1.5454\n",
      "[1588]\ttraining's l1: 0.111997\ttraining's l2: 0.0525448\tvalid_1's l1: 0.897255\tvalid_1's l2: 1.54508\n",
      "[1589]\ttraining's l1: 0.111927\ttraining's l2: 0.05248\tvalid_1's l1: 0.897559\tvalid_1's l2: 1.54592\n",
      "[1590]\ttraining's l1: 0.111877\ttraining's l2: 0.0524451\tvalid_1's l1: 0.897724\tvalid_1's l2: 1.54659\n",
      "[1591]\ttraining's l1: 0.111762\ttraining's l2: 0.0523956\tvalid_1's l1: 0.897699\tvalid_1's l2: 1.54643\n",
      "[1592]\ttraining's l1: 0.11172\ttraining's l2: 0.0523299\tvalid_1's l1: 0.897848\tvalid_1's l2: 1.54704\n",
      "[1593]\ttraining's l1: 0.111673\ttraining's l2: 0.0522956\tvalid_1's l1: 0.898066\tvalid_1's l2: 1.54775\n",
      "[1594]\ttraining's l1: 0.111604\ttraining's l2: 0.0522323\tvalid_1's l1: 0.898365\tvalid_1's l2: 1.54857\n",
      "[1595]\ttraining's l1: 0.111608\ttraining's l2: 0.0521837\tvalid_1's l1: 0.898366\tvalid_1's l2: 1.54867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1596]\ttraining's l1: 0.111517\ttraining's l2: 0.0520826\tvalid_1's l1: 0.898604\tvalid_1's l2: 1.54929\n",
      "[1597]\ttraining's l1: 0.111409\ttraining's l2: 0.0520597\tvalid_1's l1: 0.89859\tvalid_1's l2: 1.54886\n",
      "[1598]\ttraining's l1: 0.111363\ttraining's l2: 0.0519838\tvalid_1's l1: 0.898481\tvalid_1's l2: 1.54858\n",
      "[1599]\ttraining's l1: 0.111333\ttraining's l2: 0.05196\tvalid_1's l1: 0.898371\tvalid_1's l2: 1.54826\n",
      "[1600]\ttraining's l1: 0.111318\ttraining's l2: 0.0519092\tvalid_1's l1: 0.898384\tvalid_1's l2: 1.5483\n",
      "[1601]\ttraining's l1: 0.111237\ttraining's l2: 0.0518103\tvalid_1's l1: 0.898621\tvalid_1's l2: 1.54892\n",
      "[1602]\ttraining's l1: 0.11121\ttraining's l2: 0.0517548\tvalid_1's l1: 0.898468\tvalid_1's l2: 1.54866\n",
      "[1603]\ttraining's l1: 0.111168\ttraining's l2: 0.0516794\tvalid_1's l1: 0.898443\tvalid_1's l2: 1.54876\n",
      "[1604]\ttraining's l1: 0.111101\ttraining's l2: 0.0516177\tvalid_1's l1: 0.898737\tvalid_1's l2: 1.54958\n",
      "[1605]\ttraining's l1: 0.111074\ttraining's l2: 0.0515629\tvalid_1's l1: 0.898585\tvalid_1's l2: 1.54932\n",
      "[1606]\ttraining's l1: 0.111009\ttraining's l2: 0.0514885\tvalid_1's l1: 0.898557\tvalid_1's l2: 1.54939\n",
      "[1607]\ttraining's l1: 0.110987\ttraining's l2: 0.0514391\tvalid_1's l1: 0.89858\tvalid_1's l2: 1.54945\n",
      "[1608]\ttraining's l1: 0.110972\ttraining's l2: 0.0514037\tvalid_1's l1: 0.898808\tvalid_1's l2: 1.55023\n",
      "[1609]\ttraining's l1: 0.110909\ttraining's l2: 0.0513432\tvalid_1's l1: 0.899099\tvalid_1's l2: 1.55105\n",
      "[1610]\ttraining's l1: 0.110882\ttraining's l2: 0.0512942\tvalid_1's l1: 0.898907\tvalid_1's l2: 1.5507\n",
      "[1611]\ttraining's l1: 0.110834\ttraining's l2: 0.0512458\tvalid_1's l1: 0.899104\tvalid_1's l2: 1.55133\n",
      "[1612]\ttraining's l1: 0.110727\ttraining's l2: 0.0511981\tvalid_1's l1: 0.89908\tvalid_1's l2: 1.55118\n",
      "[1613]\ttraining's l1: 0.110678\ttraining's l2: 0.0511644\tvalid_1's l1: 0.899295\tvalid_1's l2: 1.55188\n",
      "[1614]\ttraining's l1: 0.110687\ttraining's l2: 0.0511115\tvalid_1's l1: 0.899274\tvalid_1's l2: 1.55187\n",
      "[1615]\ttraining's l1: 0.110693\ttraining's l2: 0.0510423\tvalid_1's l1: 0.899314\tvalid_1's l2: 1.55188\n",
      "[1616]\ttraining's l1: 0.110647\ttraining's l2: 0.0509689\tvalid_1's l1: 0.899206\tvalid_1's l2: 1.55161\n",
      "[1617]\ttraining's l1: 0.110565\ttraining's l2: 0.0508727\tvalid_1's l1: 0.899441\tvalid_1's l2: 1.55223\n",
      "[1618]\ttraining's l1: 0.110545\ttraining's l2: 0.0508196\tvalid_1's l1: 0.89929\tvalid_1's l2: 1.55197\n",
      "[1619]\ttraining's l1: 0.11049\ttraining's l2: 0.0507467\tvalid_1's l1: 0.89923\tvalid_1's l2: 1.55202\n",
      "[1620]\ttraining's l1: 0.110428\ttraining's l2: 0.0507139\tvalid_1's l1: 0.899183\tvalid_1's l2: 1.55173\n",
      "[1621]\ttraining's l1: 0.110369\ttraining's l2: 0.0506492\tvalid_1's l1: 0.899173\tvalid_1's l2: 1.55182\n",
      "[1622]\ttraining's l1: 0.110349\ttraining's l2: 0.0506216\tvalid_1's l1: 0.899047\tvalid_1's l2: 1.55137\n",
      "[1623]\ttraining's l1: 0.110295\ttraining's l2: 0.0505829\tvalid_1's l1: 0.899178\tvalid_1's l2: 1.55206\n",
      "[1624]\ttraining's l1: 0.110236\ttraining's l2: 0.0505193\tvalid_1's l1: 0.899168\tvalid_1's l2: 1.55216\n",
      "[1625]\ttraining's l1: 0.110169\ttraining's l2: 0.0504717\tvalid_1's l1: 0.899435\tvalid_1's l2: 1.55307\n",
      "[1626]\ttraining's l1: 0.110136\ttraining's l2: 0.0504489\tvalid_1's l1: 0.899328\tvalid_1's l2: 1.55275\n",
      "[1627]\ttraining's l1: 0.110139\ttraining's l2: 0.0503972\tvalid_1's l1: 0.899309\tvalid_1's l2: 1.55274\n",
      "[1628]\ttraining's l1: 0.110157\ttraining's l2: 0.0503418\tvalid_1's l1: 0.899385\tvalid_1's l2: 1.55304\n",
      "[1629]\ttraining's l1: 0.110092\ttraining's l2: 0.0502702\tvalid_1's l1: 0.899392\tvalid_1's l2: 1.55316\n",
      "[1630]\ttraining's l1: 0.110071\ttraining's l2: 0.0502226\tvalid_1's l1: 0.899405\tvalid_1's l2: 1.5532\n",
      "[1631]\ttraining's l1: 0.110008\ttraining's l2: 0.0501751\tvalid_1's l1: 0.899673\tvalid_1's l2: 1.5541\n",
      "[1632]\ttraining's l1: 0.10999\ttraining's l2: 0.0501394\tvalid_1's l1: 0.899841\tvalid_1's l2: 1.55481\n",
      "[1633]\ttraining's l1: 0.10995\ttraining's l2: 0.0500677\tvalid_1's l1: 0.899735\tvalid_1's l2: 1.55455\n",
      "[1634]\ttraining's l1: 0.109928\ttraining's l2: 0.0500167\tvalid_1's l1: 0.899588\tvalid_1's l2: 1.5543\n",
      "[1635]\ttraining's l1: 0.109861\ttraining's l2: 0.0499579\tvalid_1's l1: 0.899867\tvalid_1's l2: 1.55509\n",
      "[1636]\ttraining's l1: 0.109789\ttraining's l2: 0.049889\tvalid_1's l1: 0.899827\tvalid_1's l2: 1.55505\n",
      "[1637]\ttraining's l1: 0.109708\ttraining's l2: 0.0498384\tvalid_1's l1: 0.899793\tvalid_1's l2: 1.55504\n",
      "[1638]\ttraining's l1: 0.1096\ttraining's l2: 0.049793\tvalid_1's l1: 0.89977\tvalid_1's l2: 1.55489\n",
      "[1639]\ttraining's l1: 0.109602\ttraining's l2: 0.0497428\tvalid_1's l1: 0.89975\tvalid_1's l2: 1.55488\n",
      "[1640]\ttraining's l1: 0.109536\ttraining's l2: 0.0496588\tvalid_1's l1: 0.899937\tvalid_1's l2: 1.55522\n",
      "[1641]\ttraining's l1: 0.109472\ttraining's l2: 0.0496236\tvalid_1's l1: 0.900142\tvalid_1's l2: 1.55588\n",
      "[1642]\ttraining's l1: 0.109484\ttraining's l2: 0.0495696\tvalid_1's l1: 0.900164\tvalid_1's l2: 1.55613\n",
      "[1643]\ttraining's l1: 0.109441\ttraining's l2: 0.0494998\tvalid_1's l1: 0.900059\tvalid_1's l2: 1.55587\n",
      "[1644]\ttraining's l1: 0.109404\ttraining's l2: 0.0494301\tvalid_1's l1: 0.900074\tvalid_1's l2: 1.55602\n",
      "[1645]\ttraining's l1: 0.109382\ttraining's l2: 0.0493808\tvalid_1's l1: 0.89993\tvalid_1's l2: 1.55577\n",
      "[1646]\ttraining's l1: 0.109312\ttraining's l2: 0.0493138\tvalid_1's l1: 0.89989\tvalid_1's l2: 1.55572\n",
      "[1647]\ttraining's l1: 0.109251\ttraining's l2: 0.0492825\tvalid_1's l1: 0.899845\tvalid_1's l2: 1.55544\n",
      "[1648]\ttraining's l1: 0.109237\ttraining's l2: 0.0492363\tvalid_1's l1: 0.899858\tvalid_1's l2: 1.55548\n",
      "[1649]\ttraining's l1: 0.109221\ttraining's l2: 0.0492007\tvalid_1's l1: 0.900026\tvalid_1's l2: 1.5562\n",
      "[1650]\ttraining's l1: 0.109162\ttraining's l2: 0.0491393\tvalid_1's l1: 0.900008\tvalid_1's l2: 1.5563\n",
      "[1651]\ttraining's l1: 0.109116\ttraining's l2: 0.0490925\tvalid_1's l1: 0.900206\tvalid_1's l2: 1.55692\n",
      "[1652]\ttraining's l1: 0.109132\ttraining's l2: 0.0490395\tvalid_1's l1: 0.90028\tvalid_1's l2: 1.55722\n",
      "[1653]\ttraining's l1: 0.109099\ttraining's l2: 0.0489711\tvalid_1's l1: 0.900177\tvalid_1's l2: 1.55696\n",
      "[1654]\ttraining's l1: 0.109083\ttraining's l2: 0.0489226\tvalid_1's l1: 0.900036\tvalid_1's l2: 1.55672\n",
      "[1655]\ttraining's l1: 0.109056\ttraining's l2: 0.0489009\tvalid_1's l1: 0.899935\tvalid_1's l2: 1.55641\n",
      "[1656]\ttraining's l1: 0.108987\ttraining's l2: 0.0488545\tvalid_1's l1: 0.900201\tvalid_1's l2: 1.5573\n",
      "[1657]\ttraining's l1: 0.108975\ttraining's l2: 0.0488193\tvalid_1's l1: 0.900367\tvalid_1's l2: 1.55801\n",
      "[1658]\ttraining's l1: 0.108921\ttraining's l2: 0.0487589\tvalid_1's l1: 0.900348\tvalid_1's l2: 1.5581\n",
      "[1659]\ttraining's l1: 0.108903\ttraining's l2: 0.0487323\tvalid_1's l1: 0.900224\tvalid_1's l2: 1.55766\n",
      "[1660]\ttraining's l1: 0.108863\ttraining's l2: 0.0486866\tvalid_1's l1: 0.90042\tvalid_1's l2: 1.55827\n",
      "[1661]\ttraining's l1: 0.108808\ttraining's l2: 0.0486493\tvalid_1's l1: 0.900549\tvalid_1's l2: 1.55894\n",
      "[1662]\ttraining's l1: 0.108784\ttraining's l2: 0.0486174\tvalid_1's l1: 0.900511\tvalid_1's l2: 1.5587\n",
      "[1663]\ttraining's l1: 0.108767\ttraining's l2: 0.0485722\tvalid_1's l1: 0.900549\tvalid_1's l2: 1.55885\n",
      "[1664]\ttraining's l1: 0.108716\ttraining's l2: 0.0485049\tvalid_1's l1: 0.90047\tvalid_1's l2: 1.5586\n",
      "[1665]\ttraining's l1: 0.108689\ttraining's l2: 0.0484834\tvalid_1's l1: 0.900369\tvalid_1's l2: 1.55829\n",
      "[1666]\ttraining's l1: 0.108618\ttraining's l2: 0.0483963\tvalid_1's l1: 0.900389\tvalid_1's l2: 1.55833\n",
      "[1667]\ttraining's l1: 0.108547\ttraining's l2: 0.0483396\tvalid_1's l1: 0.900665\tvalid_1's l2: 1.55912\n",
      "[1668]\ttraining's l1: 0.108476\ttraining's l2: 0.0482539\tvalid_1's l1: 0.900685\tvalid_1's l2: 1.55916\n",
      "[1669]\ttraining's l1: 0.108439\ttraining's l2: 0.0481867\tvalid_1's l1: 0.9007\tvalid_1's l2: 1.55931\n",
      "[1670]\ttraining's l1: 0.108424\ttraining's l2: 0.0481422\tvalid_1's l1: 0.900713\tvalid_1's l2: 1.55935\n",
      "[1671]\ttraining's l1: 0.108353\ttraining's l2: 0.048096\tvalid_1's l1: 0.900989\tvalid_1's l2: 1.56025\n",
      "[1672]\ttraining's l1: 0.10834\ttraining's l2: 0.0480623\tvalid_1's l1: 0.901208\tvalid_1's l2: 1.561\n",
      "[1673]\ttraining's l1: 0.108305\ttraining's l2: 0.0479963\tvalid_1's l1: 0.901107\tvalid_1's l2: 1.56075\n",
      "[1674]\ttraining's l1: 0.108279\ttraining's l2: 0.0479752\tvalid_1's l1: 0.901008\tvalid_1's l2: 1.56045\n",
      "[1675]\ttraining's l1: 0.10821\ttraining's l2: 0.0479198\tvalid_1's l1: 0.901281\tvalid_1's l2: 1.56124\n",
      "[1676]\ttraining's l1: 0.108159\ttraining's l2: 0.0478462\tvalid_1's l1: 0.901193\tvalid_1's l2: 1.56104\n",
      "[1677]\ttraining's l1: 0.108114\ttraining's l2: 0.0478007\tvalid_1's l1: 0.901398\tvalid_1's l2: 1.56167\n",
      "[1678]\ttraining's l1: 0.108051\ttraining's l2: 0.0477485\tvalid_1's l1: 0.901427\tvalid_1's l2: 1.56181\n",
      "[1679]\ttraining's l1: 0.108069\ttraining's l2: 0.0476974\tvalid_1's l1: 0.901455\tvalid_1's l2: 1.56208\n",
      "[1680]\ttraining's l1: 0.107995\ttraining's l2: 0.0476333\tvalid_1's l1: 0.901417\tvalid_1's l2: 1.56204\n",
      "[1681]\ttraining's l1: 0.107954\ttraining's l2: 0.0475659\tvalid_1's l1: 0.90136\tvalid_1's l2: 1.5619\n",
      "[1682]\ttraining's l1: 0.107884\ttraining's l2: 0.0474826\tvalid_1's l1: 0.90138\tvalid_1's l2: 1.56194\n",
      "[1683]\ttraining's l1: 0.10785\ttraining's l2: 0.0474185\tvalid_1's l1: 0.901279\tvalid_1's l2: 1.56169\n",
      "[1684]\ttraining's l1: 0.107824\ttraining's l2: 0.0473977\tvalid_1's l1: 0.901183\tvalid_1's l2: 1.5614\n",
      "[1685]\ttraining's l1: 0.107758\ttraining's l2: 0.0473432\tvalid_1's l1: 0.901454\tvalid_1's l2: 1.56218\n",
      "[1686]\ttraining's l1: 0.107745\ttraining's l2: 0.047309\tvalid_1's l1: 0.901617\tvalid_1's l2: 1.56287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1687]\ttraining's l1: 0.107726\ttraining's l2: 0.0472698\tvalid_1's l1: 0.901676\tvalid_1's l2: 1.56296\n",
      "[1688]\ttraining's l1: 0.10773\ttraining's l2: 0.0472235\tvalid_1's l1: 0.901763\tvalid_1's l2: 1.56307\n",
      "[1689]\ttraining's l1: 0.107677\ttraining's l2: 0.0471668\tvalid_1's l1: 0.901747\tvalid_1's l2: 1.56317\n",
      "[1690]\ttraining's l1: 0.107615\ttraining's l2: 0.0470876\tvalid_1's l1: 0.90193\tvalid_1's l2: 1.56351\n",
      "[1691]\ttraining's l1: 0.107589\ttraining's l2: 0.0470445\tvalid_1's l1: 0.901915\tvalid_1's l2: 1.5636\n",
      "[1692]\ttraining's l1: 0.10753\ttraining's l2: 0.0470007\tvalid_1's l1: 0.902175\tvalid_1's l2: 1.56448\n",
      "[1693]\ttraining's l1: 0.107474\ttraining's l2: 0.046938\tvalid_1's l1: 0.902099\tvalid_1's l2: 1.56424\n",
      "[1694]\ttraining's l1: 0.107434\ttraining's l2: 0.046872\tvalid_1's l1: 0.902044\tvalid_1's l2: 1.56411\n",
      "[1695]\ttraining's l1: 0.107395\ttraining's l2: 0.046804\tvalid_1's l1: 0.902083\tvalid_1's l2: 1.56426\n",
      "[1696]\ttraining's l1: 0.107345\ttraining's l2: 0.0467332\tvalid_1's l1: 0.901997\tvalid_1's l2: 1.56406\n",
      "[1697]\ttraining's l1: 0.107278\ttraining's l2: 0.0466691\tvalid_1's l1: 0.901971\tvalid_1's l2: 1.56413\n",
      "[1698]\ttraining's l1: 0.107211\ttraining's l2: 0.0465889\tvalid_1's l1: 0.90199\tvalid_1's l2: 1.56417\n",
      "[1699]\ttraining's l1: 0.107161\ttraining's l2: 0.0465207\tvalid_1's l1: 0.901905\tvalid_1's l2: 1.56398\n",
      "[1700]\ttraining's l1: 0.107082\ttraining's l2: 0.0464587\tvalid_1's l1: 0.901868\tvalid_1's l2: 1.56393\n",
      "[1701]\ttraining's l1: 0.107064\ttraining's l2: 0.0464259\tvalid_1's l1: 0.902084\tvalid_1's l2: 1.56468\n",
      "[1702]\ttraining's l1: 0.107014\ttraining's l2: 0.0463586\tvalid_1's l1: 0.901999\tvalid_1's l2: 1.56449\n",
      "[1703]\ttraining's l1: 0.106981\ttraining's l2: 0.0462972\tvalid_1's l1: 0.901901\tvalid_1's l2: 1.56425\n",
      "[1704]\ttraining's l1: 0.106942\ttraining's l2: 0.0462324\tvalid_1's l1: 0.901846\tvalid_1's l2: 1.56411\n",
      "[1705]\ttraining's l1: 0.106878\ttraining's l2: 0.0461796\tvalid_1's l1: 0.902114\tvalid_1's l2: 1.56489\n",
      "[1706]\ttraining's l1: 0.106838\ttraining's l2: 0.0461358\tvalid_1's l1: 0.902306\tvalid_1's l2: 1.5655\n",
      "[1707]\ttraining's l1: 0.106799\ttraining's l2: 0.046098\tvalid_1's l1: 0.902086\tvalid_1's l2: 1.56499\n",
      "[1708]\ttraining's l1: 0.106775\ttraining's l2: 0.0460556\tvalid_1's l1: 0.902107\tvalid_1's l2: 1.56505\n",
      "[1709]\ttraining's l1: 0.106761\ttraining's l2: 0.0460221\tvalid_1's l1: 0.902267\tvalid_1's l2: 1.56573\n",
      "[1710]\ttraining's l1: 0.106699\ttraining's l2: 0.0459705\tvalid_1's l1: 0.902532\tvalid_1's l2: 1.5665\n",
      "[1711]\ttraining's l1: 0.106633\ttraining's l2: 0.0458935\tvalid_1's l1: 0.90255\tvalid_1's l2: 1.56654\n",
      "[1712]\ttraining's l1: 0.106573\ttraining's l2: 0.0458173\tvalid_1's l1: 0.902733\tvalid_1's l2: 1.56688\n",
      "[1713]\ttraining's l1: 0.106515\ttraining's l2: 0.045755\tvalid_1's l1: 0.902678\tvalid_1's l2: 1.56693\n",
      "[1714]\ttraining's l1: 0.106449\ttraining's l2: 0.0456815\tvalid_1's l1: 0.902679\tvalid_1's l2: 1.56691\n",
      "[1715]\ttraining's l1: 0.106455\ttraining's l2: 0.0456371\tvalid_1's l1: 0.902765\tvalid_1's l2: 1.56701\n",
      "[1716]\ttraining's l1: 0.106424\ttraining's l2: 0.0455784\tvalid_1's l1: 0.902757\tvalid_1's l2: 1.56715\n",
      "[1717]\ttraining's l1: 0.106382\ttraining's l2: 0.045515\tvalid_1's l1: 0.902702\tvalid_1's l2: 1.56702\n",
      "[1718]\ttraining's l1: 0.106324\ttraining's l2: 0.0454627\tvalid_1's l1: 0.902968\tvalid_1's l2: 1.56779\n",
      "[1719]\ttraining's l1: 0.106283\ttraining's l2: 0.0454005\tvalid_1's l1: 0.902914\tvalid_1's l2: 1.56766\n",
      "[1720]\ttraining's l1: 0.106257\ttraining's l2: 0.0453413\tvalid_1's l1: 0.902818\tvalid_1's l2: 1.56743\n",
      "[1721]\ttraining's l1: 0.106199\ttraining's l2: 0.0452911\tvalid_1's l1: 0.90308\tvalid_1's l2: 1.56819\n",
      "[1722]\ttraining's l1: 0.106154\ttraining's l2: 0.0452543\tvalid_1's l1: 0.902864\tvalid_1's l2: 1.56769\n",
      "[1723]\ttraining's l1: 0.106128\ttraining's l2: 0.0452172\tvalid_1's l1: 0.90292\tvalid_1's l2: 1.56777\n",
      "[1724]\ttraining's l1: 0.106099\ttraining's l2: 0.0451752\tvalid_1's l1: 0.903113\tvalid_1's l2: 1.56839\n",
      "[1725]\ttraining's l1: 0.106055\ttraining's l2: 0.0451105\tvalid_1's l1: 0.903012\tvalid_1's l2: 1.56815\n",
      "[1726]\ttraining's l1: 0.105936\ttraining's l2: 0.0450566\tvalid_1's l1: 0.902993\tvalid_1's l2: 1.56806\n",
      "[1727]\ttraining's l1: 0.105951\ttraining's l2: 0.0450095\tvalid_1's l1: 0.90294\tvalid_1's l2: 1.56806\n",
      "[1728]\ttraining's l1: 0.10592\ttraining's l2: 0.0449521\tvalid_1's l1: 0.902933\tvalid_1's l2: 1.5682\n",
      "[1729]\ttraining's l1: 0.105861\ttraining's l2: 0.044879\tvalid_1's l1: 0.902934\tvalid_1's l2: 1.56819\n",
      "[1730]\ttraining's l1: 0.105754\ttraining's l2: 0.0448364\tvalid_1's l1: 0.903058\tvalid_1's l2: 1.56849\n",
      "[1731]\ttraining's l1: 0.105713\ttraining's l2: 0.0448004\tvalid_1's l1: 0.902845\tvalid_1's l2: 1.568\n",
      "[1732]\ttraining's l1: 0.105687\ttraining's l2: 0.0447639\tvalid_1's l1: 0.902901\tvalid_1's l2: 1.56808\n",
      "[1733]\ttraining's l1: 0.105625\ttraining's l2: 0.0447214\tvalid_1's l1: 0.903159\tvalid_1's l2: 1.56896\n",
      "[1734]\ttraining's l1: 0.105578\ttraining's l2: 0.0446659\tvalid_1's l1: 0.903066\tvalid_1's l2: 1.56884\n",
      "[1735]\ttraining's l1: 0.105513\ttraining's l2: 0.0446006\tvalid_1's l1: 0.903179\tvalid_1's l2: 1.56909\n",
      "[1736]\ttraining's l1: 0.105459\ttraining's l2: 0.04455\tvalid_1's l1: 0.903441\tvalid_1's l2: 1.56986\n",
      "[1737]\ttraining's l1: 0.105378\ttraining's l2: 0.0445045\tvalid_1's l1: 0.903453\tvalid_1's l2: 1.56986\n",
      "[1738]\ttraining's l1: 0.105395\ttraining's l2: 0.0444581\tvalid_1's l1: 0.903401\tvalid_1's l2: 1.56986\n",
      "[1739]\ttraining's l1: 0.105369\ttraining's l2: 0.0444009\tvalid_1's l1: 0.903306\tvalid_1's l2: 1.56963\n",
      "[1740]\ttraining's l1: 0.105325\ttraining's l2: 0.0443655\tvalid_1's l1: 0.903094\tvalid_1's l2: 1.56914\n",
      "[1741]\ttraining's l1: 0.105271\ttraining's l2: 0.044295\tvalid_1's l1: 0.903095\tvalid_1's l2: 1.56913\n",
      "[1742]\ttraining's l1: 0.105224\ttraining's l2: 0.0442634\tvalid_1's l1: 0.903302\tvalid_1's l2: 1.56977\n",
      "[1743]\ttraining's l1: 0.105174\ttraining's l2: 0.0442092\tvalid_1's l1: 0.903211\tvalid_1's l2: 1.56965\n",
      "[1744]\ttraining's l1: 0.105151\ttraining's l2: 0.0441738\tvalid_1's l1: 0.903263\tvalid_1's l2: 1.56969\n",
      "[1745]\ttraining's l1: 0.10514\ttraining's l2: 0.0441423\tvalid_1's l1: 0.903472\tvalid_1's l2: 1.57041\n",
      "[1746]\ttraining's l1: 0.105067\ttraining's l2: 0.0440726\tvalid_1's l1: 0.903559\tvalid_1's l2: 1.57088\n",
      "[1747]\ttraining's l1: 0.105072\ttraining's l2: 0.0440298\tvalid_1's l1: 0.903643\tvalid_1's l2: 1.57099\n",
      "[1748]\ttraining's l1: 0.10501\ttraining's l2: 0.0439879\tvalid_1's l1: 0.903899\tvalid_1's l2: 1.57186\n",
      "[1749]\ttraining's l1: 0.105002\ttraining's l2: 0.0439561\tvalid_1's l1: 0.904055\tvalid_1's l2: 1.57253\n",
      "[1750]\ttraining's l1: 0.104955\ttraining's l2: 0.0438937\tvalid_1's l1: 0.90409\tvalid_1's l2: 1.57267\n",
      "[1751]\ttraining's l1: 0.104932\ttraining's l2: 0.0438425\tvalid_1's l1: 0.904184\tvalid_1's l2: 1.57292\n",
      "[1752]\ttraining's l1: 0.104895\ttraining's l2: 0.0438147\tvalid_1's l1: 0.904322\tvalid_1's l2: 1.57346\n",
      "[1753]\ttraining's l1: 0.104854\ttraining's l2: 0.0437546\tvalid_1's l1: 0.904268\tvalid_1's l2: 1.57333\n",
      "[1754]\ttraining's l1: 0.104809\ttraining's l2: 0.0437245\tvalid_1's l1: 0.904469\tvalid_1's l2: 1.57395\n",
      "[1755]\ttraining's l1: 0.104738\ttraining's l2: 0.0436567\tvalid_1's l1: 0.904335\tvalid_1's l2: 1.57382\n",
      "[1756]\ttraining's l1: 0.104659\ttraining's l2: 0.0435716\tvalid_1's l1: 0.904475\tvalid_1's l2: 1.57417\n",
      "[1757]\ttraining's l1: 0.104619\ttraining's l2: 0.0435128\tvalid_1's l1: 0.904422\tvalid_1's l2: 1.57404\n",
      "[1758]\ttraining's l1: 0.104574\ttraining's l2: 0.0434829\tvalid_1's l1: 0.904622\tvalid_1's l2: 1.57466\n",
      "[1759]\ttraining's l1: 0.104511\ttraining's l2: 0.0434154\tvalid_1's l1: 0.904704\tvalid_1's l2: 1.57512\n",
      "[1760]\ttraining's l1: 0.1045\ttraining's l2: 0.0433586\tvalid_1's l1: 0.904791\tvalid_1's l2: 1.5754\n",
      "[1761]\ttraining's l1: 0.104445\ttraining's l2: 0.0432884\tvalid_1's l1: 0.904966\tvalid_1's l2: 1.57574\n",
      "[1762]\ttraining's l1: 0.104348\ttraining's l2: 0.0432495\tvalid_1's l1: 0.904945\tvalid_1's l2: 1.5756\n",
      "[1763]\ttraining's l1: 0.104285\ttraining's l2: 0.0431833\tvalid_1's l1: 0.905026\tvalid_1's l2: 1.57605\n",
      "[1764]\ttraining's l1: 0.104231\ttraining's l2: 0.0431047\tvalid_1's l1: 0.904891\tvalid_1's l2: 1.57591\n",
      "[1765]\ttraining's l1: 0.10418\ttraining's l2: 0.0430552\tvalid_1's l1: 0.904904\tvalid_1's l2: 1.57599\n",
      "[1766]\ttraining's l1: 0.104194\ttraining's l2: 0.0430111\tvalid_1's l1: 0.904852\tvalid_1's l2: 1.57599\n",
      "[1767]\ttraining's l1: 0.104133\ttraining's l2: 0.0429702\tvalid_1's l1: 0.905103\tvalid_1's l2: 1.57685\n",
      "[1768]\ttraining's l1: 0.104093\ttraining's l2: 0.042913\tvalid_1's l1: 0.905051\tvalid_1's l2: 1.57673\n",
      "[1769]\ttraining's l1: 0.104042\ttraining's l2: 0.0428646\tvalid_1's l1: 0.905064\tvalid_1's l2: 1.57681\n",
      "[1770]\ttraining's l1: 0.103984\ttraining's l2: 0.0428339\tvalid_1's l1: 0.905243\tvalid_1's l2: 1.57741\n",
      "[1771]\ttraining's l1: 0.103998\ttraining's l2: 0.0427905\tvalid_1's l1: 0.905192\tvalid_1's l2: 1.57741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1772]\ttraining's l1: 0.103948\ttraining's l2: 0.0427414\tvalid_1's l1: 0.905166\tvalid_1's l2: 1.5775\n",
      "[1773]\ttraining's l1: 0.103918\ttraining's l2: 0.0426878\tvalid_1's l1: 0.905159\tvalid_1's l2: 1.57764\n",
      "[1774]\ttraining's l1: 0.103851\ttraining's l2: 0.0426522\tvalid_1's l1: 0.905141\tvalid_1's l2: 1.57753\n",
      "[1775]\ttraining's l1: 0.103841\ttraining's l2: 0.0425977\tvalid_1's l1: 0.905227\tvalid_1's l2: 1.57782\n",
      "[1776]\ttraining's l1: 0.103745\ttraining's l2: 0.04256\tvalid_1's l1: 0.905207\tvalid_1's l2: 1.57768\n",
      "[1777]\ttraining's l1: 0.103703\ttraining's l2: 0.0424985\tvalid_1's l1: 0.904969\tvalid_1's l2: 1.57719\n",
      "[1778]\ttraining's l1: 0.103645\ttraining's l2: 0.04245\tvalid_1's l1: 0.905091\tvalid_1's l2: 1.5777\n",
      "[1779]\ttraining's l1: 0.10359\ttraining's l2: 0.0423815\tvalid_1's l1: 0.905263\tvalid_1's l2: 1.57803\n",
      "[1780]\ttraining's l1: 0.103552\ttraining's l2: 0.0423531\tvalid_1's l1: 0.905463\tvalid_1's l2: 1.57865\n",
      "[1781]\ttraining's l1: 0.10356\ttraining's l2: 0.0423107\tvalid_1's l1: 0.905364\tvalid_1's l2: 1.5786\n",
      "[1782]\ttraining's l1: 0.103521\ttraining's l2: 0.0422827\tvalid_1's l1: 0.90551\tvalid_1's l2: 1.57916\n",
      "[1783]\ttraining's l1: 0.103493\ttraining's l2: 0.0422636\tvalid_1's l1: 0.905416\tvalid_1's l2: 1.57888\n",
      "[1784]\ttraining's l1: 0.10344\ttraining's l2: 0.0421891\tvalid_1's l1: 0.905284\tvalid_1's l2: 1.57874\n",
      "[1785]\ttraining's l1: 0.103411\ttraining's l2: 0.042137\tvalid_1's l1: 0.905277\tvalid_1's l2: 1.57887\n",
      "[1786]\ttraining's l1: 0.103371\ttraining's l2: 0.0420814\tvalid_1's l1: 0.905226\tvalid_1's l2: 1.57875\n",
      "[1787]\ttraining's l1: 0.103322\ttraining's l2: 0.0420347\tvalid_1's l1: 0.905239\tvalid_1's l2: 1.57883\n",
      "[1788]\ttraining's l1: 0.103245\ttraining's l2: 0.0419546\tvalid_1's l1: 0.905372\tvalid_1's l2: 1.57916\n",
      "[1789]\ttraining's l1: 0.103234\ttraining's l2: 0.0419156\tvalid_1's l1: 0.905243\tvalid_1's l2: 1.57894\n",
      "[1790]\ttraining's l1: 0.103168\ttraining's l2: 0.0418808\tvalid_1's l1: 0.905225\tvalid_1's l2: 1.57884\n",
      "[1791]\ttraining's l1: 0.103138\ttraining's l2: 0.04185\tvalid_1's l1: 0.905384\tvalid_1's l2: 1.5795\n",
      "[1792]\ttraining's l1: 0.103089\ttraining's l2: 0.0418033\tvalid_1's l1: 0.90536\tvalid_1's l2: 1.5796\n",
      "[1793]\ttraining's l1: 0.103104\ttraining's l2: 0.0417619\tvalid_1's l1: 0.905352\tvalid_1's l2: 1.57963\n",
      "[1794]\ttraining's l1: 0.103058\ttraining's l2: 0.0417342\tvalid_1's l1: 0.905551\tvalid_1's l2: 1.58026\n",
      "[1795]\ttraining's l1: 0.103004\ttraining's l2: 0.0416901\tvalid_1's l1: 0.905791\tvalid_1's l2: 1.58096\n",
      "[1796]\ttraining's l1: 0.102996\ttraining's l2: 0.0416535\tvalid_1's l1: 0.905834\tvalid_1's l2: 1.58108\n",
      "[1797]\ttraining's l1: 0.102912\ttraining's l2: 0.0415791\tvalid_1's l1: 0.906049\tvalid_1's l2: 1.58169\n",
      "[1798]\ttraining's l1: 0.102871\ttraining's l2: 0.0415232\tvalid_1's l1: 0.906081\tvalid_1's l2: 1.58182\n",
      "[1799]\ttraining's l1: 0.102842\ttraining's l2: 0.0414721\tvalid_1's l1: 0.906074\tvalid_1's l2: 1.58195\n",
      "[1800]\ttraining's l1: 0.102835\ttraining's l2: 0.0414333\tvalid_1's l1: 0.905945\tvalid_1's l2: 1.58173\n",
      "[1801]\ttraining's l1: 0.102773\ttraining's l2: 0.0414063\tvalid_1's l1: 0.905902\tvalid_1's l2: 1.58146\n",
      "[1802]\ttraining's l1: 0.102728\ttraining's l2: 0.0413611\tvalid_1's l1: 0.905879\tvalid_1's l2: 1.58156\n",
      "[1803]\ttraining's l1: 0.102671\ttraining's l2: 0.0413212\tvalid_1's l1: 0.906134\tvalid_1's l2: 1.5824\n",
      "[1804]\ttraining's l1: 0.102638\ttraining's l2: 0.0412673\tvalid_1's l1: 0.906083\tvalid_1's l2: 1.58228\n",
      "[1805]\ttraining's l1: 0.102603\ttraining's l2: 0.0412146\tvalid_1's l1: 0.905993\tvalid_1's l2: 1.58206\n",
      "[1806]\ttraining's l1: 0.102538\ttraining's l2: 0.0411803\tvalid_1's l1: 0.905975\tvalid_1's l2: 1.58196\n",
      "[1807]\ttraining's l1: 0.102512\ttraining's l2: 0.0411503\tvalid_1's l1: 0.906132\tvalid_1's l2: 1.58262\n",
      "[1808]\ttraining's l1: 0.102479\ttraining's l2: 0.0410936\tvalid_1's l1: 0.905904\tvalid_1's l2: 1.58214\n",
      "[1809]\ttraining's l1: 0.102434\ttraining's l2: 0.0410664\tvalid_1's l1: 0.906048\tvalid_1's l2: 1.58271\n",
      "[1810]\ttraining's l1: 0.102447\ttraining's l2: 0.0410259\tvalid_1's l1: 0.906116\tvalid_1's l2: 1.58299\n",
      "[1811]\ttraining's l1: 0.102405\ttraining's l2: 0.0409992\tvalid_1's l1: 0.906311\tvalid_1's l2: 1.5836\n",
      "[1812]\ttraining's l1: 0.102387\ttraining's l2: 0.0409474\tvalid_1's l1: 0.906347\tvalid_1's l2: 1.58383\n",
      "[1813]\ttraining's l1: 0.102356\ttraining's l2: 0.0409289\tvalid_1's l1: 0.906254\tvalid_1's l2: 1.58355\n",
      "[1814]\ttraining's l1: 0.102332\ttraining's l2: 0.0408772\tvalid_1's l1: 0.906165\tvalid_1's l2: 1.58333\n",
      "[1815]\ttraining's l1: 0.102259\ttraining's l2: 0.0408053\tvalid_1's l1: 0.906376\tvalid_1's l2: 1.58394\n",
      "[1816]\ttraining's l1: 0.102254\ttraining's l2: 0.0407673\tvalid_1's l1: 0.906252\tvalid_1's l2: 1.58372\n",
      "[1817]\ttraining's l1: 0.102142\ttraining's l2: 0.0407192\tvalid_1's l1: 0.906235\tvalid_1's l2: 1.58363\n",
      "[1818]\ttraining's l1: 0.10207\ttraining's l2: 0.0406622\tvalid_1's l1: 0.906309\tvalid_1's l2: 1.58406\n",
      "[1819]\ttraining's l1: 0.102044\ttraining's l2: 0.0406326\tvalid_1's l1: 0.906464\tvalid_1's l2: 1.58471\n",
      "[1820]\ttraining's l1: 0.102005\ttraining's l2: 0.040577\tvalid_1's l1: 0.906378\tvalid_1's l2: 1.58465\n",
      "[1821]\ttraining's l1: 0.101983\ttraining's l2: 0.0405479\tvalid_1's l1: 0.906532\tvalid_1's l2: 1.5853\n",
      "[1822]\ttraining's l1: 0.10191\ttraining's l2: 0.0404915\tvalid_1's l1: 0.906609\tvalid_1's l2: 1.58571\n",
      "[1823]\ttraining's l1: 0.101901\ttraining's l2: 0.0404469\tvalid_1's l1: 0.906614\tvalid_1's l2: 1.58579\n",
      "[1824]\ttraining's l1: 0.101893\ttraining's l2: 0.0404094\tvalid_1's l1: 0.906492\tvalid_1's l2: 1.58557\n",
      "[1825]\ttraining's l1: 0.101792\ttraining's l2: 0.0403624\tvalid_1's l1: 0.906474\tvalid_1's l2: 1.58549\n",
      "[1826]\ttraining's l1: 0.10177\ttraining's l2: 0.0403335\tvalid_1's l1: 0.906629\tvalid_1's l2: 1.58614\n",
      "[1827]\ttraining's l1: 0.101733\ttraining's l2: 0.0402843\tvalid_1's l1: 0.906622\tvalid_1's l2: 1.58627\n",
      "[1828]\ttraining's l1: 0.10173\ttraining's l2: 0.0402471\tvalid_1's l1: 0.906496\tvalid_1's l2: 1.58605\n",
      "[1829]\ttraining's l1: 0.101663\ttraining's l2: 0.0402207\tvalid_1's l1: 0.906453\tvalid_1's l2: 1.58578\n",
      "[1830]\ttraining's l1: 0.101553\ttraining's l2: 0.0401816\tvalid_1's l1: 0.906569\tvalid_1's l2: 1.58606\n",
      "[1831]\ttraining's l1: 0.101536\ttraining's l2: 0.0401451\tvalid_1's l1: 0.906659\tvalid_1's l2: 1.58624\n",
      "[1832]\ttraining's l1: 0.101498\ttraining's l2: 0.0401199\tvalid_1's l1: 0.90674\tvalid_1's l2: 1.58669\n",
      "[1833]\ttraining's l1: 0.101443\ttraining's l2: 0.0400786\tvalid_1's l1: 0.906976\tvalid_1's l2: 1.58737\n",
      "[1834]\ttraining's l1: 0.101363\ttraining's l2: 0.0400044\tvalid_1's l1: 0.907099\tvalid_1's l2: 1.58768\n",
      "[1835]\ttraining's l1: 0.101364\ttraining's l2: 0.0399678\tvalid_1's l1: 0.906978\tvalid_1's l2: 1.58747\n",
      "[1836]\ttraining's l1: 0.101265\ttraining's l2: 0.0399217\tvalid_1's l1: 0.906961\tvalid_1's l2: 1.58739\n",
      "[1837]\ttraining's l1: 0.101231\ttraining's l2: 0.0398859\tvalid_1's l1: 0.906991\tvalid_1's l2: 1.58751\n",
      "[1838]\ttraining's l1: 0.101124\ttraining's l2: 0.0398476\tvalid_1's l1: 0.907107\tvalid_1's l2: 1.58779\n",
      "[1839]\ttraining's l1: 0.101124\ttraining's l2: 0.0398117\tvalid_1's l1: 0.906983\tvalid_1's l2: 1.58758\n",
      "[1840]\ttraining's l1: 0.101104\ttraining's l2: 0.0397679\tvalid_1's l1: 0.907068\tvalid_1's l2: 1.58782\n",
      "[1841]\ttraining's l1: 0.101067\ttraining's l2: 0.0397415\tvalid_1's l1: 0.907207\tvalid_1's l2: 1.58835\n",
      "[1842]\ttraining's l1: 0.101002\ttraining's l2: 0.039703\tvalid_1's l1: 0.907452\tvalid_1's l2: 1.58919\n",
      "[1843]\ttraining's l1: 0.100909\ttraining's l2: 0.0396578\tvalid_1's l1: 0.907435\tvalid_1's l2: 1.5891\n",
      "[1844]\ttraining's l1: 0.100901\ttraining's l2: 0.0396206\tvalid_1's l1: 0.90754\tvalid_1's l2: 1.58936\n",
      "[1845]\ttraining's l1: 0.100854\ttraining's l2: 0.0395545\tvalid_1's l1: 0.907414\tvalid_1's l2: 1.58923\n",
      "[1846]\ttraining's l1: 0.100831\ttraining's l2: 0.0394856\tvalid_1's l1: 0.907488\tvalid_1's l2: 1.58942\n",
      "[1847]\ttraining's l1: 0.10077\ttraining's l2: 0.0394429\tvalid_1's l1: 0.907761\tvalid_1's l2: 1.59013\n",
      "[1848]\ttraining's l1: 0.100756\ttraining's l2: 0.0394001\tvalid_1's l1: 0.907766\tvalid_1's l2: 1.5902\n",
      "[1849]\ttraining's l1: 0.100697\ttraining's l2: 0.0393598\tvalid_1's l1: 0.90769\tvalid_1's l2: 1.59013\n",
      "[1850]\ttraining's l1: 0.100653\ttraining's l2: 0.0393194\tvalid_1's l1: 0.907678\tvalid_1's l2: 1.59021\n",
      "[1851]\ttraining's l1: 0.100652\ttraining's l2: 0.0392844\tvalid_1's l1: 0.907556\tvalid_1's l2: 1.59\n",
      "[1852]\ttraining's l1: 0.100582\ttraining's l2: 0.039253\tvalid_1's l1: 0.907413\tvalid_1's l2: 1.58942\n",
      "[1853]\ttraining's l1: 0.100574\ttraining's l2: 0.0392259\tvalid_1's l1: 0.907603\tvalid_1's l2: 1.59009\n",
      "[1854]\ttraining's l1: 0.100549\ttraining's l2: 0.0391807\tvalid_1's l1: 0.907714\tvalid_1's l2: 1.59059\n",
      "[1855]\ttraining's l1: 0.100475\ttraining's l2: 0.0391318\tvalid_1's l1: 0.907881\tvalid_1's l2: 1.59122\n",
      "[1856]\ttraining's l1: 0.100438\ttraining's l2: 0.039082\tvalid_1's l1: 0.907793\tvalid_1's l2: 1.59101\n",
      "[1857]\ttraining's l1: 0.100373\ttraining's l2: 0.0390564\tvalid_1's l1: 0.907751\tvalid_1's l2: 1.59075\n",
      "[1858]\ttraining's l1: 0.10034\ttraining's l2: 0.0390306\tvalid_1's l1: 0.907891\tvalid_1's l2: 1.5913\n",
      "[1859]\ttraining's l1: 0.100294\ttraining's l2: 0.0389906\tvalid_1's l1: 0.90812\tvalid_1's l2: 1.59197\n",
      "[1860]\ttraining's l1: 0.100224\ttraining's l2: 0.0389596\tvalid_1's l1: 0.907977\tvalid_1's l2: 1.5914\n",
      "[1861]\ttraining's l1: 0.100234\ttraining's l2: 0.0389222\tvalid_1's l1: 0.908056\tvalid_1's l2: 1.59149\n",
      "[1862]\ttraining's l1: 0.100219\ttraining's l2: 0.0388947\tvalid_1's l1: 0.908031\tvalid_1's l2: 1.59134\n",
      "[1863]\ttraining's l1: 0.10021\ttraining's l2: 0.0388681\tvalid_1's l1: 0.908218\tvalid_1's l2: 1.592\n",
      "[1864]\ttraining's l1: 0.100177\ttraining's l2: 0.0388439\tvalid_1's l1: 0.908295\tvalid_1's l2: 1.59245\n",
      "[1865]\ttraining's l1: 0.100145\ttraining's l2: 0.0388188\tvalid_1's l1: 0.908482\tvalid_1's l2: 1.59304\n",
      "[1866]\ttraining's l1: 0.100137\ttraining's l2: 0.0387708\tvalid_1's l1: 0.908564\tvalid_1's l2: 1.59332\n",
      "[1867]\ttraining's l1: 0.100055\ttraining's l2: 0.0387096\tvalid_1's l1: 0.908715\tvalid_1's l2: 1.59364\n",
      "[1868]\ttraining's l1: 0.100028\ttraining's l2: 0.0386846\tvalid_1's l1: 0.908849\tvalid_1's l2: 1.59416\n",
      "[1869]\ttraining's l1: 0.100024\ttraining's l2: 0.0386469\tvalid_1's l1: 0.908838\tvalid_1's l2: 1.59418\n",
      "[1870]\ttraining's l1: 0.0999811\ttraining's l2: 0.0385828\tvalid_1's l1: 0.908713\tvalid_1's l2: 1.59405\n",
      "[1871]\ttraining's l1: 0.0999431\ttraining's l2: 0.0385348\tvalid_1's l1: 0.908635\tvalid_1's l2: 1.59395\n",
      "[1872]\ttraining's l1: 0.0998752\ttraining's l2: 0.0385018\tvalid_1's l1: 0.908618\tvalid_1's l2: 1.59385\n",
      "[1873]\ttraining's l1: 0.0998443\ttraining's l2: 0.0384772\tvalid_1's l1: 0.908804\tvalid_1's l2: 1.59444\n",
      "[1874]\ttraining's l1: 0.0998355\ttraining's l2: 0.0384305\tvalid_1's l1: 0.908885\tvalid_1's l2: 1.59471\n",
      "[1875]\ttraining's l1: 0.0997656\ttraining's l2: 0.0383996\tvalid_1's l1: 0.908741\tvalid_1's l2: 1.59413\n",
      "[1876]\ttraining's l1: 0.0997405\ttraining's l2: 0.0383726\tvalid_1's l1: 0.908889\tvalid_1's l2: 1.59475\n",
      "[1877]\ttraining's l1: 0.0997117\ttraining's l2: 0.0383486\tvalid_1's l1: 0.909016\tvalid_1's l2: 1.59524\n",
      "[1878]\ttraining's l1: 0.0996859\ttraining's l2: 0.0382977\tvalid_1's l1: 0.908932\tvalid_1's l2: 1.59517\n",
      "[1879]\ttraining's l1: 0.0996591\ttraining's l2: 0.0382735\tvalid_1's l1: 0.909063\tvalid_1's l2: 1.59569\n",
      "[1880]\ttraining's l1: 0.0995787\ttraining's l2: 0.0382566\tvalid_1's l1: 0.909054\tvalid_1's l2: 1.59532\n",
      "[1881]\ttraining's l1: 0.09957\ttraining's l2: 0.0382195\tvalid_1's l1: 0.908996\tvalid_1's l2: 1.59529\n",
      "[1882]\ttraining's l1: 0.0995505\ttraining's l2: 0.0381763\tvalid_1's l1: 0.909111\tvalid_1's l2: 1.59577\n",
      "[1883]\ttraining's l1: 0.0994735\ttraining's l2: 0.0381263\tvalid_1's l1: 0.909281\tvalid_1's l2: 1.59614\n",
      "[1884]\ttraining's l1: 0.0994369\ttraining's l2: 0.0381032\tvalid_1's l1: 0.909349\tvalid_1's l2: 1.59657\n",
      "[1885]\ttraining's l1: 0.0993524\ttraining's l2: 0.0380428\tvalid_1's l1: 0.909381\tvalid_1's l2: 1.59683\n",
      "[1886]\ttraining's l1: 0.0993229\ttraining's l2: 0.0379942\tvalid_1's l1: 0.909412\tvalid_1's l2: 1.59695\n",
      "[1887]\ttraining's l1: 0.0992869\ttraining's l2: 0.03796\tvalid_1's l1: 0.909435\tvalid_1's l2: 1.59705\n",
      "[1888]\ttraining's l1: 0.0991982\ttraining's l2: 0.0379169\tvalid_1's l1: 0.909418\tvalid_1's l2: 1.59697\n",
      "[1889]\ttraining's l1: 0.0991503\ttraining's l2: 0.0378724\tvalid_1's l1: 0.909592\tvalid_1's l2: 1.59762\n",
      "[1890]\ttraining's l1: 0.0991184\ttraining's l2: 0.0378308\tvalid_1's l1: 0.909605\tvalid_1's l2: 1.5977\n",
      "[1891]\ttraining's l1: 0.0990475\ttraining's l2: 0.0377999\tvalid_1's l1: 0.90946\tvalid_1's l2: 1.59712\n",
      "[1892]\ttraining's l1: 0.0990442\ttraining's l2: 0.0377636\tvalid_1's l1: 0.909448\tvalid_1's l2: 1.59714\n",
      "[1893]\ttraining's l1: 0.099008\ttraining's l2: 0.0377396\tvalid_1's l1: 0.909408\tvalid_1's l2: 1.59691\n",
      "[1894]\ttraining's l1: 0.0989329\ttraining's l2: 0.037694\tvalid_1's l1: 0.90943\tvalid_1's l2: 1.59703\n",
      "[1895]\ttraining's l1: 0.0989068\ttraining's l2: 0.0376293\tvalid_1's l1: 0.909502\tvalid_1's l2: 1.59722\n",
      "[1896]\ttraining's l1: 0.0988802\ttraining's l2: 0.0376056\tvalid_1's l1: 0.909632\tvalid_1's l2: 1.59772\n",
      "[1897]\ttraining's l1: 0.0988059\ttraining's l2: 0.0375416\tvalid_1's l1: 0.909828\tvalid_1's l2: 1.59829\n",
      "[1898]\ttraining's l1: 0.0987437\ttraining's l2: 0.0374908\tvalid_1's l1: 0.909898\tvalid_1's l2: 1.59868\n",
      "[1899]\ttraining's l1: 0.0986631\ttraining's l2: 0.0374326\tvalid_1's l1: 0.91004\tvalid_1's l2: 1.59898\n",
      "[1900]\ttraining's l1: 0.0985921\ttraining's l2: 0.0373886\tvalid_1's l1: 0.910002\tvalid_1's l2: 1.59897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1901]\ttraining's l1: 0.0985659\ttraining's l2: 0.0373412\tvalid_1's l1: 0.910032\tvalid_1's l2: 1.59909\n",
      "[1902]\ttraining's l1: 0.0985253\ttraining's l2: 0.0373081\tvalid_1's l1: 0.910008\tvalid_1's l2: 1.59915\n",
      "[1903]\ttraining's l1: 0.0984373\ttraining's l2: 0.0372596\tvalid_1's l1: 0.910157\tvalid_1's l2: 1.59948\n",
      "[1904]\ttraining's l1: 0.0984289\ttraining's l2: 0.0372256\tvalid_1's l1: 0.910025\tvalid_1's l2: 1.59928\n",
      "[1905]\ttraining's l1: 0.0983828\ttraining's l2: 0.0371891\tvalid_1's l1: 0.91007\tvalid_1's l2: 1.59932\n",
      "[1906]\ttraining's l1: 0.0983509\ttraining's l2: 0.0371625\tvalid_1's l1: 0.910197\tvalid_1's l2: 1.59989\n",
      "[1907]\ttraining's l1: 0.0983145\ttraining's l2: 0.0371389\tvalid_1's l1: 0.91022\tvalid_1's l2: 1.60028\n",
      "[1908]\ttraining's l1: 0.0983264\ttraining's l2: 0.0371043\tvalid_1's l1: 0.910296\tvalid_1's l2: 1.60038\n",
      "[1909]\ttraining's l1: 0.0982724\ttraining's l2: 0.0370546\tvalid_1's l1: 0.910365\tvalid_1's l2: 1.60076\n",
      "[1910]\ttraining's l1: 0.0981948\ttraining's l2: 0.0369969\tvalid_1's l1: 0.910397\tvalid_1's l2: 1.60102\n",
      "[1911]\ttraining's l1: 0.0981651\ttraining's l2: 0.0369512\tvalid_1's l1: 0.910319\tvalid_1's l2: 1.60092\n",
      "[1912]\ttraining's l1: 0.09811\ttraining's l2: 0.0369229\tvalid_1's l1: 0.910171\tvalid_1's l2: 1.60033\n",
      "[1913]\ttraining's l1: 0.0980587\ttraining's l2: 0.0368796\tvalid_1's l1: 0.910343\tvalid_1's l2: 1.60097\n",
      "[1914]\ttraining's l1: 0.0980036\ttraining's l2: 0.0368517\tvalid_1's l1: 0.910195\tvalid_1's l2: 1.60038\n",
      "[1915]\ttraining's l1: 0.0979776\ttraining's l2: 0.0368286\tvalid_1's l1: 0.910324\tvalid_1's l2: 1.60088\n",
      "[1916]\ttraining's l1: 0.0979406\ttraining's l2: 0.0367961\tvalid_1's l1: 0.910329\tvalid_1's l2: 1.60098\n",
      "[1917]\ttraining's l1: 0.0979485\ttraining's l2: 0.0367625\tvalid_1's l1: 0.910387\tvalid_1's l2: 1.60107\n",
      "[1918]\ttraining's l1: 0.0979189\ttraining's l2: 0.0367397\tvalid_1's l1: 0.91051\tvalid_1's l2: 1.60154\n",
      "[1919]\ttraining's l1: 0.097841\ttraining's l2: 0.0367232\tvalid_1's l1: 0.910503\tvalid_1's l2: 1.60119\n",
      "[1920]\ttraining's l1: 0.0977515\ttraining's l2: 0.0366571\tvalid_1's l1: 0.910612\tvalid_1's l2: 1.60147\n",
      "[1921]\ttraining's l1: 0.0976834\ttraining's l2: 0.0366275\tvalid_1's l1: 0.91047\tvalid_1's l2: 1.6009\n",
      "[1922]\ttraining's l1: 0.0976665\ttraining's l2: 0.0366045\tvalid_1's l1: 0.910647\tvalid_1's l2: 1.60145\n",
      "[1923]\ttraining's l1: 0.0976614\ttraining's l2: 0.0365699\tvalid_1's l1: 0.910589\tvalid_1's l2: 1.60142\n",
      "[1924]\ttraining's l1: 0.0976445\ttraining's l2: 0.0365473\tvalid_1's l1: 0.910764\tvalid_1's l2: 1.60196\n",
      "[1925]\ttraining's l1: 0.0976224\ttraining's l2: 0.0365068\tvalid_1's l1: 0.910877\tvalid_1's l2: 1.60242\n",
      "[1926]\ttraining's l1: 0.0976167\ttraining's l2: 0.0364629\tvalid_1's l1: 0.910797\tvalid_1's l2: 1.60234\n",
      "[1927]\ttraining's l1: 0.0975646\ttraining's l2: 0.0364353\tvalid_1's l1: 0.91065\tvalid_1's l2: 1.60175\n",
      "[1928]\ttraining's l1: 0.0975311\ttraining's l2: 0.0364124\tvalid_1's l1: 0.910611\tvalid_1's l2: 1.60153\n",
      "[1929]\ttraining's l1: 0.0975071\ttraining's l2: 0.036387\tvalid_1's l1: 0.910751\tvalid_1's l2: 1.60213\n",
      "[1930]\ttraining's l1: 0.0974712\ttraining's l2: 0.0363642\tvalid_1's l1: 0.910773\tvalid_1's l2: 1.60251\n",
      "[1931]\ttraining's l1: 0.0974869\ttraining's l2: 0.0363314\tvalid_1's l1: 0.910847\tvalid_1's l2: 1.60261\n",
      "[1932]\ttraining's l1: 0.0974534\ttraining's l2: 0.0362962\tvalid_1's l1: 0.911059\tvalid_1's l2: 1.60324\n",
      "[1933]\ttraining's l1: 0.0974157\ttraining's l2: 0.0362646\tvalid_1's l1: 0.911035\tvalid_1's l2: 1.60329\n",
      "[1934]\ttraining's l1: 0.0973836\ttraining's l2: 0.0362423\tvalid_1's l1: 0.911156\tvalid_1's l2: 1.60375\n",
      "[1935]\ttraining's l1: 0.0973133\ttraining's l2: 0.0362264\tvalid_1's l1: 0.911141\tvalid_1's l2: 1.60339\n",
      "[1936]\ttraining's l1: 0.0972481\ttraining's l2: 0.0361707\tvalid_1's l1: 0.911172\tvalid_1's l2: 1.60365\n",
      "[1937]\ttraining's l1: 0.0972261\ttraining's l2: 0.0361307\tvalid_1's l1: 0.911283\tvalid_1's l2: 1.6041\n",
      "[1938]\ttraining's l1: 0.0971926\ttraining's l2: 0.036108\tvalid_1's l1: 0.911243\tvalid_1's l2: 1.60388\n",
      "[1939]\ttraining's l1: 0.0971964\ttraining's l2: 0.0360709\tvalid_1's l1: 0.911207\tvalid_1's l2: 1.60392\n",
      "[1940]\ttraining's l1: 0.0971445\ttraining's l2: 0.0360435\tvalid_1's l1: 0.911061\tvalid_1's l2: 1.60333\n",
      "[1941]\ttraining's l1: 0.0971064\ttraining's l2: 0.0360179\tvalid_1's l1: 0.911146\tvalid_1's l2: 1.60388\n",
      "[1942]\ttraining's l1: 0.0970621\ttraining's l2: 0.0359633\tvalid_1's l1: 0.911144\tvalid_1's l2: 1.60385\n",
      "[1943]\ttraining's l1: 0.0970247\ttraining's l2: 0.0359173\tvalid_1's l1: 0.91106\tvalid_1's l2: 1.60365\n",
      "[1944]\ttraining's l1: 0.096958\ttraining's l2: 0.0358886\tvalid_1's l1: 0.910921\tvalid_1's l2: 1.60309\n",
      "[1945]\ttraining's l1: 0.0969356\ttraining's l2: 0.0358639\tvalid_1's l1: 0.911058\tvalid_1's l2: 1.60368\n",
      "[1946]\ttraining's l1: 0.0969051\ttraining's l2: 0.0358418\tvalid_1's l1: 0.911178\tvalid_1's l2: 1.60414\n",
      "[1947]\ttraining's l1: 0.0968535\ttraining's l2: 0.0358181\tvalid_1's l1: 0.911318\tvalid_1's l2: 1.60465\n",
      "[1948]\ttraining's l1: 0.0967836\ttraining's l2: 0.0358023\tvalid_1's l1: 0.911302\tvalid_1's l2: 1.60429\n",
      "[1949]\ttraining's l1: 0.0967593\ttraining's l2: 0.0357636\tvalid_1's l1: 0.911408\tvalid_1's l2: 1.60474\n",
      "[1950]\ttraining's l1: 0.0966902\ttraining's l2: 0.0357482\tvalid_1's l1: 0.911392\tvalid_1's l2: 1.60438\n",
      "[1951]\ttraining's l1: 0.096669\ttraining's l2: 0.0357102\tvalid_1's l1: 0.911501\tvalid_1's l2: 1.60483\n",
      "[1952]\ttraining's l1: 0.0966124\ttraining's l2: 0.0356623\tvalid_1's l1: 0.911459\tvalid_1's l2: 1.60498\n",
      "[1953]\ttraining's l1: 0.0965474\ttraining's l2: 0.0356339\tvalid_1's l1: 0.911319\tvalid_1's l2: 1.60441\n",
      "[1954]\ttraining's l1: 0.0965157\ttraining's l2: 0.0356116\tvalid_1's l1: 0.91128\tvalid_1's l2: 1.60419\n",
      "[1955]\ttraining's l1: 0.0965275\ttraining's l2: 0.0355793\tvalid_1's l1: 0.911354\tvalid_1's l2: 1.60429\n",
      "[1956]\ttraining's l1: 0.0964724\ttraining's l2: 0.0355379\tvalid_1's l1: 0.911318\tvalid_1's l2: 1.60428\n",
      "[1957]\ttraining's l1: 0.0964415\ttraining's l2: 0.0355161\tvalid_1's l1: 0.911279\tvalid_1's l2: 1.60407\n",
      "[1958]\ttraining's l1: 0.0964415\ttraining's l2: 0.0354869\tvalid_1's l1: 0.911307\tvalid_1's l2: 1.60415\n",
      "[1959]\ttraining's l1: 0.0964113\ttraining's l2: 0.0354618\tvalid_1's l1: 0.911409\tvalid_1's l2: 1.6047\n",
      "[1960]\ttraining's l1: 0.0963797\ttraining's l2: 0.0354017\tvalid_1's l1: 0.911478\tvalid_1's l2: 1.60488\n",
      "[1961]\ttraining's l1: 0.0963455\ttraining's l2: 0.035367\tvalid_1's l1: 0.911689\tvalid_1's l2: 1.60551\n",
      "[1962]\ttraining's l1: 0.0962798\ttraining's l2: 0.0353083\tvalid_1's l1: 0.911874\tvalid_1's l2: 1.60605\n",
      "[1963]\ttraining's l1: 0.0962338\ttraining's l2: 0.0352733\tvalid_1's l1: 0.912089\tvalid_1's l2: 1.60666\n",
      "[1964]\ttraining's l1: 0.0962026\ttraining's l2: 0.0352515\tvalid_1's l1: 0.912049\tvalid_1's l2: 1.60644\n",
      "[1965]\ttraining's l1: 0.0962005\ttraining's l2: 0.0352133\tvalid_1's l1: 0.912008\tvalid_1's l2: 1.60648\n",
      "[1966]\ttraining's l1: 0.0961672\ttraining's l2: 0.0351659\tvalid_1's l1: 0.91196\tvalid_1's l2: 1.60637\n",
      "[1967]\ttraining's l1: 0.0960995\ttraining's l2: 0.0351124\tvalid_1's l1: 0.91199\tvalid_1's l2: 1.60662\n",
      "[1968]\ttraining's l1: 0.0960631\ttraining's l2: 0.0350676\tvalid_1's l1: 0.911908\tvalid_1's l2: 1.60642\n",
      "[1969]\ttraining's l1: 0.0960044\ttraining's l2: 0.0350367\tvalid_1's l1: 0.911886\tvalid_1's l2: 1.6063\n",
      "[1970]\ttraining's l1: 0.0959647\ttraining's l2: 0.0350012\tvalid_1's l1: 0.91213\tvalid_1's l2: 1.60695\n",
      "[1971]\ttraining's l1: 0.0959028\ttraining's l2: 0.0349437\tvalid_1's l1: 0.912313\tvalid_1's l2: 1.60749\n",
      "[1972]\ttraining's l1: 0.0958791\ttraining's l2: 0.0348887\tvalid_1's l1: 0.912195\tvalid_1's l2: 1.60737\n",
      "[1973]\ttraining's l1: 0.0958447\ttraining's l2: 0.0348425\tvalid_1's l1: 0.912147\tvalid_1's l2: 1.60726\n",
      "[1974]\ttraining's l1: 0.0958188\ttraining's l2: 0.0348054\tvalid_1's l1: 0.912183\tvalid_1's l2: 1.60737\n",
      "[1975]\ttraining's l1: 0.0957326\ttraining's l2: 0.0347638\tvalid_1's l1: 0.912159\tvalid_1's l2: 1.60744\n",
      "[1976]\ttraining's l1: 0.0957137\ttraining's l2: 0.0347423\tvalid_1's l1: 0.912328\tvalid_1's l2: 1.60796\n",
      "[1977]\ttraining's l1: 0.0956283\ttraining's l2: 0.0346704\tvalid_1's l1: 0.912541\tvalid_1's l2: 1.60842\n",
      "[1978]\ttraining's l1: 0.0956125\ttraining's l2: 0.0346494\tvalid_1's l1: 0.912707\tvalid_1's l2: 1.60893\n",
      "[1979]\ttraining's l1: 0.0956034\ttraining's l2: 0.0346122\tvalid_1's l1: 0.912649\tvalid_1's l2: 1.60893\n",
      "[1980]\ttraining's l1: 0.0955708\ttraining's l2: 0.034568\tvalid_1's l1: 0.912569\tvalid_1's l2: 1.60894\n",
      "[1981]\ttraining's l1: 0.0955189\ttraining's l2: 0.0345379\tvalid_1's l1: 0.91256\tvalid_1's l2: 1.60881\n",
      "[1982]\ttraining's l1: 0.095473\ttraining's l2: 0.0345049\tvalid_1's l1: 0.912765\tvalid_1's l2: 1.60941\n",
      "[1983]\ttraining's l1: 0.0954779\ttraining's l2: 0.0344622\tvalid_1's l1: 0.912904\tvalid_1's l2: 1.60983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1984]\ttraining's l1: 0.0954264\ttraining's l2: 0.0344327\tvalid_1's l1: 0.912894\tvalid_1's l2: 1.60971\n",
      "[1985]\ttraining's l1: 0.0954014\ttraining's l2: 0.0343948\tvalid_1's l1: 0.912996\tvalid_1's l2: 1.61015\n",
      "[1986]\ttraining's l1: 0.0953676\ttraining's l2: 0.0343502\tvalid_1's l1: 0.912966\tvalid_1's l2: 1.61029\n",
      "[1987]\ttraining's l1: 0.0953444\ttraining's l2: 0.0343168\tvalid_1's l1: 0.913001\tvalid_1's l2: 1.6104\n",
      "[1988]\ttraining's l1: 0.095299\ttraining's l2: 0.034282\tvalid_1's l1: 0.913003\tvalid_1's l2: 1.61046\n",
      "[1989]\ttraining's l1: 0.0952643\ttraining's l2: 0.0342369\tvalid_1's l1: 0.91296\tvalid_1's l2: 1.61035\n",
      "[1990]\ttraining's l1: 0.095244\ttraining's l2: 0.0342011\tvalid_1's l1: 0.912983\tvalid_1's l2: 1.61043\n",
      "[1991]\ttraining's l1: 0.095175\ttraining's l2: 0.0341598\tvalid_1's l1: 0.91289\tvalid_1's l2: 1.61034\n",
      "[1992]\ttraining's l1: 0.0951347\ttraining's l2: 0.0341047\tvalid_1's l1: 0.913082\tvalid_1's l2: 1.61088\n",
      "[1993]\ttraining's l1: 0.0951083\ttraining's l2: 0.0340606\tvalid_1's l1: 0.91304\tvalid_1's l2: 1.61077\n",
      "[1994]\ttraining's l1: 0.0950654\ttraining's l2: 0.0340277\tvalid_1's l1: 0.913246\tvalid_1's l2: 1.61137\n",
      "[1995]\ttraining's l1: 0.0950269\ttraining's l2: 0.0339955\tvalid_1's l1: 0.913451\tvalid_1's l2: 1.61197\n",
      "[1996]\ttraining's l1: 0.0949955\ttraining's l2: 0.0339595\tvalid_1's l1: 0.913462\tvalid_1's l2: 1.61214\n",
      "[1997]\ttraining's l1: 0.094923\ttraining's l2: 0.0339214\tvalid_1's l1: 0.913442\tvalid_1's l2: 1.61206\n",
      "[1998]\ttraining's l1: 0.0948855\ttraining's l2: 0.0338832\tvalid_1's l1: 0.913415\tvalid_1's l2: 1.61192\n",
      "[1999]\ttraining's l1: 0.0948387\ttraining's l2: 0.0338492\tvalid_1's l1: 0.913417\tvalid_1's l2: 1.61198\n",
      "[2000]\ttraining's l1: 0.0948163\ttraining's l2: 0.0338172\tvalid_1's l1: 0.913451\tvalid_1's l2: 1.61208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.01, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_boost_round=2000, num_leaves=31,\n",
       "              objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "              subsample_freq=0)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\n",
    "    'lambda_l1': 1.5,\n",
    "    #'boosting_type':'gbdt',\n",
    "    'lambda_l2': 0,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'num_leaves': 30,\n",
    "    'reg_alpha': 0.1\n",
    "}\n",
    "model = LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
    "                                     colsample_bytree=1.0,\n",
    "                                     importance_type='split',\n",
    "                                     learning_rate=0.01, max_depth=-1,\n",
    "                                     min_child_samples=20,\n",
    "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
    "                                     n_estimators=100, n_jobs=-1,\n",
    "                                     num_boost_round=2000, num_leaves=31,\n",
    "                                     objective=None, random_state=None,\n",
    "                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "                                     subsample=1.0, subsample_for_bin=200000,\n",
    "                                     subsample_freq=0)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "             eval_metric='mae')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
